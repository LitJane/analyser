{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 test demo no UI.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "vXHjbkIfc8Ws",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GLOBALS__={}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zGPbyfYp6nIq",
        "colab_type": "code",
        "outputId": "0b048732-e6cc-4ad2-dc9f-7617530d8926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title –ù–∞—Å—Ç—Ä–æ–π–∫–∏ { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "USD_to_RUB = 34.02 #@param {type:\"number\"}\n",
        "RUB_to_USD = 1.0/USD_to_RUB\n",
        "\n",
        "# print('USD_to_RUB=',USD_to_RUB)\n",
        "# print('RUB_to_USD=',RUB_to_USD)\n",
        "\n",
        "\n",
        "\n",
        "currency_converter = {\n",
        "  'USD': USD_to_RUB,\n",
        "  'RUB': 1.0\n",
        "}\n",
        "\n",
        "print(currency_converter)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'USD': 34.02, 'RUB': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nwpPPXqRQs6-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#MAIN"
      ]
    },
    {
      "metadata": {
        "id": "-2Oe-BsTcCIW",
        "colab_type": "code",
        "outputId": "ea7b45e7-121c-4399-fac5-81b1204ca131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#@title –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ { output-height: 800, form-width: \"300px\", display-mode: \"form\" }\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "def interactive_upload(filetype):\n",
        "  from google.colab import files\n",
        "  import docx2txt\n",
        "\n",
        "  print(f'Please select \"{filetype}\" .docx file:')\n",
        "  uploaded = files.upload()\n",
        "  docs = []\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "    with open(fn, \"wb\") as df:\n",
        "      df.write(uploaded[fn])\n",
        "      df.close()\n",
        "\n",
        "    # extract text\n",
        "\n",
        "    text = ''\n",
        "    try:\n",
        "      text = docx2txt.process(fn)\n",
        "    except:\n",
        "      print(\"Unexpected error:\", sys.exc_info())\n",
        "      os.system('antiword -w 0 \"' + fn + '\" > \"' + fn + '.txt\"')\n",
        "      with open(fn + '.txt') as f:\n",
        "        text = f.read()\n",
        "    print(\"–°–∏–º–≤–æ–ª–æ–≤ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ:\", len(text))\n",
        "    docs.append(text)\n",
        "    return docs\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# ====================================\n",
        "_git_branch = \"show-violations\"  # @param {type:\"string\"}\n",
        "# ====================================\n",
        "# ====================================\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "#''' AZ:-IMPORT CODE GITHUB----------------------------------------------üò∫------ '''\n",
        "import sys\n",
        "\n",
        "\n",
        "def _init_import_code_from_gh():\n",
        "  if 'GLOBALS__' not in globals():\n",
        "    print('adding global GLOBALS__')\n",
        "    global GLOBALS__\n",
        "    GLOBALS__ = {}\n",
        "\n",
        "  if '_init_import_code_from_gh' in GLOBALS__:\n",
        "    print('üëå code already imported from GitHub!')\n",
        "    return\n",
        "\n",
        "  import subprocess\n",
        "  def exec(x):\n",
        "    r = subprocess.check_output(x, shell=True)\n",
        "    r = r.decode('unicode-escape').encode('latin1').decode('utf8')\n",
        "    print(r)\n",
        "\n",
        "  print(f\"fetching code from GitHub.....{_git_branch}\")\n",
        "  try:\n",
        "    exec('rm -r nlp_tools')\n",
        "  except:\n",
        "    pass\n",
        "  exec(f'git clone --single-branch --branch {_git_branch} https://github.com/compartia/nlp_tools.git nlp_tools')\n",
        "\n",
        "  print('ü¶ä GIT revision:')\n",
        "  exec('cd nlp_tools\\ngit rev-list --reverse HEAD | awk \"{ print NR }\" | tail -n 1\\ngit branch\\ngit log -3 --pretty=%B')\n",
        "\n",
        "  sys.path.insert(0, 'nlp_tools')\n",
        "\n",
        "  # self-test\n",
        "  from text_tools import untokenize\n",
        "  print(untokenize(['code', 'imported', 'OK üëç']))\n",
        "\n",
        "  print('installing antiword...')\n",
        "  exec('sudo apt-get install antiword')\n",
        "\n",
        "  print('installing docx2txt...')\n",
        "  exec(\"pip install docx2txt\")\n",
        "\n",
        "  GLOBALS__['_init_import_code_from_gh'] = True\n",
        "\n",
        "\n",
        "  ''' AZ:-------------------------------------------------IMPORT CODE GITHUB-üò∫---'''\n",
        "  print('‚ù§Ô∏è DONE importing Code fro GitHub')\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "# AZ:-INIT ELMO-----------------------------------------------------------------------------------\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "\n",
        "def _import_elmo():\n",
        "  \"\"\"\n",
        "  ACHTUNG!! this method is called later by ElmoEmbedder\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "  elmo = hub.Module('https://storage.googleapis.com/az-nlp/elmo_ru-news_wmt11-16_1.5M_steps.tar.gz',\n",
        "                    trainable=False)  # news\n",
        "#   elmo = hub.Module('https://storage.googleapis.com/az-nlp/elmo_ru-twitter_2013-01_2018-04_600k_steps.tar.gz',\n",
        "#                     trainable=False)  # twitter\n",
        "  print('‚ù§Ô∏è ‚ù§Ô∏è ‚ù§Ô∏è DONE (re)importing Tensorflow hub.Module ')\n",
        "  print('Tensorflow version is', tf.__version__)\n",
        "\n",
        "  return elmo\n",
        "\n",
        "\n",
        "\n",
        "# AZ:-INIT EMBEDDER-----------------------------------------------------------------------------------\n",
        "\n",
        "def _init_embedder():\n",
        "  if 'elmo_embedder' in GLOBALS__:\n",
        "    print('üëå Embedder is already created! ')\n",
        "    return\n",
        "\n",
        "  from embedding_tools import ElmoEmbedder\n",
        "  GLOBALS__['elmo_embedder'] = ElmoEmbedder(_import_elmo(), tf, 'elmo', _import_elmo)\n",
        "\n",
        "  print('‚ù§Ô∏è DONE creating words embedding model')\n",
        "  return GLOBALS__['elmo_embedder']\n",
        "\n",
        "\n",
        "# AZ:-Init chartes context-----------------------------------------------------------------------------------\n",
        "def _init_charters():\n",
        "  if 'CharterAnlysingContext' in GLOBALS__:\n",
        "    print('üëå Charters-related tools are already inited ')\n",
        "    return\n",
        "\n",
        "  _init_embedder()# PRECONDITION\n",
        "  from charter_patterns import CharterPatternFactory \n",
        "  from charter_parser import CharterDocumentParser\n",
        "  CPF = CharterPatternFactory( GLOBALS__[ 'elmo_embedder']  )  \n",
        "  GLOBALS__['CharterAnlysingContext'] = CharterDocumentParser(CPF)\n",
        "  print('‚ù§Ô∏è DONE initing Charters-related tools and models ')\n",
        "\n",
        "\n",
        "def _init_contracts():\n",
        "  if 'ContractAnlysingContext' in GLOBALS__:\n",
        "    print('üëå Contracts-related tools are already inited ')\n",
        "    return\n",
        "\n",
        "  from demo import ContractAnlysingContext\n",
        "  GLOBALS__['ContractAnlysingContext'] = ContractAnlysingContext(GLOBALS__['elmo_embedder'], GLOBALS__['renderer'])\n",
        "  print('‚ù§Ô∏è DONE initing Contracts-related tools and models ')\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "# AZ:- THE CODE----------------------------------------------------------------------------------\n",
        "from typing import List\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _init_the_code(reset=False):\n",
        "  if '_init_the_code' in GLOBALS__ and not reset:\n",
        "    print('üëå Code is alredy imported!')\n",
        "    return\n",
        "\n",
        "  from transaction_values import ValueConstraint\n",
        "\n",
        "  import matplotlib as mpl\n",
        "  from IPython.core.display import display, HTML\n",
        "  import matplotlib.pyplot as plt\n",
        "  from renderer import AbstractRenderer, head_types_colors\n",
        "  from renderer import to_multicolor_text, as_headline_3, as_offset\n",
        "  from renderer import as_msg, as_quote\n",
        "  from renderer import as_error_html\n",
        "  from transaction_values import ValueConstraint\n",
        "  from parsing import head_types_dict, head_types\n",
        "  from legal_docs import PatternSearchResults, ConstraintsSearchResult\n",
        "\n",
        "  def _as_smaller(txt):\n",
        "    return f'<div font-size:12px\">{txt}</div>'\n",
        "\n",
        "  def as_c_quote(txt):\n",
        "    return f'<div style=\"margin-top:0.2em; margin-left:2em; font-size:14px\">\"...{txt} ...\"</div>'\n",
        "\n",
        "  v_color_map = {\n",
        "    'deal_value_attention_vector': (1, 0.0, 0.5),\n",
        "    'soft$.$at_sum__': (0.9, 0.5, 0.0),\n",
        "    '$at_sum__': (0.9, 0, 0.1),\n",
        "    'soft$.$at_d_order_':   (0.0, 0.3, 0.9),\n",
        "    '$at_x_charity_': (0.0, 0.9, 0.3),\n",
        "    'soft$.$at_x_charity_': (0.0, 1.0, 0.0),\n",
        "      \n",
        "    'soft$.$at_x_lawsuit_': (0.8, 0, 0.7),\n",
        "    '$at_x_lawsuit_': (0.9, 0, 0.9),\n",
        "  }\n",
        "\n",
        "  import numpy as np\n",
        "  class DemoRenderer(AbstractRenderer):\n",
        "    \n",
        "    def render_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None):\n",
        "      print('render_color_text')\n",
        "      html = self.to_color_text(tokens, weights, colormap, print_debug, _range)\n",
        "      display(HTML(html))\n",
        "    \n",
        "    def to_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None):\n",
        "      if len(tokens) == 0:\n",
        "        return \" - empty -\"\n",
        "      if len(weights) != len(tokens):\n",
        "        raise ValueError(\"number of weights differs weights={} tokens={}\".format(len(weights), len(tokens)))\n",
        "\n",
        "      #   if()\n",
        "      vmin = weights.min()\n",
        "      vmax = weights.max()\n",
        "\n",
        "      if _range is not None:\n",
        "        vmin = _range[0]\n",
        "        vmax = _range[1]\n",
        "\n",
        "      if print_debug:\n",
        "        print(vmin, vmax)\n",
        "\n",
        "      norm = mpl.colors.Normalize(vmin=vmin - 0.5, vmax=vmax)\n",
        "      html = \"\"\n",
        "      cmap = mpl.cm.get_cmap(colormap)\n",
        "\n",
        "      for d in range(0, len(weights)):\n",
        "        word = tokens[d]\n",
        "        if word == ' ':\n",
        "          word = '&nbsp;_ '\n",
        "\n",
        "        html += '<span title=\"{} {:.4f}\" style=\"background-color:{}\">{} </span>'.format(\n",
        "          d,\n",
        "          weights[d],\n",
        "          mpl.colors.to_hex(cmap(norm(weights[d]))),\n",
        "          word)\n",
        "\n",
        "        #     html+='<span style=\"background-color:' +mpl.colors.to_hex(cmap(norm(weights[d]) ))+ '\">' + str(tokens[d]) + \" </span>\"\n",
        "        if tokens[d] == '\\n':\n",
        "          html += \"<br>\"\n",
        "\n",
        "      return html\n",
        "    \n",
        "    def render_multicolor_text(self, tokens, vectors, colormap, min_color=None, _slice=None):\n",
        "      display(HTML(to_multicolor_text(tokens, vectors, colormap, min_color=min_color, _slice=_slice)))\n",
        "\n",
        "    ''' AZ:-Rendering CHARITYüî•-----üí∏------üí∏-------üí∏------------------------------'''\n",
        "\n",
        "    \n",
        "    ''' AZ:------üí∏------üí∏-------üí∏----------------------END--Rendering CHARITYüî•------'''\n",
        "\n",
        "    def render_subj(self, doc):\n",
        "      from demo import subject_types_dict\n",
        "      subj = doc.subject\n",
        "      s_name = subject_types_dict[subj[0]].upper()\n",
        "\n",
        "      display(\n",
        "        HTML(f'–ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞:<h3 style=\"margin:0\">{s_name}<sup> {subj[0]}</sup> </h3> confidence:{subj[1]:20,.2f}'))\n",
        "\n",
        "    def sign_to_text(self, sign: int):\n",
        "      if sign < 0: return \" &lt; \"\n",
        "      if sign > 0: return \" &gt; \"\n",
        "      return ' = '\n",
        "\n",
        "    def probable_value_to_html(self, pv):\n",
        "      vc = pv.value\n",
        "      color = '#333333'\n",
        "      if vc.sign > 0:\n",
        "        color = '#993300'\n",
        "      elif vc.sign < 0:\n",
        "        color = '#009933'\n",
        "\n",
        "      return f'<b style=\"color:{color}\">{self.sign_to_text(vc.sign)} {vc.currency} {vc.value:20,.2f} confidence={pv.confidence:20,.2f}</b> '\n",
        "\n",
        "    def render_contents(self, doc):\n",
        "      html =  as_headline_3('–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞')\n",
        "      html += \"<ul>\"\n",
        "      for i in doc.structure.headline_indexes:\n",
        "        line = doc.structure.structure[i].to_string(doc.tokens_cc)\n",
        "        html += f'<li> {line} <sup>line {i}</sup></li>'\n",
        "      html += \"</ul>\"\n",
        "\n",
        "      display(HTML(html))\n",
        "      \n",
        "\n",
        "    def render_sections(self, sections):\n",
        "      from legal_docs import HeadlineMeta\n",
        "      html = as_headline_3('–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ —Å–µ–∫—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞')\n",
        "      html += \"<ul>\"\n",
        "      for section_type in sections:\n",
        "        section: HeadlineMeta = sections[section_type]\n",
        "        body = section.body.untokenize_cc()[:1000]\n",
        "        headline = section.subdoc.untokenize_cc()[:500]\n",
        "        #     line = doc.structure.structure[i].to_string(doc.tokens_cc)\n",
        "        html += f'<li><h3> {headline} <sup>type: {section_type}</sup> </h3> <p>{body}</p> </li>'\n",
        "      html += \"</ul>\"\n",
        "\n",
        "      display(HTML(html))\n",
        "\n",
        "    def render_values(self, values):\n",
        "      if len(values) > 0:\n",
        "        for pv in values:\n",
        "          h = self.probable_value_to_html(pv)\n",
        "          display(HTML(h))\n",
        "      else:\n",
        "        display(HTML('—Å—É–º–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'))\n",
        "\n",
        "    \n",
        "\n",
        "    def render_value_section_details(self, value_section_info):\n",
        "      value_section = value_section_info.body\n",
        "      headline_doc = value_section_info.subdoc\n",
        "\n",
        "      headline = headline_doc.untokenize_cc()\n",
        "\n",
        "      v_names = {\n",
        "        'value_attention_vector',\n",
        "        'novalue_attention_vector',\n",
        "\n",
        "        'novalue_attention_vector_local_contrast',\n",
        "        'value_attention_vector_tuned'}\n",
        "\n",
        "      fig = plt.figure(figsize=(20, 6))\n",
        "      ax = plt.axes()\n",
        "      for vector_name in v_names:\n",
        "        ax.plot(value_section.distances_per_pattern_dict[vector_name], label=vector_name, alpha=0.4)\n",
        "        \n",
        "      ax.plot(value_section.distances_per_pattern_dict['value_attention_vector_tuned'], label=vector_name.upper(),\n",
        "              alpha=0.9, color='black')\n",
        "      plt.legend(loc='upper right')\n",
        "\n",
        "      text = self.to_color_text(value_section.tokens_cc,\n",
        "                                value_section.distances_per_pattern_dict['value_attention_vector_tuned'], _range=(0, 1))\n",
        "      html = f'{ as_headline_3(headline)} <div style=\"margin-left:4em; font-size=90%\">{text}</div>'\n",
        "      display(HTML(html))\n",
        "\n",
        "    def to_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None):\n",
        "      if len(tokens) == 0:\n",
        "        return \" - empty -\"\n",
        "      if len(weights) != len(tokens):\n",
        "        raise ValueError(\"number of weights differs weights={} tokens={}\".format(len(weights), len(tokens)))\n",
        "\n",
        "      #   if()\n",
        "      vmin = np.min(weights)\n",
        "      vmax = np.max(weights)\n",
        "\n",
        "      if _range is not None:\n",
        "        vmin = _range[0]\n",
        "        vmax = _range[1]\n",
        "\n",
        "      if print_debug:\n",
        "        print(vmin, vmax)\n",
        "\n",
        "      norm = mpl.colors.Normalize(vmin=vmin - 0.5, vmax=vmax)\n",
        "      html = \"\"\n",
        "      cmap = mpl.cm.get_cmap(colormap)\n",
        "\n",
        "      for d in range(0, len(weights)):\n",
        "        word = tokens[d]\n",
        "        if word == ' ':\n",
        "          word = '&nbsp;_ '\n",
        "\n",
        "        html += '<span title=\"{} {:.4f}\" style=\"background-color:{}\">{} </span>'.format(\n",
        "          d,\n",
        "          weights[d],\n",
        "          mpl.colors.to_hex(cmap(norm(weights[d]))),\n",
        "          word)\n",
        "\n",
        "        #     html+='<span style=\"background-color:' +mpl.colors.to_hex(cmap(norm(weights[d]) ))+ '\">' + str(tokens[d]) + \" </span>\"\n",
        "        if tokens[d] == '\\n':\n",
        "          html += \"<br>\"\n",
        "\n",
        "      return html\n",
        "\n",
        "    def render_charter_parsing_results(self, doc, org, rz, charity_constraints):\n",
        "\n",
        "      txt_html = self.to_color_text(org['tokens'], org['attention_vector'], _range=[0, 1])\n",
        "  \n",
        "      html = '<div style=\"background:#eeeeff; padding:0.5em\"> recognized NE(s): <br><br> org type:<h3 style=\"margin:0\">  {} </h3>org full name:<h2 style=\"margin:0\">  {} </h2> <br>quote: <div style=\"font-size:90%; background:white\">{}</div> </div>'.format(\n",
        "        org['type_name'], org['name'], txt_html)\n",
        "      # html+=txt_html\n",
        "      html += self.render_constraint_values(doc, rz, charity_constraints)\n",
        "  \n",
        "      display(HTML(html))\n",
        "\n",
        "    \n",
        "    def _render_sentence(self, sentence: ConstraintsSearchResult):\n",
        "      html = \"\"\n",
        "      constraints: List[ValueConstraint] = sentence.constraints\n",
        "\n",
        "      html += \"<br>\"\n",
        "      for probable_v in constraints:\n",
        "        html += self.value_to_html(probable_v.value)\n",
        "\n",
        "      if len(constraints) > 0:\n",
        "        html += '<div style=\"border-bottom:1px solid #ccc; margin-top:1em\"></div>'\n",
        "        search_result:PatternSearchResult = sentence.subdoc\n",
        "\n",
        "        v = {\n",
        "          search_result.attention_vector_name:search_result.get_attention (),\n",
        "\n",
        "          '$at_sum__': search_result.get_attention ('$at_sum__'),\n",
        "          '$at_x_lawsuit_': search_result.get_attention('soft$.$at_x_lawsuit_'),\n",
        "          '$at_x_charity_': search_result.get_attention('soft$.$at_x_charity_')\n",
        "        }\n",
        "        min_color = (0.3, 0.3, 0.33)\n",
        "        html += as_c_quote(to_multicolor_text(search_result.tokens, v,\n",
        "                                              v_color_map,\n",
        "                                              min_color=min_color,\n",
        "                                              _slice=None))\n",
        "\n",
        "      return html\n",
        "\n",
        "\n",
        "\n",
        "#     def render_constraint_values(self, doc, rz, charity_constraints):\n",
        "  \n",
        "#       html = ''\n",
        "#       for head_type in rz.keys():\n",
        "  \n",
        "#         r_by_head_type = rz[head_type]\n",
        "  \n",
        "#         html += '<hr style=\"margin-top: 45px\">'\n",
        "  \n",
        "#         html += f'<h2 style=\"color:{head_types_colors[head_type]}; padding:0; margin:0\">{head_types_dict[head_type]}</h2>'\n",
        "  \n",
        "#         sentences = r_by_head_type['sentences']\n",
        "#         html += as_quote(r_by_head_type['caption'])\n",
        "  \n",
        "#         charity_constraints_by_head = charity_constraints[head_type]\n",
        "         \n",
        "#         html_i = ''\n",
        "#         html_i += self.html_charity_constraints_by_head(charity_constraints_by_head)\n",
        "  \n",
        "#         if True:\n",
        "#           html_i += as_headline_3('—Ä–µ—à–µ–Ω–∏—è –æ –ø–æ—Ä–æ–≥–æ–≤—ã—Ö —Å—É–º–º–∞—Ö:')\n",
        "  \n",
        "#           if len(sentences) > 0:\n",
        "#             for sentence in sentences:\n",
        "#               html_i += self._render_sentence(sentence)\n",
        "  \n",
        "#           else:\n",
        "#             html_i += as_error_html('–ü–æ—Ä–æ–≥–æ–≤—ã–µ —Å—É–º–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω—ã')\n",
        "  \n",
        "#         html += as_offset(html_i)\n",
        "  \n",
        "#       return html\n",
        "\n",
        "    def render_constraint_values(self, doc, rz, charity_constraints):\n",
        "      from legal_docs import ConstraintsSearchResult\n",
        "\n",
        "      html = ''\n",
        "      for head_type in rz.keys():\n",
        "\n",
        "        constraint_search_results: List[ConstraintsSearchResult] = rz[head_type]\n",
        "\n",
        "        html += '<hr style=\"margin-top: 45px\">'\n",
        "\n",
        "        html += f'<h2 style=\"color:{head_types_colors[head_type]}; padding:0; margin:0\">{head_types_dict[head_type]}</h2>'\n",
        "\n",
        "        # html += as_quote(r_by_head_type.)\n",
        "\n",
        "        charity_constraints_by_head = charity_constraints[head_type]\n",
        "\n",
        "        html_i = ''\n",
        "        html_i += self.html_charity_constraints_by_head(charity_constraints_by_head)\n",
        "\n",
        "        if True:\n",
        "          html_i += as_headline_3('—Ä–µ—à–µ–Ω–∏—è –æ –ø–æ—Ä–æ–≥–æ–≤—ã—Ö —Å—É–º–º–∞—Ö:')\n",
        "\n",
        "          if len(constraint_search_results) > 0:\n",
        "            for constraint_search_result in constraint_search_results:\n",
        "              html_i += self._render_sentence(constraint_search_result)\n",
        "\n",
        "          else:\n",
        "            html_i += as_error_html('–ü–æ—Ä–æ–≥–æ–≤—ã–µ —Å—É–º–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω—ã')\n",
        "\n",
        "        html += as_offset(html_i)\n",
        "\n",
        "      return html\n",
        "\n",
        "    \n",
        "\n",
        "    ''' AZ:-Rendering CHARITYüî•-----üí∏------üí∏-------üí∏------------------------------'''\n",
        "\n",
        "     \n",
        "\n",
        "    def html_charity_constraints_by_head(self, charity_constraints_by_head: PatternSearchResults) -> str:\n",
        "      html = ''\n",
        "\n",
        "      html += as_headline_3('–æ–¥–æ–±—Ä–µ–Ω–∏–µ —Å–¥–µ–ª–æ–∫ –ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:')\n",
        "\n",
        "      if len(charity_constraints_by_head) > 0:\n",
        "\n",
        "        for r in charity_constraints_by_head:\n",
        "          html += '<BR>'\n",
        " \n",
        "          v = {\n",
        "            'soft$.'+r.attention_vector_name: r.parent.distances_per_pattern_dict['soft$.'+r.attention_vector_name],\n",
        "            r.attention_vector_name: r.parent.distances_per_pattern_dict[r.attention_vector_name],\n",
        "#             'soft$.$at_d_order_': r.parent.distances_per_pattern_dict['soft$.$at_d_order_'],\n",
        "#             'd_order_consent': r.parent.distances_per_pattern_dict['d_order_consent']\n",
        "          }\n",
        "\n",
        "          min_color = (0.3, 0.3, 0.33)\n",
        "          q_html = ''\n",
        "          q_html += to_multicolor_text(r.parent.tokens_cc, v, \n",
        "                                       v_color_map, min_color=min_color, _slice=r.region)\n",
        "          html += as_c_quote(q_html)\n",
        "      else:\n",
        "        html += as_msg('–Ω–µ –≤—ã—è–≤–ª–µ–Ω–æ')\n",
        "\n",
        "      return html\n",
        "       \n",
        "\n",
        "  GLOBALS__['renderer'] = DemoRenderer()\n",
        "\n",
        "  \n",
        "  # AZ:----------PROTOCOLS RENDERER-------------------------\n",
        "\n",
        "  from legal_docs import LegalDocument\n",
        "\n",
        "  import matplotlib as mpl\n",
        "  from IPython.core.display import display, HTML\n",
        "  from renderer import  as_headline_3\n",
        "  class ProtocolRenderer(DemoRenderer):\n",
        "\n",
        "    def winning_patterns_to_html(self, _tokens, ranges, winning_patterns, _range,\n",
        "                                 colormaps=['Reds', 'Purples', 'Blues', 'Greens', 'Greys']):\n",
        "      vmin = -ranges[1]\n",
        "      vmax = -ranges[0]\n",
        "\n",
        "      #     print(\"winning_patterns_to_html _range\", _range, \"min max=\", ranges)\n",
        "\n",
        "      norm = mpl.colors.Normalize(vmax=vmax, vmin=vmin)\n",
        "\n",
        "      cmaps = []\n",
        "\n",
        "      #     print (colormaps)\n",
        "      for n in colormaps:\n",
        "        cmap = mpl.cm.get_cmap(n)\n",
        "        cmaps.append(cmap)\n",
        "\n",
        "      html = \"\"\n",
        "\n",
        "      for d in _range:\n",
        "        winning_pattern_i = winning_patterns[d][0]\n",
        "        colormap = cmaps[winning_pattern_i % len(colormaps)]\n",
        "        normed = norm(-winning_patterns[d][1])\n",
        "        color = mpl.colors.to_hex(colormap(normed))\n",
        "        html += '<span title=\"' + '{} {:.2f}'.format(d, winning_patterns[d][\n",
        "          1]) + '\" style=\"background-color:' + color + '\">' + str(\n",
        "          _tokens[d]) + \" </span>\"\n",
        "        if _tokens[d] == '\\n':\n",
        "          html += \"<br>\"\n",
        "\n",
        "      return html\n",
        "\n",
        "    def _render_doc_subject_fragments(self, doc):\n",
        "      #     print(doc.per_subject_distances)\n",
        "\n",
        "      _html = \"\"\n",
        "      if doc.per_subject_distances is not None:\n",
        "\n",
        "        type = \"–î–æ–≥–æ–≤–æ—Ä  –±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏—è\"\n",
        "        if doc.per_subject_distances[0] > doc.per_subject_distances[1]:\n",
        "          type = \"–î–æ–≥–æ–≤–æ—Ä –≤–æ–∑–º–µ–∑–¥–Ω–æ–≥–æ –æ–∫–∞–∑–∞–Ω–∏—è —É—Å–ª—É–≥\"\n",
        "\n",
        "        _html += \"<h3>\" + type + \"</h3>\"\n",
        "\n",
        "        colormaps = ['PuRd'] * 5 + ['Blues'] * 7 + ['Greys']\n",
        "\n",
        "        _html += as_headline_4('–ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞')\n",
        "\n",
        "        for region in [doc.subj_range]:\n",
        "          _html += self.winning_patterns_to_html(_tokens=doc.tokens, ranges=doc.subj_ranges,\n",
        "                                                 winning_patterns=doc.winning_subj_patterns, _range=region,\n",
        "                                                 colormaps=colormaps)\n",
        "\n",
        "      return _html\n",
        "\n",
        "    def render_subject(self, counter):\n",
        "      html = as_headline_3('–ü—Ä–µ–¥–º–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ (X):') + self.subject_type_weights_to_html(counter)\n",
        "      display(HTML(html))\n",
        "\n",
        "    def print_results(self, _doc: LegalDocument, results=None):\n",
        "\n",
        "      if results is None:\n",
        "        results = _doc.found_sum\n",
        "\n",
        "      result, (start, end), sentence, meta = results\n",
        "\n",
        "      html = \"<hr>\"\n",
        "\n",
        "      html += self._render_doc_subject_fragments(_doc)\n",
        "\n",
        "      if result is None:\n",
        "        html += '<h2 style=\"color:red\">–°–£–ú–ú–ê –ù–ï –ù–ê–ô–î–ï–ù–ê</h2>'\n",
        "      else:\n",
        "        html += '<h2>' + str(result[0]) + ' ' + str(result[1]) + '</h2>'\n",
        "\n",
        "      for key in meta.keys():\n",
        "        html += '<div style=\"font-size:9px\">' + str(key) + \" = \" + str(meta[key]) + \"</div>\"\n",
        "\n",
        "      display(HTML(html))\n",
        "      self.render_color_text(_doc.tokens[start:end], _doc.sums[start:end])\n",
        "\n",
        "    def subject_type_weights_to_html(self, counter):\n",
        "      dict = {\n",
        "        't_dea': '–°–¥–µ–ª–∫–∞',\n",
        "        't_cha': '–ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å',\n",
        "        't_org': '–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è'\n",
        "      }\n",
        "\n",
        "      maxkey = \"None\"\n",
        "      for key in dict:\n",
        "        if counter[key] > counter[maxkey]:\n",
        "          maxkey = key\n",
        "\n",
        "      html = \"\"\n",
        "      for key in dict:\n",
        "        templ = \"<div>{}: {}</div>\"\n",
        "        if key == maxkey:\n",
        "          templ = '<b style=\"font-size:135%; color:maroon\">{}: {}</b>'\n",
        "        html += templ.format(counter[key], dict[key])\n",
        "\n",
        "      return html\n",
        "\n",
        "  GLOBALS__['ProtocolRenderer'] = ProtocolRenderer()\n",
        "  \n",
        "  from demo_protocols import ProtocolAnlysingContext\n",
        "  GLOBALS__['ProtocolAnlysingContext'] = ProtocolAnlysingContext(GLOBALS__['elmo_embedder'],\n",
        "                                                                 GLOBALS__['ProtocolRenderer'])\n",
        "  GLOBALS__['_init_the_code'] = True\n",
        "    # AZ:-------------------------------------------------Init Protocols context===\n",
        "  \n",
        "\n",
        "  # AZ:-------------------------------------------------Init Charters context====\n",
        "\n",
        "  def read_doc(fn):\n",
        "    import docx2txt, sys, os\n",
        "    text = ''\n",
        "    try:\n",
        "      text = docx2txt.process(fn)\n",
        "    except:\n",
        "      print(\"Unexpected error:\", sys.exc_info())\n",
        "      os.system('antiword -w 0 \"' + fn + '\" > \"' + fn + '.txt\"')\n",
        "      with open(fn + '.txt') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    return text\n",
        "\n",
        "  GLOBALS__['read_doc'] = read_doc\n",
        "\n",
        "  print(\"‚ù§Ô∏è DONE initializing the code\")\n",
        "\n",
        "\n",
        "# AZ:-FINDING_VIOLATIONS--------------------------------------------------------\n",
        "def find_and_show_violations():\n",
        "  from IPython.core.display import display, HTML\n",
        "\n",
        "  from demo import ContractAnlysingContext\n",
        "  from renderer import as_headline_2, as_error_html\n",
        "\n",
        "  print('–ü–æ–∏—Å–∫ –Ω–∞—Ä—É—à–µ–Ω–∏–π')\n",
        "\n",
        "  charterAnlysingContext: CharterAnlysingContext = GLOBALS__['CharterAnlysingContext']\n",
        "  contractAnlysingContext: ContractAnlysingContext = GLOBALS__['ContractAnlysingContext']\n",
        "\n",
        "  contract = contractAnlysingContext.contract\n",
        "  charter = charterAnlysingContext.doc\n",
        "  charter_constraints = charterAnlysingContext.constraints  # XXX: move to doc\n",
        "\n",
        "  renderer = GLOBALS__['renderer']\n",
        "  renderer.render_subj(contract)\n",
        "\n",
        "  import copy\n",
        "\n",
        "  def convert(v):\n",
        "    v_converted = copy.copy(v)\n",
        "    if v.currency in currency_converter:\n",
        "      v_converted.value = currency_converter[v.currency] * v.value\n",
        "      v_converted.currency = 'RUB'\n",
        "      return v_converted\n",
        "    else:\n",
        "      display(HTML(as_error_html(\n",
        "        f\"–º—ã –Ω–µ –≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏ (–ø–æ–∫–∞) –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å {v.currency} --> RUB. –≠—Ç–æ –≤–æ–æ–±—â–µ –≤–∞–ª—é—Ç–∞ –∫–∞–∫–æ–π —Å—Ç—Ä–∞–Ω—ã? –†—É–º—ã–Ω–∏–∏?\")))\n",
        "      return v\n",
        "\n",
        "  best_value = contractAnlysingContext.find_contract_best_value(convert)\n",
        "\n",
        "  # rendering:----------------------------\n",
        "\n",
        "  def _render_violations(ranges_by_group, best_value):\n",
        "    for group_key in ranges_by_group:\n",
        "      group = ranges_by_group[group_key]\n",
        "      display(HTML(as_headline_2(group['name'])))\n",
        "\n",
        "      for rk in group['ranges']:\n",
        "        r = group['ranges'][rk]\n",
        "        display(HTML(r.check_contract_value(best_value, convert, renderer)))\n",
        "\n",
        "  print(\"–°—É–º–º–∞ –î–æ–≥–æ–≤–æ—Ä–∞:\")\n",
        "  renderer.render_values([best_value])\n",
        "  renderer.render_color_text(best_value.value.context.tokens, best_value.value.context.attention, _range=[0, 1])\n",
        "\n",
        "  _render_violations(\n",
        "    charterAnlysingContext.find_ranges_by_group(charter_constraints, convert, verbose=False),\n",
        "    best_value)\n",
        "\n",
        "\n",
        "#   display(HTML(renderer.render_constraint_values(charter_constraints)))\n",
        "\n",
        "\n",
        "# AZ:--------------------------------------------------------FINDING_VIOLATIONS-\n",
        "\n",
        "# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXXX\n",
        "# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXXX\n",
        "# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXXX\n",
        "# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXX"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0423 06:48:10.478367 139815788386176 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "YhjI5YF61cpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# step 0. –ò–Ω–∏—Ç –≤—Å–µ–≥–∞"
      ]
    },
    {
      "metadata": {
        "id": "6BnrLv2k1iVq",
        "colab_type": "code",
        "outputId": "f50e7dbb-a240-4342-e2eb-f9e1eae8a835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        }
      },
      "cell_type": "code",
      "source": [
        "## do preparation here\n",
        "\n",
        "# 1.\n",
        "_init_import_code_from_gh()\n",
        "# 2.\n",
        "_init_embedder()\n",
        "# 3.\n",
        "_init_the_code()\n",
        "4.\n",
        "_init_charters()\n",
        "# 5.\n",
        "_init_contracts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fetching code from GitHub.....show-violations\n",
            "\n",
            "\n",
            "ü¶ä GIT revision:\n",
            "321\n",
            "* show-violations\n",
            "Smarter splitting setencens by values\n",
            "\n",
            "Merge branch 'contract_patterns_join' into show-violations\n",
            "\n",
            "Joining pattern factories üìé\n",
            "\n",
            "\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "code imported OK üëç\n",
            "installing antiword...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "antiword is already the newest version (0.37-11build1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 6 not upgraded.\n",
            "\n",
            "installing docx2txt...\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.6/dist-packages (0.7)\n",
            "\n",
            "‚ù§Ô∏è DONE importing Code fro GitHub\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0423 06:48:30.223141 139815788386176 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "‚ù§Ô∏è ‚ù§Ô∏è ‚ù§Ô∏è DONE (re)importing Tensorflow hub.Module \n",
            "Tensorflow version is 1.13.1\n",
            "‚ù§Ô∏è DONE creating words embedding model\n",
            "<nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x7f28e6294828>\n",
            "‚ù§Ô∏è DONE initializing the code\n",
            "üëå Embedder is already created! \n",
            "üêå Embedding 607 words... it takes time (‚òïÔ∏è?)..\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0423 06:48:33.381309 139815788386176 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding complete üêå ; the shape is (64, 20, 1024)\n",
            "‚ù§Ô∏è DONE initing Charters-related tools and models \n",
            "üêå Embedding 483 words... it takes time (‚òïÔ∏è?)..\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0423 06:48:38.673687 139815788386176 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding complete üêå ; the shape is (57, 33, 1024)\n",
            "‚ù§Ô∏è DONE initing Contracts-related tools and models \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zNNi8ZkbzLwx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# step 1. –£—Å—Ç–∞—Ñ—Ñ"
      ]
    },
    {
      "metadata": {
        "id": "z2rA1VotgOSo",
        "colab_type": "code",
        "outputId": "7d0a50f0-9456-4e7d-cbcc-1165e53f4e6a",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1803
        }
      },
      "cell_type": "code",
      "source": [
        "uploaded = interactive_upload('–£—Å—Ç–∞—Ñ—Ñ, –æ–Ω –ª—ë—Ö—Ö—Ö, –Ω–æ –ø–æ–¥—É–º–∞—Ñ—Ñ –æ–Ω –æ—Å–æ–∑–Ω–∞–ª, —á—Ç–æ –æ–Ω –Ω–µ —Ç–∞–∫–æ–π —É–∂ –∏ –õ—ë—Ö—Ö')\n",
        "\n",
        "_CTX = GLOBALS__['CharterAnlysingContext']\n",
        "_CTX.verbosity_level=2\n",
        "_CTX.analyze_charter(uploaded[0], True)\n",
        "\n",
        "\n",
        "GLOBALS__['renderer'].render_charter_parsing_results(_CTX.doc, _CTX.org, _CTX.constraints, _CTX.charity_constraints)\n",
        "GLOBALS__['renderer'].render_contents(_CTX.doc)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please select \"–£—Å—Ç–∞—Ñ—Ñ, –æ–Ω –ª—ë—Ö—Ö—Ö, –Ω–æ –ø–æ–¥—É–º–∞—Ñ—Ñ –æ–Ω –æ—Å–æ–∑–Ω–∞–ª, —á—Ç–æ –æ–Ω –Ω–µ —Ç–∞–∫–æ–π —É–∂ –∏ –õ—ë—Ö—Ö\" .docx file:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e9ddd930-5724-40dd-a6ef-2982b44c1f10\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e9ddd930-5724-40dd-a6ef-2982b44c1f10\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving –ú–ù–ì –£—Å—Ç–∞–≤.docx to –ú–ù–ì –£—Å—Ç–∞–≤ (4).docx\n",
            "User uploaded file \"–ú–ù–ì –£—Å—Ç–∞–≤.docx\" with length 332083 bytes\n",
            "–°–∏–º–≤–æ–ª–æ–≤ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ: 71981\n",
            "WARNING: Document is too large for embedding: 10388 tokens. Splitting into 2 windows overlapping with 1200 tokens \n",
            "Embedding region: 0 7200\n",
            "üêå Embedding 7200 words... it takes time (‚òïÔ∏è?)..\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0423 06:48:56.520751 139815788386176 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding complete üêå ; the shape is (1, 7200, 1024)\n",
            "Function _emb called 1 times. \n",
            "Execution time max: 19.9238, average: 19.9238\n",
            "Embedding region: 6000 4388\n",
            "üêå Embedding 4388 words... it takes time (‚òïÔ∏è?)..\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0423 06:49:16.731015 139815788386176 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding complete üêå ; the shape is (1, 4388, 1024)\n",
            "Function _emb called 2 times. \n",
            "Execution time max: 19.9238, average: 16.8924\n",
            "Function _emb called 2 times. \n",
            "Execution time max: 19.9238, average: 16.8924\n",
            "Function _embedd_large called 1 times. \n",
            "Execution time max: 33.8081, average: 33.8081\n",
            "----------------- LegalDocument charter.head.all deleted. Ciao bella!\n",
            "----------------- LegalDocument charter.head.pravlenie deleted. Ciao bella!\n",
            "‚ù§Ô∏è ACCOMPLISHED: \t 0.\t Splitting Document into sections ‚úÇÔ∏è üìÉ -> üìÑüìÑüìÑ\n",
            "----WARNING!: function rectifyed_sum_by_pattern_prefix is deprecated\n",
            "----WARNING!: function subdoc is deprecated\n",
            "----------------- LegalDocument charter.name.undef deleted. Ciao bella!\n",
            "‚ù§Ô∏è ACCOMPLISHED: \t 1.\t extracting NERs (named entities üè¶ üè® üèõ)\n",
            "----WARNING!: function find_sentences_by_pattern_prefix is deprecated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"background:#eeeeff; padding:0.5em\"> recognized NE(s): <br><br> org type:<h3 style=\"margin:0\">  –ê–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ –æ–±—â–µ—Å—Ç–≤–æ </h3>org full name:<h2 style=\"margin:0\">  ¬´ –ú–µ—Å—Å–æ—è—Ö–∞–Ω–µ—Ñ—Ç–µ–≥–∞–∑ ¬ª </h2> <br>quote: <div style=\"font-size:90%; background:white\"><span title=\"0 0.1457\" style=\"background-color:#cad8ef\">–°—Ç–∞—Ç—å—è </span><span title=\"1 0.1226\" style=\"background-color:#c5d6f2\">2 </span><span title=\"2 0.2460\" style=\"background-color:#dcdddd\">. </span><span title=\"3 0.3233\" style=\"background-color:#e9d5cb\">–§–∏—Ä–º–µ–Ω–Ω–æ–µ </span><span title=\"4 0.2576\" style=\"background-color:#dedcdb\">–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ </span><span title=\"5 0.2362\" style=\"background-color:#dadce0\">–∏ </span><span title=\"6 0.2136\" style=\"background-color:#d6dce4\">–º–µ—Å—Ç–æ </span><span title=\"7 0.2360\" style=\"background-color:#dadce0\">–Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è </span><span title=\"8 0.2545\" style=\"background-color:#dddcdc\">–û–±—â–µ—Å—Ç–≤–∞ </span><span title=\"9 0.1467\" style=\"background-color:#cad8ef\">\n",
              " </span><br><span title=\"10 0.2656\" style=\"background-color:#dfdbd9\">\n",
              " </span><br><span title=\"11 0.3396\" style=\"background-color:#ebd3c6\">–§–∏—Ä–º–µ–Ω–Ω–æ–µ </span><span title=\"12 0.3548\" style=\"background-color:#edd2c3\">–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ </span><span title=\"13 0.2697\" style=\"background-color:#e0dbd8\">–û–±—â–µ—Å—Ç–≤–∞ </span><span title=\"14 0.1788\" style=\"background-color:#cfdaea\">–Ω–∞ </span><span title=\"15 0.1951\" style=\"background-color:#d3dbe7\">—Ä—É—Å—Å–∫–æ–º </span><span title=\"16 0.1795\" style=\"background-color:#cfdaea\">—è–∑—ã–∫–µ </span><span title=\"17 0.1414\" style=\"background-color:#c9d7f0\">: </span><span title=\"18 0.2064\" style=\"background-color:#d5dbe5\">\n",
              " </span><br><span title=\"19 0.2883\" style=\"background-color:#e3d9d3\">–ø–æ–ª–Ω–æ–µ </span><span title=\"20 0.3204\" style=\"background-color:#e9d5cb\">—Ñ–∏—Ä–º–µ–Ω–Ω–æ–µ </span><span title=\"21 0.2637\" style=\"background-color:#dfdbd9\">–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ </span><span title=\"22 0.5068\" style=\"background-color:#f7b79b\">‚Äì </span><span title=\"23 0.6274\" style=\"background-color:#f4987a\">–ê–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ </span><span title=\"24 0.3393\" style=\"background-color:#ebd3c6\">–æ–±—â–µ—Å—Ç–≤–æ </span><span title=\"25 0.1300\" style=\"background-color:#c6d6f1\">\n",
              " </span><br><span title=\"26 0.1938\" style=\"background-color:#d3dbe7\">¬´ </span><span title=\"27 0.2063\" style=\"background-color:#d5dbe5\">–ú–µ—Å—Å–æ—è—Ö–∞–Ω–µ—Ñ—Ç–µ–≥–∞–∑ </span><span title=\"28 0.1460\" style=\"background-color:#cad8ef\">¬ª </span><span title=\"29 0.1654\" style=\"background-color:#cdd9ec\">; </span><span title=\"30 0.2461\" style=\"background-color:#dcdddd\">\n",
              " </span><br><span title=\"31 0.3206\" style=\"background-color:#e9d5cb\">—Å–æ–∫—Ä–∞—â–µ–Ω–Ω–æ–µ </span><span title=\"32 0.3406\" style=\"background-color:#ebd3c6\">—Ñ–∏—Ä–º–µ–Ω–Ω–æ–µ </span><span title=\"33 0.2799\" style=\"background-color:#e2dad5\">–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ </span><span title=\"34 0.5208\" style=\"background-color:#f7b396\">‚Äì </span><span title=\"35 0.6427\" style=\"background-color:#f39475\">–ê–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ </span><span title=\"36 0.3222\" style=\"background-color:#e9d5cb\">–û–±—â–µ—Å—Ç–≤–æ </span><span title=\"37 0.1966\" style=\"background-color:#d3dbe7\">¬´ </span><span title=\"38 0.2011\" style=\"background-color:#d4dbe6\">–ú–µ—Å—Å–æ—è—Ö–∞–Ω–µ—Ñ—Ç–µ–≥–∞–∑ </span><span title=\"39 0.1223\" style=\"background-color:#c5d6f2\">¬ª </span><span title=\"40 0.1353\" style=\"background-color:#c7d7f0\">. </span><span title=\"41 0.2157\" style=\"background-color:#d7dce3\">\n",
              " </span><br><span title=\"42 0.2072\" style=\"background-color:#d5dbe5\">–ú–µ—Å—Ç–æ </span><span title=\"43 0.2473\" style=\"background-color:#dcdddd\">–Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è </span><span title=\"44 0.2850\" style=\"background-color:#e2dad5\">–û–±—â–µ—Å—Ç–≤–∞ </span><span title=\"45 0.2482\" style=\"background-color:#dcdddd\">: </span><span title=\"46 0.2788\" style=\"background-color:#e1dad6\">–†–æ—Å—Å–∏–π—Å–∫–∞—è </span><span title=\"47 0.2412\" style=\"background-color:#dbdcde\">–§–µ–¥–µ—Ä–∞—Ü–∏—è </span><span title=\"48 0.2057\" style=\"background-color:#d5dbe5\">, </span><span title=\"49 0.2132\" style=\"background-color:#d6dce4\">–¢—é–º–µ–Ω—Å–∫–∞—è </span><span title=\"50 0.1921\" style=\"background-color:#d3dbe7\">–æ–±–ª–∞—Å—Ç—å </span><span title=\"51 0.2194\" style=\"background-color:#d7dce3\">, </span><span title=\"52 0.2512\" style=\"background-color:#dddcdc\">–Ø–º–∞–ª–æ-–ù–µ–Ω–µ—Ü–∫–∏–π </span><span title=\"53 0.2421\" style=\"background-color:#dbdcde\">–∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π </span><span title=\"54 0.1803\" style=\"background-color:#d1dae9\">–æ–∫—Ä—É–≥ </span><span title=\"55 0.1480\" style=\"background-color:#cad8ef\">, </span><span title=\"56 0.1510\" style=\"background-color:#cbd8ee\">–≥–æ—Ä–æ–¥ </span><span title=\"57 0.1440\" style=\"background-color:#c9d7f0\">–ù–æ–≤—ã–π </span><span title=\"58 0.1411\" style=\"background-color:#c9d7f0\">–£—Ä–µ–Ω–≥–æ–π </span><span title=\"59 0.1423\" style=\"background-color:#c9d7f0\">. </span><span title=\"60 0.1289\" style=\"background-color:#c6d6f1\">\n",
              " </span><br><span title=\"61 0.1177\" style=\"background-color:#c4d5f3\">\n",
              " </span><br></div> </div><hr style=\"margin-top: 45px\"><h2 style=\"color:crimson; padding:0; margin:0\">–°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤</h2><div style=\"margin-left:2em\"><h3 style=\"margin:0\">–æ–¥–æ–±—Ä–µ–Ω–∏–µ —Å–¥–µ–ª–æ–∫ –ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:</h3><BR><div style=\"margin-top:0.2em; margin-left:2em; font-size:14px\">\"...<span style=\"background:rgb(76,146,84)\">–æ–¥–æ–±—Ä–µ–Ω–∏–µ </span><span style=\"background:rgb(76,239,84)\">—Å–¥–µ–ª–æ–∫ </span><span style=\"background:rgb(76,123,84)\">–æ </span><span style=\"background:rgb(76,158,84)\">–ø–µ—Ä–µ–¥–∞—á–µ </span><span style=\"background:rgb(76,238,84)\">–∏–º—É—â–µ—Å—Ç–≤–∞ </span><span style=\"background:rgb(76,121,84)\">–û–±—â–µ—Å—Ç–≤–∞ </span><span style=\"background:rgb(76,120,84)\">–≤ </span><span style=\"background:rgb(76,164,84)\">–±–µ–∑–≤–æ–∑–º–µ–∑–¥–Ω–æ–µ </span><span style=\"background:rgb(76,128,84)\">–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ </span><span style=\"background:rgb(76,124,84)\">–∏–ª–∏ </span><span style=\"background:rgb(76,147,84)\">–¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ </span><span style=\"background:rgb(76,119,84)\">—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ </span><span style=\"background:rgb(76,118,84)\">, </span><span style=\"background:rgb(76,243,84)\">—Å–¥–µ–ª–æ–∫ </span><span style=\"background:rgb(76,247,84)\">–¥–∞—Ä–µ–Ω–∏—è </span><span style=\"background:rgb(76,222,84)\">, </span><span style=\"background:rgb(76,255,158)\">–ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏–π </span><span style=\"background:rgb(76,130,84)\">, </span><span style=\"background:rgb(76,247,84)\">—Å–¥–µ–ª–æ–∫ </span><span style=\"background:rgb(76,129,84)\">, </span><span style=\"background:rgb(76,124,84)\">—Å–≤—è–∑–∞–Ω–Ω—ã—Ö </span><span style=\"background:rgb(76,124,84)\">—Å </span><span style=\"background:rgb(76,226,84)\">–±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é </span><span style=\"background:rgb(76,122,84)\">; </span> ...\"</div><h3 style=\"margin:0\">—Ä–µ—à–µ–Ω–∏—è –æ –ø–æ—Ä–æ–≥–æ–≤—ã—Ö —Å—É–º–º–∞—Ö:</h3><div style=\"color:red\">–ü–æ—Ä–æ–≥–æ–≤—ã–µ —Å—É–º–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω—ã</div></div><hr style=\"margin-top: 45px\"><h2 style=\"color:blue; padding:0; margin:0\">–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä</h2><div style=\"margin-left:2em\"><h3 style=\"margin:0\">–æ–¥–æ–±—Ä–µ–Ω–∏–µ —Å–¥–µ–ª–æ–∫ –ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:</h3><div>–Ω–µ –≤—ã—è–≤–ª–µ–Ω–æ</div><h3 style=\"margin:0\">—Ä–µ—à–µ–Ω–∏—è –æ –ø–æ—Ä–æ–≥–æ–≤—ã—Ö —Å—É–º–º–∞—Ö:</h3><div style=\"color:red\">–ü–æ—Ä–æ–≥–æ–≤—ã–µ —Å—É–º–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω—ã</div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3 style=\"margin:0\">–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞</h3><ul><li> –£–¢–í–ï–†–ñ–î–ï–ù. <sup>line 0</sup></li><li> –£ –° –¢ –ê –í. <sup>line 16</sup></li><li> –°—Ç–∞—Ç—å—è 1. –û–±—â–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è <sup>line 39</sup></li><li> –°—Ç–∞—Ç—å—è 2. –§–∏—Ä–º–µ–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏ –º–µ—Å—Ç–æ –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞ <sup>line 45</sup></li><li> –°—Ç–∞—Ç—å—è 3. –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π —Å—Ç–∞—Ç—É—Å –û–±—â–µ—Å—Ç–≤–∞ <sup>line 53</sup></li><li> –°—Ç–∞—Ç—å—è 4. –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –û–±—â–µ—Å—Ç–≤–∞ <sup>line 69</sup></li><li> –°—Ç–∞—Ç—å—è 5. –§–∏–ª–∏–∞–ª—ã –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞, –¥–æ—á–µ—Ä–Ω–∏–µ –∏ –∑–∞–≤–∏—Å–∏–º—ã–µ –æ–±—â–µ—Å—Ç–≤–∞ <sup>line 75</sup></li><li> –°—Ç–∞—Ç—å—è 6. –¶–µ–ª—å —Å–æ–∑–¥–∞–Ω–∏—è –∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –≤–∏–¥—ã –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 84</sup></li><li> –°—Ç–∞—Ç—å—è 8. –û–±–ª–∏–≥–∞—Ü–∏–∏ –∏ –∏–Ω—ã–µ —ç–º–∏—Å—Å–∏–æ–Ω–Ω—ã–µ —Ü–µ–Ω–Ω—ã–µ –±—É–º–∞–≥–∏ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 116</sup></li><li> –°—Ç–∞—Ç—å—è 9. –ü—Ä–∞–≤–∞ –∏ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 120</sup></li><li> –°—Ç–∞—Ç—å—è 10. –§–æ–Ω–¥—ã –û–±—â–µ—Å—Ç–≤–∞ <sup>line 137</sup></li><li> –°—Ç–∞—Ç—å—è 11. –î–∏–≤–∏–¥–µ–Ω–¥—ã –û–±—â–µ—Å—Ç–≤–∞ <sup>line 143</sup></li><li> –°—Ç–∞—Ç—å—è 12. –û—Ä–≥–∞–Ω—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è <sup>line 152</sup></li><li> –°—Ç–∞—Ç—å—è 13. –û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 158</sup></li><li> –°—Ç–∞—Ç—å—è 14. –ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 169</sup></li><li> –°—Ç–∞—Ç—å—è 15. –†–µ—à–µ–Ω–∏—è –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 199</sup></li><li> –°—Ç–∞—Ç—å—è 16. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –ø–æ–≤–µ—Å—Ç–∫—É –¥–Ω—è, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–∏ –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 206</sup></li><li> –°—Ç–∞—Ç—å—è 17. –£—á–∞—Å—Ç–∏–µ –∏ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ –Ω–∞ –û–±—â–µ–º —Å–æ–±—Ä–∞–Ω–∏–∏ –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤, –ø—Ä–æ—Ç–æ–∫–æ–ª –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 223</sup></li><li> –°—Ç–∞—Ç—å—è 18. –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 234</sup></li><li> –°—Ç–∞—Ç—å—è 19. –ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 243</sup></li><li> –°—Ç–∞—Ç—å—è 20. –ü—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—å –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤, –°–µ–∫—Ä–µ—Ç–∞—Ä—å –∑–∞—Å–µ–¥–∞–Ω–∏—è –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –∏ –°–µ–∫—Ä–µ—Ç–∞—Ä—å –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 324</sup></li><li> –°—Ç–∞—Ç—å—è 21. –ó–∞—Å–µ–¥–∞–Ω–∏—è –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 348</sup></li><li> –°—Ç–∞—Ç—å—è 22. –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –û–±—â–µ—Å—Ç–≤–∞ <sup>line 364</sup></li><li> –°—Ç–∞—Ç—å—è 23. –ü–æ—Ä—è–¥–æ–∫ –æ—Ç—á—É–∂–¥–µ–Ω–∏—è –∞–∫—Ü–∏–π –û–±—â–µ—Å—Ç–≤–∞. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–∏ —Å–¥–µ–ª–æ–∫ —Å –∞–∫—Ü–∏—è–º–∏ –û–±—â–µ—Å—Ç–≤–∞. <sup>line 408</sup></li><li> –°—Ç–∞—Ç—å—è 24. –†–µ–≤–∏–∑–∏–æ–Ω–Ω–∞—è –∫–æ–º–∏—Å—Å–∏—è –û–±—â–µ—Å—Ç–≤–∞ <sup>line 426</sup></li><li> –°—Ç–∞—Ç—å—è 25. –î–µ–π—Å—Ç–≤–∏–µ –£—Å—Ç–∞–≤–∞ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 453</sup></li><li> 11 <sup>line 463</sup></li></ul>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "olVwh_GqMs52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0b93bc2c-893b-4529-d4b4-7e7564427981"
      },
      "cell_type": "code",
      "source": [
        "# GLOBALS__['renderer'].render_charter_parsing_results(_CTX.doc, _CTX.org, _CTX.constraints, _CTX.charity_constraints)\n",
        "_CTX.charity_constraints\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'head.directors': [<legal_docs.PatternSearchResult at 0x7f275cdf6c50>],\n",
              " 'head.gen': []}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "7OFOIGEs5pZC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1232
        },
        "outputId": "39d130ef-91e2-47eb-aa5a-a85cc76a3095"
      },
      "cell_type": "code",
      "source": [
        "# del(GLOBALS__['_init_the_code'] )\n",
        "_init_the_code(True)\n",
        "GLOBALS__['renderer'].render_charter_parsing_results(_CTX.doc, _CTX.org, _CTX.constraints, _CTX.charity_constraints)\n",
        "GLOBALS__['renderer'].render_contents(_CTX.doc)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚ù§Ô∏è DONE initializing the code\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"background:#eeeeff; padding:0.5em\"> recognized NE(s): <br><br> org type:<h3 style=\"margin:0\">  –ê–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ –æ–±—â–µ—Å—Ç–≤–æ </h3>org full name:<h2 style=\"margin:0\">  ¬´ –ú–µ—Å—Å–æ—è—Ö–∞–Ω–µ—Ñ—Ç–µ–≥–∞–∑ ¬ª </h2> <br>quote: <div style=\"font-size:90%; background:white\"><span title=\"0 0.1457\" style=\"background-color:#cad8ef\">–°—Ç–∞—Ç—å—è </span><span title=\"1 0.1226\" style=\"background-color:#c5d6f2\">2 </span><span title=\"2 0.2460\" style=\"background-color:#dcdddd\">. </span><span title=\"3 0.3233\" style=\"background-color:#e9d5cb\">–§–∏—Ä–º–µ–Ω–Ω–æ–µ </span><span title=\"4 0.2576\" style=\"background-color:#dedcdb\">–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ </span><span title=\"5 0.2362\" style=\"background-color:#dadce0\">–∏ </span><span title=\"6 0.2136\" style=\"background-color:#d6dce4\">–º–µ—Å—Ç–æ </span><span title=\"7 0.2360\" style=\"background-color:#dadce0\">–Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è </span><span title=\"8 0.2545\" style=\"background-color:#dddcdc\">–û–±—â–µ—Å—Ç–≤–∞ </span><span title=\"9 0.1467\" style=\"background-color:#cad8ef\">\n",
              " </span><br><span title=\"10 0.2656\" style=\"background-color:#dfdbd9\">\n",
              " </span><br><span title=\"11 0.3396\" style=\"background-color:#ebd3c6\">–§–∏—Ä–º–µ–Ω–Ω–æ–µ </span><span title=\"12 0.3548\" style=\"background-color:#edd2c3\">–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ </span><span title=\"13 0.2697\" style=\"background-color:#e0dbd8\">–û–±—â–µ—Å—Ç–≤–∞ </span><span title=\"14 0.1788\" style=\"background-color:#cfdaea\">–Ω–∞ </span><span title=\"15 0.1951\" style=\"background-color:#d3dbe7\">—Ä—É—Å—Å–∫–æ–º </span><span title=\"16 0.1795\" style=\"background-color:#cfdaea\">—è–∑—ã–∫–µ </span><span title=\"17 0.1414\" style=\"background-color:#c9d7f0\">: </span><span title=\"18 0.2064\" style=\"background-color:#d5dbe5\">\n",
              " </span><br><span title=\"19 0.2883\" style=\"background-color:#e3d9d3\">–ø–æ–ª–Ω–æ–µ </span><span title=\"20 0.3204\" style=\"background-color:#e9d5cb\">—Ñ–∏—Ä–º–µ–Ω–Ω–æ–µ </span><span title=\"21 0.2637\" style=\"background-color:#dfdbd9\">–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ </span><span title=\"22 0.5068\" style=\"background-color:#f7b79b\">‚Äì </span><span title=\"23 0.6274\" style=\"background-color:#f4987a\">–ê–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ </span><span title=\"24 0.3393\" style=\"background-color:#ebd3c6\">–æ–±—â–µ—Å—Ç–≤–æ </span><span title=\"25 0.1300\" style=\"background-color:#c6d6f1\">\n",
              " </span><br><span title=\"26 0.1938\" style=\"background-color:#d3dbe7\">¬´ </span><span title=\"27 0.2063\" style=\"background-color:#d5dbe5\">–ú–µ—Å—Å–æ—è—Ö–∞–Ω–µ—Ñ—Ç–µ–≥–∞–∑ </span><span title=\"28 0.1460\" style=\"background-color:#cad8ef\">¬ª </span><span title=\"29 0.1654\" style=\"background-color:#cdd9ec\">; </span><span title=\"30 0.2461\" style=\"background-color:#dcdddd\">\n",
              " </span><br><span title=\"31 0.3206\" style=\"background-color:#e9d5cb\">—Å–æ–∫—Ä–∞—â–µ–Ω–Ω–æ–µ </span><span title=\"32 0.3406\" style=\"background-color:#ebd3c6\">—Ñ–∏—Ä–º–µ–Ω–Ω–æ–µ </span><span title=\"33 0.2799\" style=\"background-color:#e2dad5\">–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ </span><span title=\"34 0.5208\" style=\"background-color:#f7b396\">‚Äì </span><span title=\"35 0.6427\" style=\"background-color:#f39475\">–ê–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ </span><span title=\"36 0.3222\" style=\"background-color:#e9d5cb\">–û–±—â–µ—Å—Ç–≤–æ </span><span title=\"37 0.1966\" style=\"background-color:#d3dbe7\">¬´ </span><span title=\"38 0.2011\" style=\"background-color:#d4dbe6\">–ú–µ—Å—Å–æ—è—Ö–∞–Ω–µ—Ñ—Ç–µ–≥–∞–∑ </span><span title=\"39 0.1223\" style=\"background-color:#c5d6f2\">¬ª </span><span title=\"40 0.1353\" style=\"background-color:#c7d7f0\">. </span><span title=\"41 0.2157\" style=\"background-color:#d7dce3\">\n",
              " </span><br><span title=\"42 0.2072\" style=\"background-color:#d5dbe5\">–ú–µ—Å—Ç–æ </span><span title=\"43 0.2473\" style=\"background-color:#dcdddd\">–Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è </span><span title=\"44 0.2850\" style=\"background-color:#e2dad5\">–û–±—â–µ—Å—Ç–≤–∞ </span><span title=\"45 0.2482\" style=\"background-color:#dcdddd\">: </span><span title=\"46 0.2788\" style=\"background-color:#e1dad6\">–†–æ—Å—Å–∏–π—Å–∫–∞—è </span><span title=\"47 0.2412\" style=\"background-color:#dbdcde\">–§–µ–¥–µ—Ä–∞—Ü–∏—è </span><span title=\"48 0.2057\" style=\"background-color:#d5dbe5\">, </span><span title=\"49 0.2132\" style=\"background-color:#d6dce4\">–¢—é–º–µ–Ω—Å–∫–∞—è </span><span title=\"50 0.1921\" style=\"background-color:#d3dbe7\">–æ–±–ª–∞—Å—Ç—å </span><span title=\"51 0.2194\" style=\"background-color:#d7dce3\">, </span><span title=\"52 0.2512\" style=\"background-color:#dddcdc\">–Ø–º–∞–ª–æ-–ù–µ–Ω–µ—Ü–∫–∏–π </span><span title=\"53 0.2421\" style=\"background-color:#dbdcde\">–∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π </span><span title=\"54 0.1803\" style=\"background-color:#d1dae9\">–æ–∫—Ä—É–≥ </span><span title=\"55 0.1480\" style=\"background-color:#cad8ef\">, </span><span title=\"56 0.1510\" style=\"background-color:#cbd8ee\">–≥–æ—Ä–æ–¥ </span><span title=\"57 0.1440\" style=\"background-color:#c9d7f0\">–ù–æ–≤—ã–π </span><span title=\"58 0.1411\" style=\"background-color:#c9d7f0\">–£—Ä–µ–Ω–≥–æ–π </span><span title=\"59 0.1423\" style=\"background-color:#c9d7f0\">. </span><span title=\"60 0.1289\" style=\"background-color:#c6d6f1\">\n",
              " </span><br><span title=\"61 0.1177\" style=\"background-color:#c4d5f3\">\n",
              " </span><br></div> </div><hr style=\"margin-top: 45px\"><h2 style=\"color:crimson; padding:0; margin:0\">–°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤</h2><div style=\"margin-left:2em\"><h3 style=\"margin:0\">–æ–¥–æ–±—Ä–µ–Ω–∏–µ —Å–¥–µ–ª–æ–∫ –ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:</h3><BR><div style=\"margin-top:0.2em; margin-left:2em; font-size:14px\">\"...<span style=\"background:rgb(76,146,84)\">–æ–¥–æ–±—Ä–µ–Ω–∏–µ </span><span style=\"background:rgb(76,239,84)\">—Å–¥–µ–ª–æ–∫ </span><span style=\"background:rgb(76,123,84)\">–æ </span><span style=\"background:rgb(76,158,84)\">–ø–µ—Ä–µ–¥–∞—á–µ </span><span style=\"background:rgb(76,238,84)\">–∏–º—É—â–µ—Å—Ç–≤–∞ </span><span style=\"background:rgb(76,121,84)\">–û–±—â–µ—Å—Ç–≤–∞ </span><span style=\"background:rgb(76,120,84)\">–≤ </span><span style=\"background:rgb(76,164,84)\">–±–µ–∑–≤–æ–∑–º–µ–∑–¥–Ω–æ–µ </span><span style=\"background:rgb(76,128,84)\">–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ </span><span style=\"background:rgb(76,124,84)\">–∏–ª–∏ </span><span style=\"background:rgb(76,147,84)\">–¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ </span><span style=\"background:rgb(76,119,84)\">—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ </span><span style=\"background:rgb(76,118,84)\">, </span><span style=\"background:rgb(76,243,84)\">—Å–¥–µ–ª–æ–∫ </span><span style=\"background:rgb(76,247,84)\">–¥–∞—Ä–µ–Ω–∏—è </span><span style=\"background:rgb(76,222,84)\">, </span><span style=\"background:rgb(76,255,158)\">–ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏–π </span><span style=\"background:rgb(76,130,84)\">, </span><span style=\"background:rgb(76,247,84)\">—Å–¥–µ–ª–æ–∫ </span><span style=\"background:rgb(76,129,84)\">, </span><span style=\"background:rgb(76,124,84)\">—Å–≤—è–∑–∞–Ω–Ω—ã—Ö </span><span style=\"background:rgb(76,124,84)\">—Å </span><span style=\"background:rgb(76,226,84)\">–±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é </span><span style=\"background:rgb(76,122,84)\">; </span> ...\"</div><h3 style=\"margin:0\">—Ä–µ—à–µ–Ω–∏—è –æ –ø–æ—Ä–æ–≥–æ–≤—ã—Ö —Å—É–º–º–∞—Ö:</h3><div style=\"color:red\">–ü–æ—Ä–æ–≥–æ–≤—ã–µ —Å—É–º–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω—ã</div></div><hr style=\"margin-top: 45px\"><h2 style=\"color:blue; padding:0; margin:0\">–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä</h2><div style=\"margin-left:2em\"><h3 style=\"margin:0\">–æ–¥–æ–±—Ä–µ–Ω–∏–µ —Å–¥–µ–ª–æ–∫ –ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:</h3><div>–Ω–µ –≤—ã—è–≤–ª–µ–Ω–æ</div><h3 style=\"margin:0\">—Ä–µ—à–µ–Ω–∏—è –æ –ø–æ—Ä–æ–≥–æ–≤—ã—Ö —Å—É–º–º–∞—Ö:</h3><div style=\"color:red\">–ü–æ—Ä–æ–≥–æ–≤—ã–µ —Å—É–º–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω—ã</div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3 style=\"margin:0\">–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞</h3><ul><li> –£–¢–í–ï–†–ñ–î–ï–ù. <sup>line 0</sup></li><li> –£ –° –¢ –ê –í. <sup>line 16</sup></li><li> –°—Ç–∞—Ç—å—è 1. –û–±—â–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è <sup>line 39</sup></li><li> –°—Ç–∞—Ç—å—è 2. –§–∏—Ä–º–µ–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏ –º–µ—Å—Ç–æ –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞ <sup>line 45</sup></li><li> –°—Ç–∞—Ç—å—è 3. –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π —Å—Ç–∞—Ç—É—Å –û–±—â–µ—Å—Ç–≤–∞ <sup>line 53</sup></li><li> –°—Ç–∞—Ç—å—è 4. –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –û–±—â–µ—Å—Ç–≤–∞ <sup>line 69</sup></li><li> –°—Ç–∞—Ç—å—è 5. –§–∏–ª–∏–∞–ª—ã –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞, –¥–æ—á–µ—Ä–Ω–∏–µ –∏ –∑–∞–≤–∏—Å–∏–º—ã–µ –æ–±—â–µ—Å—Ç–≤–∞ <sup>line 75</sup></li><li> –°—Ç–∞—Ç—å—è 6. –¶–µ–ª—å —Å–æ–∑–¥–∞–Ω–∏—è –∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –≤–∏–¥—ã –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 84</sup></li><li> –°—Ç–∞—Ç—å—è 8. –û–±–ª–∏–≥–∞—Ü–∏–∏ –∏ –∏–Ω—ã–µ —ç–º–∏—Å—Å–∏–æ–Ω–Ω—ã–µ —Ü–µ–Ω–Ω—ã–µ –±—É–º–∞–≥–∏ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 116</sup></li><li> –°—Ç–∞—Ç—å—è 9. –ü—Ä–∞–≤–∞ –∏ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 120</sup></li><li> –°—Ç–∞—Ç—å—è 10. –§–æ–Ω–¥—ã –û–±—â–µ—Å—Ç–≤–∞ <sup>line 137</sup></li><li> –°—Ç–∞—Ç—å—è 11. –î–∏–≤–∏–¥–µ–Ω–¥—ã –û–±—â–µ—Å—Ç–≤–∞ <sup>line 143</sup></li><li> –°—Ç–∞—Ç—å—è 12. –û—Ä–≥–∞–Ω—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è <sup>line 152</sup></li><li> –°—Ç–∞—Ç—å—è 13. –û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 158</sup></li><li> –°—Ç–∞—Ç—å—è 14. –ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 169</sup></li><li> –°—Ç–∞—Ç—å—è 15. –†–µ—à–µ–Ω–∏—è –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 199</sup></li><li> –°—Ç–∞—Ç—å—è 16. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –ø–æ–≤–µ—Å—Ç–∫—É –¥–Ω—è, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–∏ –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 206</sup></li><li> –°—Ç–∞—Ç—å—è 17. –£—á–∞—Å—Ç–∏–µ –∏ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ –Ω–∞ –û–±—â–µ–º —Å–æ–±—Ä–∞–Ω–∏–∏ –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤, –ø—Ä–æ—Ç–æ–∫–æ–ª –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 223</sup></li><li> –°—Ç–∞—Ç—å—è 18. –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 234</sup></li><li> –°—Ç–∞—Ç—å—è 19. –ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 243</sup></li><li> –°—Ç–∞—Ç—å—è 20. –ü—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—å –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤, –°–µ–∫—Ä–µ—Ç–∞—Ä—å –∑–∞—Å–µ–¥–∞–Ω–∏—è –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –∏ –°–µ–∫—Ä–µ—Ç–∞—Ä—å –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 324</sup></li><li> –°—Ç–∞—Ç—å—è 21. –ó–∞—Å–µ–¥–∞–Ω–∏—è –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 348</sup></li><li> –°—Ç–∞—Ç—å—è 22. –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –û–±—â–µ—Å—Ç–≤–∞ <sup>line 364</sup></li><li> –°—Ç–∞—Ç—å—è 23. –ü–æ—Ä—è–¥–æ–∫ –æ—Ç—á—É–∂–¥–µ–Ω–∏—è –∞–∫—Ü–∏–π –û–±—â–µ—Å—Ç–≤–∞. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–∏ —Å–¥–µ–ª–æ–∫ —Å –∞–∫—Ü–∏—è–º–∏ –û–±—â–µ—Å—Ç–≤–∞. <sup>line 408</sup></li><li> –°—Ç–∞—Ç—å—è 24. –†–µ–≤–∏–∑–∏–æ–Ω–Ω–∞—è –∫–æ–º–∏—Å—Å–∏—è –û–±—â–µ—Å—Ç–≤–∞ <sup>line 426</sup></li><li> –°—Ç–∞—Ç—å—è 25. –î–µ–π—Å—Ç–≤–∏–µ –£—Å—Ç–∞–≤–∞ –û–±—â–µ—Å—Ç–≤–∞ <sup>line 453</sup></li><li> 11 <sup>line 463</sup></li></ul>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9fV5mnSXciKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "22de2d3a-765a-4c9e-dc79-69b2c5e69fc9"
      },
      "cell_type": "code",
      "source": [
        "GLOBALS__['CharterAnlysingContext'].constraints['head.directors'][0].__dict__"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-027614a5b8ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGLOBALS__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CharterAnlysingContext'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'head.directors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SnsM7Qzwci1J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### tests, experiments"
      ]
    },
    {
      "metadata": {
        "id": "ycJrZCWAFEXw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  GLOBALS__['CharterAnlysingContext'].verbosity_level=2\n",
        "  org, rz = GLOBALS__['CharterAnlysingContext'].analyze_charter(text, True)\n",
        "  doc = GLOBALS__['CharterAnlysingContext'].doc\n",
        "  charity_constraints = GLOBALS__['CharterAnlysingContext'].charity_constraints\n",
        "  org = GLOBALS__['CharterAnlysingContext'].org\n",
        "\n",
        "\n",
        "  GLOBALS__['renderer'].render_contents(doc)\n",
        "  GLOBALS__['renderer'].render_charter_parsing_results(doc, org, rz)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J_CqKEG514Xf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JVPCRaSAmYHt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## üëû Constraint type detection"
      ]
    },
    {
      "metadata": {
        "id": "1r41cS5RCxcv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_lawsuit_patterns(factory):\n",
        "  def cp(name, tuples):\n",
        "    return factory.create_pattern(name, tuples)\n",
        "\n",
        "  cp('x_lawsuit_4', ('–Ω–∞—á–∞–ª–æ/—É—Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ª—é–±—ã—Ö', '—Å—É–¥–µ–±–Ω—ã—Ö', \n",
        "                '—Å–ø–æ—Ä–æ–≤, –ø–æ–¥–ø–∏—Å–∞–Ω–∏–µ –º–∏—Ä–æ–≤–æ–≥–æ —Å–æ–≥–ª–∞—à–µ–Ω–∏—è, –ø—Ä–∏–∑–Ω–∞–Ω–∏–µ –∏—Å–∫–∞, –æ—Ç–∫–∞–∑ –æ—Ç –∏—Å–∫–∞, –∞ —Ç–∞–∫–∂–µ –ª—é–±—ã–µ –¥—Ä—É–≥–∏–µ  ',\n",
        "                      ))\n",
        "\n",
        "  cp('x_lawsuit_3', ('—Å—É–¥–µ–±–Ω—ã—Ö —Å–ø–æ—Ä–æ–≤, —Ü–µ–Ω–∞ ',\n",
        "                       '–∏—Å–∫–∞',\n",
        "                       '–ø–æ –∫–æ—Ç–æ—Ä—ã–º –ø—Ä–µ–≤—ã—à–∞–µ—Ç'))\n",
        " \n",
        "  \n",
        "  \n",
        "build_lawsuit_patterns(GLOBALS__['CharterAnlysingContext'].pattern_factory)\n",
        "GLOBALS__['CharterAnlysingContext'].pattern_factory.embedd()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zDgF5nNkLZ88",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_incl_patterns(factory):\n",
        "  def cp(name, tuples):\n",
        "    return factory.create_pattern(name, tuples)\n",
        "\n",
        "  cp('x_exclusive_1', ('', '–∏—Å–∫–ª—é—á–∞—è', '—Å–¥–µ–ª–∫–∏'))\n",
        "\n",
        "  cp('x_inclusive_1', ('', '–≤–∫–ª—é—á–∞—è', '—Å–¥–µ–ª–∫–∏'))\n",
        "  \n",
        "build_incl_patterns(GLOBALS__['CharterAnlysingContext'].pattern_factory)\n",
        "GLOBALS__['CharterAnlysingContext'].pattern_factory.embedd()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EAreL6ew6Nh5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_init_the_code(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T6wc-fUn0aek",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "\n",
        "CH_CTX=GLOBALS__['CharterAnlysingContext']\n",
        "\n",
        "from charter_patterns import find_sentences_by_pattern_prefix\n",
        "\n",
        "a:dict = find_sentences_by_pattern_prefix(  CH_CTX.pattern_factory, CH_CTX._get_head_sections(), 'x_charity_')\n",
        "b:dict = find_sentences_by_pattern_prefix(  CH_CTX.pattern_factory, CH_CTX._get_head_sections(), 'sum__')\n",
        "lawsuits = find_sentences_by_pattern_prefix(  CH_CTX.pattern_factory, CH_CTX._get_head_sections(), 'x_lawsuit_')\n",
        "  \n",
        "def merge_quotes_by_head_type (a, b):\n",
        "  res={}\n",
        "  for head in a:\n",
        "    res[head] = a[head]+b[head]\n",
        "  return res\n",
        "  \n",
        "merged=merge_quotes_by_head_type(a, b)\n",
        "merged=merge_quotes_by_head_type(merged, lawsuits)\n",
        "# soft$.$at_sum__\n",
        "for head in merged:\n",
        "  print(CH_CTX.doc.sections[head].body.distances_per_pattern_dict.keys())\n",
        "  html = GLOBALS__['renderer'].html_charity_constraints_by_head(merged[head] )\n",
        "  display(HTML(html))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JQWRoJf_OfS7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "\n",
        "CH_CTX=GLOBALS__['CharterAnlysingContext']\n",
        "\n",
        "from charter_patterns import find_sentences_by_pattern_prefix\n",
        "lawsuits = find_sentences_by_pattern_prefix( CH_CTX.pattern_factory, CH_CTX._get_head_sections(), 'x_lawsuit_')\n",
        "  \n",
        " \n",
        "  \n",
        "# soft$.$at_sum__\n",
        "for head in lawsuits:\n",
        "  print(CH_CTX.doc.sections[head].body.distances_per_pattern_dict.keys())\n",
        "  html = GLOBALS__['renderer'].html_charity_constraints_by_head(lawsuits[head] )\n",
        "  display(HTML(html))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WlTMYsBgPMG0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from legal_docs import PatternSearchResults, PatternSearchResult\n",
        "def substract_search_results(a:PatternSearchResults, b:PatternSearchResults):\n",
        "  b_indexes = [ x.region.start for x in b]\n",
        "  result=[]\n",
        "  for x in a:\n",
        "    if x.region.start not in b_indexes:\n",
        "      result.append(x)\n",
        "  return result\n",
        "  \n",
        "# for head in lawsuits:\n",
        "#   rest = substract_search_results(merged, lawsuits)\n",
        "\n",
        "from transaction_values import complete_re\n",
        "from text_tools import untokenize, tokenize_text\n",
        "from legal_docs import extract_sum_and_sign_3\n",
        "import re\n",
        "\n",
        "def tokens_before_index(string, index):\n",
        "  return len(string[:index].split(' '))\n",
        "  \n",
        "for head in lawsuits:\n",
        "\n",
        "  rest = substract_search_results(merged[head], lawsuits[head])\n",
        "  \n",
        "  html = GLOBALS__['renderer'].html_charity_constraints_by_head(rest)\n",
        "  \n",
        "#   def tokens_before_index(sting, index):\n",
        "  for sr in rest:\n",
        "    \n",
        "    \n",
        "    sentence = ' '.join(sr.tokens)\n",
        "    all = [slice(m.start(0), m.end(0)) for m in re.finditer(complete_re, sentence)]\n",
        "    for a in all:\n",
        "      print (tokens_before_index(sentence, a.start),'from',sentence[a])\n",
        "      \n",
        "      \n",
        "      \n",
        "      token_index_s = tokens_before_index(sentence, a.start) - 1\n",
        "      token_index_e = tokens_before_index(sentence, a.stop)  \n",
        "      \n",
        "      slice_=slice(token_index_s, token_index_e)\n",
        "      print(\"token:\", slice_)\n",
        "      \n",
        "      vc = extract_sum_and_sign_3(sr, slice_)\n",
        "      print(vc.value)\n",
        "#       finds = complete_re.search(sentence)\n",
        "#       if finds is not None:\n",
        "#         print(   )\n",
        "# #         print(len(finds) )\n",
        "# #         for find in finds:\n",
        "\n",
        "\n",
        "#         print('--')\n",
        "  \n",
        "  \n",
        "  \n",
        "#   complete_re.search(sentence)\n",
        "\n",
        "  display(HTML(html))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6C5LhlUp0Jln",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from legal_docs import ConstraintsSearchResult\n",
        "from IPython.core.display import display, HTML\n",
        "from renderer import as_quote, to_multicolor_text\n",
        "\n",
        "v_color_map = {\n",
        "    'deal_value_attention_vector': (1, 0.0, 0.5),\n",
        "    'soft$.$at_sum__': (0.9, 0.5, 0.0),\n",
        "    '$at_sum__': (0.9, 0, 0.1),\n",
        "    'soft$.$at_d_order_':   (0.0, 0.3, 0.9),\n",
        "    '$at_x_charity_': (0.0, 0.9, 0.3),\n",
        "    'soft$.$at_x_charity_': (0.0, 1.0, 0.0),\n",
        "      \n",
        "    'soft$.$at_x_lawsuit_': (0.8, 0, 0.7),\n",
        "    '$at_x_lawsuit_': (0.9, 0, 0.9),\n",
        "  }\n",
        "\n",
        "def _render_sentence(self, sentence: ConstraintsSearchResult):\n",
        "  html = \"\"\n",
        "  constraints: List[ValueConstraint] = sentence.constraints\n",
        "\n",
        "  html += \"<br>\"\n",
        "  for probable_v in constraints:\n",
        "    html += self.value_to_html(probable_v.value)\n",
        "\n",
        "  if len(constraints) > 0:\n",
        "    html += '<div style=\"border-bottom:1px solid #ccc; margin-top:1em\"></div>'\n",
        "    search_result:PatternSearchResult = sentence.subdoc\n",
        "\n",
        "    v = {\n",
        "      search_result.attention_vector_name:search_result.get_attention (),\n",
        "\n",
        "      '$at_sum__': search_result.get_attention ('$at_sum__'),\n",
        "      '$at_x_lawsuit_': search_result.get_attention('soft$.$at_x_lawsuit_'),\n",
        "      '$at_x_charity_': search_result.get_attention('soft$.$at_x_charity_')\n",
        "    }\n",
        "    min_color = (0.3, 0.3, 0.33)\n",
        "    html += as_quote(to_multicolor_text(search_result.tokens, v,\n",
        "                                          v_color_map,\n",
        "                                          min_color=min_color,\n",
        "                                          _slice=None))\n",
        "\n",
        "  return html\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "CH_CTX=GLOBALS__['CharterAnlysingContext']\n",
        "CH_CTX.constraints['head.all']\n",
        "\n",
        "for sentence in CH_CTX.constraints['head.all']:\n",
        "  html =_render_sentence(GLOBALS__['renderer'], sentence)\n",
        "  display(HTML(html))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2qD6gSJ_1rQH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from legal_docs import calculate_distances_per_pattern\n",
        "from ml_tools import *\n",
        "from patterns import *\n",
        "\n",
        "#XXX: renamed from find_charity_sentences\n",
        "\n",
        "\n",
        "  \n",
        " \n",
        "\n",
        "###-----test\n",
        "CH_CTX=GLOBALS__['CharterAnlysingContext']\n",
        "renderer = GLOBALS__['renderer']\n",
        "charter = CH_CTX.doc\n",
        "section = charter.sections['head.directors'].body\n",
        "\n",
        "\n",
        "slices1, attention_v_name_consent = find_sentences_by_pattern_prefix (section, CH_CTX.pattern_factory, pattern_prefix='d_order_consent')\n",
        "slices2, attention_v_name_charity = find_sentences_by_pattern_prefix (section, CH_CTX.pattern_factory, pattern_prefix='x_charity')\n",
        "slices3, attention_v_name_law = find_sentences_by_pattern_prefix (section, CH_CTX.pattern_factory, pattern_prefix='x_lawsuit_')\n",
        "slices4, attention_v_currency = find_sentences_by_pattern_prefix (section, CH_CTX.pattern_factory, pattern_prefix='currency')\n",
        "\n",
        "\n",
        "attention_incl,_ = make_attention_vector(section, CH_CTX.pattern_factory, 'x_inclusive')\n",
        "attention_excl,_ = make_attention_vector(section, CH_CTX.pattern_factory, 'x_exclusive')\n",
        "\n",
        "attention_excl=momentum(attention_excl, 0.9)\n",
        "\n",
        "colormap = {\n",
        "    'red':(1,0,0),\n",
        "    'red1':(1,0.4,0),\n",
        "    'green':(0,1,0),\n",
        "    'blue':(0,0,1),\n",
        "    'cyan':(0,0.7,1),\n",
        "    'yellow':(0.9,0.8,0)\n",
        "}\n",
        "\n",
        "alltogether={}\n",
        "def merge_slices(slices1):\n",
        "  for _slice in slices1:\n",
        "    alltogether[_slice [0].start] = _slice\n",
        "    ss=section.subdoc_slice( _slice [0] )\n",
        "\n",
        "merge_slices(slices1)\n",
        "merge_slices(slices3)\n",
        "merge_slices(slices2)\n",
        "merge_slices(slices4)\n",
        "\n",
        "ssss=[]\n",
        "for k in alltogether:\n",
        "  _slice=alltogether[k]\n",
        "#   print(_slice)\n",
        "  ss=section.subdoc_slice( _slice [0] )\n",
        "  vectors = {\n",
        "    'red':ss.distances_per_pattern_dict['soft$.'+attention_v_name_law],\n",
        "    'cyan':ss.distances_per_pattern_dict['soft$.'+attention_v_name_charity],\n",
        "#     'green':ss.distances_per_pattern_dict['soft$.'+attention_v_name_consent],\n",
        "    'red1':ss.distances_per_pattern_dict['soft$.'+attention_v_currency],\n",
        "      \n",
        "    'yellow':attention_incl[_slice [0] ],\n",
        "    'green':attention_excl[_slice [0] ],\n",
        "  }\n",
        "  ssss.append(ss)\n",
        "#   print (ss.tokens_cc)\n",
        "  renderer.render_multicolor_text(ss.tokens_cc, vectors, colormap=colormap)\n",
        "#   renderer.render_color_text(ss.tokens, vectors['red'])\n",
        "del ssss\n",
        "# print (slices)\n",
        "# print(section.distances_per_pattern_dict)\n",
        "# vectors['red']\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML('ddd'))\n",
        "GLOBALS__['renderer'].__dict__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s0XY6kIFS2X8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# contract value: 5\n",
        "  \n",
        "# directors:{\n",
        "    \n",
        "#     [4, 6]: True\n",
        "#     [6, 20]: False\n",
        "#     [2, inf]: True\n",
        "#     [-inf, 4]: False\n",
        "    \n",
        "# } ==> True | False | True | False ===> True\n",
        "  \n",
        "  \n",
        "  \n",
        "# all:{    \n",
        "#     [6, inf]: False\n",
        "#     [6, 20]: False\n",
        "#     [2, inf]: True\n",
        "#     [-inf, 4]: False\n",
        "    \n",
        "# } ==> True | False | True | False ===> True\n",
        "  \n",
        "  \n",
        "# for level in OrgLevel:\n",
        "#   for constraint in OrgLevel.constraints:\n",
        "#     if contract.value in range(constraint.min, constraint.max) \n",
        "#       if constraint.subj == contract.subj\n",
        "#         raise RedFlag('–∞ —á–æ –ø—Ä–æ—Ç–æ–∫–æ–ª-—Ç–æ –µ—Å—Ç—å?')\n",
        "\n",
        "# if contract.value > max ( every constraint.max)\n",
        "#    raise RedFlag('—á—Ç–æ-—Ç–æ –Ω–µ —Ç–∞–∫')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gEM5XvFcA_J-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Charitiy finder"
      ]
    },
    {
      "metadata": {
        "id": "PhCbZyLYiBnz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_charity_patterns(factory):\n",
        "  def cp(name, tuples):\n",
        "    return factory.create_pattern(name, tuples)\n",
        "\n",
        "  cp('x_charity_1', ('–¥–æ–≥–æ–≤–æ—Ä',\n",
        "                     '–±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ',\n",
        "                     '–ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏—è'))\n",
        "\n",
        "  cp('x_charity_1.1', ('–æ–¥–æ–±—Ä–µ–Ω–∏–µ –≤–Ω–µ—Å–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–æ–º –∫–∞–∫–∏—Ö-–ª–∏–±–æ –≤–∫–ª–∞–¥–æ–≤ –∏–ª–∏ –ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏–π –Ω–∞ –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏–ª–∏',\n",
        "                       '–±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ',\n",
        "                       '—Ü–µ–ª–∏'))\n",
        "\n",
        "  cp('x_charity_1.2', ('–æ–¥–æ–±—Ä–µ–Ω–∏–µ –≤–Ω–µ—Å–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–æ–º –∫–∞–∫–∏—Ö-–ª–∏–±–æ –≤–∫–ª–∞–¥–æ–≤ –∏–ª–∏',\n",
        "                       '–ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏–π',\n",
        "                       '–Ω–∞ –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏–ª–∏ –±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ü–µ–ª–∏ '))\n",
        "\n",
        "  cp('x_charity_2', ('–ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ',\n",
        "                     '–±–µ–∑–≤–æ–∑–º–µ–∑–¥–Ω–æ–π',\n",
        "                     '–ø–æ–º–æ—â–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π')),\n",
        "\n",
        "  cp('x_charity_3', ('—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ —Å–¥–µ–ª–æ–∫',\n",
        "                     ' –¥–∞—Ä–µ–Ω–∏—è ',\n",
        "                     ' '))\n",
        "\n",
        "\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from legal_docs import calculate_distances_per_pattern\n",
        "from ml_tools import filter_values_by_key_prefix, max_exclusive_pattern, relu\n",
        "from patterns import improve_attention_vector\n",
        "from text_tools import get_sentence_bounds_at_index\n",
        "\n",
        "\n",
        "def find_charity_constraints(doc, factory, head_sections:dict ) -> dict:\n",
        "  charity_quotes_by_head_type = {}\n",
        "  for section_name in head_sections:\n",
        "\n",
        "    # section_name = section_prefix + head\n",
        "    # print(head, '->', section_name)\n",
        "    if section_name in doc.sections:\n",
        "      subdoc = doc.sections[section_name].body\n",
        "      # subdoc.calculate_distances_per_pattern(TFAA)\n",
        "\n",
        "      print(section_name)\n",
        "      bounds = find_charity_sentences(subdoc, factory)\n",
        "      charity_quotes_by_head_type[section_name] = bounds\n",
        "\n",
        "      # print('ok')\n",
        "  return charity_quotes_by_head_type\n",
        "\n",
        "\n",
        "def find_charity_sentences(subdoc, factory) -> List:\n",
        "  \"\"\"\n",
        "    returns list of tuples (slice, confidence, summa-of-attention-)\n",
        "  \"\"\"\n",
        "\n",
        "  calculate_distances_per_pattern(subdoc, factory, merge=True, pattern_prefix='x_charity_')\n",
        "\n",
        "  slices = []\n",
        "  vectors = filter_values_by_key_prefix(subdoc.distances_per_pattern_dict, 'x_charity_')\n",
        "  vectors_i = []\n",
        "  for v in vectors:\n",
        "    if max(v) > 0.6:\n",
        "      vector_i, _ = improve_attention_vector(subdoc.embeddings, v, relu_th=0.6, mix=0.9)\n",
        "      vectors_i.append(vector_i)\n",
        "    else:\n",
        "      vectors_i.append(v)\n",
        "\n",
        "  x = max_exclusive_pattern(vectors_i)\n",
        "  x = relu(x, 0.8)\n",
        "  subdoc.distances_per_pattern_dict['$at_x_charity_'] = x\n",
        "\n",
        "  dups = {}\n",
        "  for i in np.nonzero(x)[0]:\n",
        "    bounds = get_sentence_bounds_at_index(i, subdoc.tokens)\n",
        "\n",
        "    if bounds[0] not in dups:\n",
        "      sl = slice(bounds[0], bounds[1])\n",
        "      sum_ = sum(x[sl])\n",
        "      confidence = 'x'\n",
        "      #       confidence = np.mean( np.nonzero(x[sl]) )\n",
        "      nonzeros_count = len(np.nonzero(x[sl])[0])\n",
        "      print('nonzeros_count=', nonzeros_count)\n",
        "      confidence = 0\n",
        "\n",
        "      if nonzeros_count > 0:\n",
        "        confidence = sum_ / nonzeros_count\n",
        "      print('confidence=', confidence)\n",
        "      if confidence > 0.8:\n",
        "        # GLOBALS__['renderer'].render_color_text(subdoc.tokens_cc[sl],\n",
        "        #                                         subdoc.distances_per_pattern_dict['$at_x_charity_'][sl], _range=(0, 1))\n",
        "        print(i, sum_)\n",
        "\n",
        "        slices.append((sl, confidence, sum_))\n",
        "\n",
        "      dups[bounds[0]] = True\n",
        "\n",
        "  return slices\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##---test\n",
        "\n",
        "# find_charity_constraints(self.doc, GLOBALS__['CharterAnlysingContext'].pattern_factory, self._get_head_sections())\n",
        "# GLOBALS__['CharterAnlysingContext'].\n",
        "\n",
        "charity_constraints = find_charity_constraints(doc, \n",
        "                                               GLOBALS__['CharterAnlysingContext'].pattern_factory, \n",
        "                                               GLOBALS__['CharterAnlysingContext']._get_head_sections())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QflbPNjUDQJT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Render charity constraints"
      ]
    },
    {
      "metadata": {
        "id": "AsbjbSMmDOnN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        " \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "#---CharterRenderer\n",
        "_CTX = GLOBALS__['CharterAnlysingContext']\n",
        "_cr = CharterRenderer()\n",
        "_cr.render_charter_parsing_results(_CTX.doc, _CTX.org, _CTX.constraints, _CTX.charity_constraints)\n",
        "# _cr.render_contents(_CTX.doc)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nLEZH3mDiRUm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # GLOBALS__['renderer'].render_color_text(subdoc.tokens_cc, subdoc.distances_per_pattern_dict['x_charity_1.2'], _range=(0,1))\n",
        "# # x = max_exclusive_pattern_by_prefix(subdoc.distances_per_pattern_dict, 'x_charity_')\n",
        "# import numpy as np\n",
        "# from text_tools import get_sentence_bounds_at_index\n",
        "# from ml_tools import filter_values_by_key_prefix,max_exclusive_pattern, momentum, smooth_safe, smooth, relu\n",
        "# from patterns import improve_attention_vector\n",
        "# vectors = filter_values_by_key_prefix(subdoc.distances_per_pattern_dict, 'x_charity_')\n",
        "# vectors_i=[]\n",
        "# for v in vectors:\n",
        "#   if max(v)>0.6:\n",
        "#     vector_i, _ = improve_attention_vector(subdoc.embeddings, v, relu_th=0.6, mix=0.9)\n",
        "#     vectors_i.append(vector_i)\n",
        "#   else:\n",
        "#     vectors_i.append(v)\n",
        "    \n",
        "# x = max_exclusive_pattern(vectors_i)\n",
        "# x=relu(x, 0.8)\n",
        "# i = np.argmax(x)\n",
        "# sl = slice( i-150, i+150)\n",
        "\n",
        "\n",
        "\n",
        "# dups={}\n",
        "# for i in np.nonzero(x)[0]:\n",
        "#   bounds = get_sentence_bounds_at_index( i, subdoc.tokens)\n",
        "  \n",
        "#   if bounds[0] not in dups:\n",
        "#     sl=slice(bounds[0], bounds[1])\n",
        "#     sum_ = sum(x[sl])\n",
        "\n",
        "#     if sum_ >2:\n",
        "#       GLOBALS__['renderer'].render_color_text(subdoc.tokens_cc[sl], x[sl], _range=(0,1))\n",
        "#       print(i, sum_)\n",
        "# #       yeld (bounds)\n",
        "\n",
        "#     dups[bounds[0]]=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oX4OH7NMBNUB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Miscl\n"
      ]
    },
    {
      "metadata": {
        "id": "8h2m0krc_KM4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  doc.embedd(GLOBALS__['ContractAnlysingContext'].hadlines_factory)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vUnmEKg0HE0I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  # GLOBALS__['ContractAnlysingContext'].hadlines_factory.\n",
        "\n",
        "  doc.calculate_distances_per_pattern(GLOBALS__['CharterAnlysingContext'].hadlines_factory)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jqnUuNcxHlmc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(doc.distances_per_pattern_dict.keys())\n",
        "from legal_docs import rectifyed_sum_by_pattern_prefix\n",
        "\n",
        "from ml_tools import max_exclusive_pattern_by_prefix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "vv = max_exclusive_pattern_by_prefix(doc.distances_per_pattern_dict, 'headline.name.1')\n",
        "print(vv[0:10])\n",
        "\n",
        "\n",
        "\n",
        "# GLOBALS__['renderer'].render_color_text(doc.tokens_cc, vv)\n",
        "\n",
        "for s in doc.sections:\n",
        "  print (s)\n",
        "  \n",
        "if 'head.directors' in doc.sections:\n",
        "  subdoc = doc.sections['head.directors'].body\n",
        "  for ky in subdoc.distances_per_pattern_dict:\n",
        "    print(ky)\n",
        "  GLOBALS__['renderer'].render_color_text(subdoc.tokens_cc, subdoc.distances_per_pattern_dict['deal_attention_vector'])\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Rv4ja_xLmxW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " \n",
        "\n",
        "level_by_line = [ max ( i._possible_levels) for i in doc.structure.structure ]\n",
        " \n",
        "\n",
        "\n",
        "headlines_attention_vector=[]\n",
        "for i in doc.structure.structure:\n",
        "  l = i.span[1]-i.span[0]\n",
        "  headlines_attention_vector+=[level_by_line[ i.line_number ]]*l\n",
        "  \n",
        "# print (pv[0:100])\n",
        "headlines_attention_vector = normalize(headlines_attention_vector)\n",
        "headlines_attention_vector = relu(headlines_attention_vector, 0.4)\n",
        "\n",
        "# headlines_attention_vector = smooth(headlines_attention_vector, 20)\n",
        "\n",
        "av= relu(headlines_attention_vector/2 + vv, 0.6)\n",
        "av = momentum(av, 0.99)\n",
        "\n",
        "GLOBALS__['renderer'].render_color_text(doc.tokens_cc, av)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kT3NPG52fAjK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Meta-pattern! (Cool!!(!))\n",
        "—Ç–∏–ø–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ"
      ]
    },
    {
      "metadata": {
        "id": "xUcxb8lmc1Dq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ---------\n",
        "from patterns import FuzzyPattern\n",
        "best_id=np.argmax(av)\n",
        "best_embedding_v = doc.embeddings[best_id]\n",
        "\n",
        "meta_pattern=FuzzyPattern('s-meta-na')\n",
        "meta_pattern.embeddings =  np.array([ best_embedding_v ])\n",
        "\n",
        "meta_pattern_attention = 1.0 - meta_pattern._eval_distances(doc.embeddings)\n",
        "meta_pattern_attention = relu(meta_pattern_attention,  0.7)\n",
        "\n",
        "\n",
        "GLOBALS__['renderer'].render_color_text(doc.tokens_cc, meta_pattern_attention, _range=(0,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uFctYf9efjFt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(20, 6))\n",
        "ax = plt.axes()\n",
        "span=1400\n",
        "ax.plot(meta_pattern_attention[best_id-span:best_id+span], alpha=0.5, color='green', label='meta_pattern_attention');\n",
        "ax.plot(normalize(av[best_id-span:best_id+span]), alpha=0.5, color='red', label='av');\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CsmnVkodzR7h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# step 2. –î–æ–≥–æ–≤–æ—Ä"
      ]
    },
    {
      "metadata": {
        "id": "ysQTF-wAzwtV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " \n",
        "\n",
        "uploaded = interactive_upload('–î–æ–≥–æ–≤–æ—Ä –≤ –∑–∞–∫–æ–Ω–µ')\n",
        "\n",
        "GLOBALS__['ContractAnlysingContext'].analyze_contract(uploaded[0])\n",
        "doc = GLOBALS__['ContractAnlysingContext'].contract\n",
        "\n",
        "GLOBALS__['renderer'].render_subj(doc)\n",
        "GLOBALS__['renderer'].render_contents(doc)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GnyR3dSIzUyE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# step 3. –ü–æ–∏—Å–∫ –≤—Ä–µ–¥–∞"
      ]
    },
    {
      "metadata": {
        "id": "3ob6Mmo4z5BZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "find_and_show_violations()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qo8nIebSl7rE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### subj correlations"
      ]
    },
    {
      "metadata": {
        "id": "KWXN-Ecjl_GZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(GLOBALS__['ContractAnlysingContext'].contract.sections['subj'].body.untokenize_cc())\n",
        "print(\"-\"*20)\n",
        "print(GLOBALS__['CharterAnlysingContext'].constraints['head.directors']['sentences'][1]['subdoc'].untokenize_cc())\n",
        "\n",
        "\n",
        "docA=GLOBALS__['ContractAnlysingContext'].contract.sections['subj'].body\n",
        "docB=GLOBALS__['CharterAnlysingContext'].constraints['head.directors']['sentences'][1]['subdoc']\n",
        "\n",
        "\n",
        "GLOBALS__['CharterAnlysingContext'].constraints['head.directors']['sentences'][1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TboOY5t3plhK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GLOBALS__['CharterAnlysingContext'].doc.constraints\n",
        "_init_the_code(reset=True)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PGcbxq5poBH5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from patterns import dist_mean_cosine as DF\n",
        "from text_tools import untokenize\n",
        "\n",
        "#\n",
        "# docA.embedd( GLOBALS__['CharterAnlysingContext'].pattern_factory )\n",
        "# docB.embeddings[0:10]\n",
        "# docA.embeddings = None\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def match_contract_to_charter_constraints(contract, charter, charter_constraints, charity_constraints):\n",
        "  \"\"\"\n",
        "  find best constraint to apply to Contract\n",
        "  \"\"\"\n",
        "\n",
        "  r_quotes = []\n",
        "  r_vector = []\n",
        "\n",
        "  quote_slice = slice(0, 17)\n",
        "\n",
        "  if 'subj' not in contract.sections:\n",
        "    raise ValueError(\"contract has no subject section\")\n",
        "\n",
        "  subj = contract.sections['subj'].body\n",
        "  print(subj.untokenize_cc())\n",
        "  print('------')\n",
        "  if subj.embeddings is None:\n",
        "    print(\"Subj embeddings are gone, restoring...\")\n",
        "    subj.embeddings = contract.embeddings[subj.start:subj.end]\n",
        "    #     subj.tokens = doc.tokens[subj.start:subj.end]\n",
        "    #     subj.tokens_cc = doc.tokens_cc[subj.start:subj.end]\n",
        "    #     subj.embedd( GLOBALS__['CharterAnlysingContext'].pattern_factory )\n",
        "    print('\\t\\t sample:', subj.embeddings[0][1:10])\n",
        "\n",
        "  for head_type in charter_constraints:\n",
        "\n",
        "    ##charity:\n",
        "    if head_type in charity_constraints:\n",
        "      print(f'{head_type} has charity constrinats')\n",
        "      \n",
        "      charity_constraints_by_head = charity_constraints[head_type]\n",
        "      charity_constraints_by_head_new = []\n",
        "      \n",
        "      charity_constraints['new.'+head_type] = charity_constraints_by_head_new\n",
        "      \n",
        "      for i in range(len(charity_constraints_by_head)):\n",
        "        _tuple = charity_constraints_by_head[i] \n",
        "#       for cc in charity_constraints[head_type]:\n",
        "        _slice = _tuple[0]\n",
        "        emb_charter = charter.sections[head_type].body.embeddings[_slice]\n",
        "        \n",
        "        distance = 1 - DF(emb_charter,  subj.embeddings[5:])\n",
        "        \n",
        "#         cc.add['subj_correlation'] = distance\n",
        "        \n",
        "#         detupling\n",
        "        charity_constraints_by_head_new.append ( {\n",
        "            'slice':_slice,\n",
        "            'subj_correlation': distance,\n",
        "            'confidence': _tuple[1],\n",
        "            'sum': _tuple[2]\n",
        "        })\n",
        "  \n",
        "        print('\\t'*4, 'cc=', charity_constraints_by_head_new[i])\n",
        "        \n",
        "        #         print('\\t\\t---CC', cc[0])\n",
        "        \n",
        "\n",
        "    #       GLOBALS__['CharterAnlysingContext'].doc.sections['head.directors'].body.embeddings[_slice]\n",
        "\n",
        "    ##------------------------charity end\n",
        "    print(f'measuring {head_type} constraints...'.upper())\n",
        "    cc = charter_constraints[head_type]\n",
        "    quotes = cc['sentences']\n",
        "    for quote in quotes:\n",
        "      print()\n",
        "      _q = untokenize(quote['subdoc'].tokens_cc[quote_slice])\n",
        "      print(_q)\n",
        "\n",
        "      distance = 1 - DF(quote['subdoc'].embeddings[quote_slice],\n",
        "                        subj.embeddings[5:])\n",
        "\n",
        "      quote['subj_correlation'] = distance\n",
        "\n",
        "      print(f'distance = {distance:.4f}')\n",
        "\n",
        "      r_quotes.append(_q)\n",
        "      r_vector.append(distance)\n",
        "      r_quotes.append('\\n')\n",
        "      r_vector.append(distance)\n",
        "\n",
        "  GLOBALS__['renderer'].render_color_text(r_quotes, r_vector)\n",
        "  print(r_vector)\n",
        "  print(r_quotes)\n",
        "  \n",
        "  \n",
        "match_contract_to_charter_constraints(GLOBALS__['ContractAnlysingContext'].contract,\n",
        "                                      GLOBALS__['CharterAnlysingContext'].doc,\n",
        "                                      GLOBALS__['CharterAnlysingContext'].constraints,\n",
        "                                      GLOBALS__['CharterAnlysingContext'].charity_constraints\n",
        "                                     )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hiOWiOKX9MEy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from ml_tools import ProbableValue, np, TokensWithAttention\n",
        "from renderer import as_warning, as_offset, as_error_html, as_msg, as_quote, as_currency\n",
        "from text_tools import untokenize\n",
        "from transaction_values import ValueConstraint\n",
        "\n",
        "# //copy\n",
        "class ViolationsFinder:\n",
        "\n",
        "  def find_ranges_by_group(self, charter_constraints, m_convert, verbose=False):\n",
        "    ranges_by_group = {}\n",
        "    for head_group in charter_constraints:\n",
        "      #     print('-' * 20)\n",
        "      group_c = charter_constraints[head_group]\n",
        "      data = self._combine_constraints_in_group(group_c, m_convert, verbose)\n",
        "      ranges_by_group[head_group] = data\n",
        "    return ranges_by_group\n",
        "\n",
        "  @staticmethod\n",
        "  def _combine_constraints_in_group(group_c, m_convert, verbose=False):\n",
        "    # print(group_c)\n",
        "    # print(group_c['section'])\n",
        "\n",
        "    data = {\n",
        "      'name': group_c['section'],\n",
        "      'ranges': {}\n",
        "    }\n",
        "\n",
        "    sentences = group_c['sentences']\n",
        "    #   print (charter_constraints[head_group]['sentences'])\n",
        "    sentence_id = 0\n",
        "    for sentence in sentences:\n",
        "      constraint_low = None\n",
        "      constraint_up = None\n",
        "\n",
        "      sentence_id += 1\n",
        "      #     print (sentence['constraints'])\n",
        "\n",
        "      s_constraints = sentence['constraints']\n",
        "      # –±–æ–ª—å—à–∏–µ –∏—â–µ–º\n",
        "      maximals = [x for x in s_constraints if x.value.sign > 0]\n",
        "\n",
        "      if len(maximals) > 0:\n",
        "        constraint_low = min(maximals, key=lambda item: m_convert(item.value).value)\n",
        "        # if verbose:\n",
        "        #   print(\"all maximals:\")\n",
        "        #   self.renderer.render_values(maximals)\n",
        "        #   print('\\t\\t\\t constraint_low', constraint_low.value.value)\n",
        "        #   self.renderer.render_values([constraint_low])\n",
        "\n",
        "      minimals = [x for x in s_constraints if x.value.sign <= 0]\n",
        "      if len(minimals) > 0:\n",
        "        constraint_up = min(minimals, key=lambda item: m_convert(item.value).value)\n",
        "        # if verbose:\n",
        "        #   print(\"all: minimals\")\n",
        "        #   self.renderer.render_values(minimals)\n",
        "        #   print('\\t\\t\\t constraint_upper', constraint_up.value.value)\n",
        "        #   self.renderer.render_values([constraint_up])\n",
        "        #   print(\"----X\")\n",
        "\n",
        "      if constraint_low is not None or constraint_up is not None:\n",
        "        data['ranges'][sentence_id] = VConstraint(constraint_low, constraint_up, group_c)\n",
        "\n",
        "    return data\n",
        "    # ==================================================================VIOLATIONS\n",
        "\n",
        "\n",
        "class VConstraint:\n",
        "  def __init__(self, lower, upper, head_group):\n",
        "    _emp = TokensWithAttention([''], [0])\n",
        "    self.lower = ProbableValue(ValueConstraint(0, 'RUB', +1, context=_emp), 0)\n",
        "    self.upper = ProbableValue(ValueConstraint(np.inf, 'RUB', -1, context=_emp), 0)\n",
        "\n",
        "    if lower is not None:\n",
        "      self.lower = lower\n",
        "\n",
        "    if upper is not None:\n",
        "      self.upper = upper\n",
        "\n",
        "    self.head_group = head_group\n",
        "\n",
        "  @staticmethod\n",
        "  def maybe_convert(v: ValueConstraint, convet_m):\n",
        "    html = \"\"\n",
        "    v_converted = v\n",
        "    if v.currency != 'RUB':\n",
        "      v_converted = convet_m(v)\n",
        "      html += as_warning(f\"–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤–∞–ª—é—Ç {as_currency(v)} --> RUB \")\n",
        "      html += as_offset(as_warning(f\"–ø—Ä–∏–º–µ—Ä–Ω–æ: {as_currency(v)} ~~  {as_currency(v_converted)}  \"))\n",
        "    return v, v_converted, html\n",
        "\n",
        "  def check_contract_value(self, _v: ProbableValue, convet_m, renderer):\n",
        "    greather_lower = False\n",
        "    greather_upper = False\n",
        "\n",
        "    if _v is None:\n",
        "      return as_error_html(\"—Å—É–º–º–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞\")\n",
        "    v: ValueConstraint = _v.value\n",
        "\n",
        "    if v is None:\n",
        "      return as_error_html(\"—Å—É–º–º–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ –Ω–µ –≤–µ—Ä–Ω–∞\")\n",
        "\n",
        "    if v.value is None:\n",
        "      return as_error_html(f\"—Å—É–º–º–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ –Ω–µ –≤–µ—Ä–Ω–∞ {v.currency}\")\n",
        "    ###----\n",
        "\n",
        "    lower_v = None\n",
        "    upper_v = None\n",
        "    if self.lower is not None:\n",
        "      lower_v: ValueConstraint = self.lower.value\n",
        "    if self.upper is not None:\n",
        "      upper_v: ValueConstraint = self.upper.value\n",
        "\n",
        "    html = as_msg(f\"–î–∏–∞–ø–∞–∑–æ–Ω: {as_currency(lower_v)} < ..... < {as_currency(upper_v)}\")\n",
        "\n",
        "    v, v_converted, h = self.maybe_convert(v, convet_m)\n",
        "    html += h\n",
        "\n",
        "    if self.lower is not None:\n",
        "      lower_v: ValueConstraint = self.lower.value\n",
        "      lower_v, lower_converted, h = self.maybe_convert(lower_v, convet_m)\n",
        "      html += h\n",
        "\n",
        "      if v_converted.value >= lower_converted.value:\n",
        "        greather_lower = True\n",
        "        html += as_warning(\"—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–¥–æ–±—Ä–µ–Ω–∏–µ...\".upper())\n",
        "        html += as_warning(\n",
        "          f\"—Å—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞  {as_currency(v_converted)}  –ë–û–õ–¨–®–ï –Ω–∏–∂–Ω–µ–π –ø–æ—Ä–æ–≥–æ–≤–æ–π {as_currency(lower_converted)} \")\n",
        "        html += as_quote(untokenize(lower_v.context.tokens))\n",
        "\n",
        "    if self.upper is not None:\n",
        "\n",
        "      upper_v: ValueConstraint = self.upper.value\n",
        "      upper_v, upper_converted, h = self.maybe_convert(upper_v, convet_m)\n",
        "      html += h\n",
        "\n",
        "      if v_converted.value >= upper_converted.value:\n",
        "\n",
        "        html += as_error_html(\n",
        "          f\"—Å—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞  {as_currency(v_converted)} –ë–û–õ–¨–®–ï –≤–µ—Ä—Ö–Ω–µ–π –ø–æ—Ä–æ–≥–æ–≤–æ–π {as_currency(upper_converted)} \")\n",
        "\n",
        "      elif greather_lower:\n",
        "        head_name = self.head_group['section']\n",
        "        html += as_error_html(f'—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–¥–æ–±—Ä–µ–Ω–∏–µ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã \"{head_name.upper()}\"')\n",
        "\n",
        "        if lower_v.context is not None:\n",
        "          html += as_quote(renderer.to_color_text(lower_v.context.tokens, lower_v.context.attention, _range=[0, 1]))\n",
        "\n",
        "        if upper_v.context is not None:\n",
        "          html += '<br>'\n",
        "          html += as_quote(renderer.to_color_text(upper_v.context.tokens, upper_v.context.attention, _range=[0, 1]))\n",
        "\n",
        "    return html \n",
        "  \n",
        "  \n",
        "  \n",
        "  # AZ:-FINDING_VIOLATIONS--------------------------------------------------------\n",
        "def find_and_show_violations():\n",
        "  from IPython.core.display import display, HTML\n",
        "\n",
        "  from demo import ContractAnlysingContext\n",
        "  from renderer import as_headline_2, as_error_html\n",
        "\n",
        "  charterAnlysingContext: CharterAnlysingContext = GLOBALS__['CharterAnlysingContext']\n",
        "  contractAnlysingContext: ContractAnlysingContext = GLOBALS__['ContractAnlysingContext']\n",
        "\n",
        "  contract = contractAnlysingContext.contract\n",
        "  charter = charterAnlysingContext.doc\n",
        "  \n",
        "  charter_constraints = charterAnlysingContext.constraints  # XXX: move to doc\n",
        "  charity_constraints = charterAnlysingContext.charity_constraints  # XXX: move to doc\n",
        "\n",
        "  \n",
        "\n",
        "  import copy\n",
        "\n",
        "  def convert(v):\n",
        "    v_converted = copy.copy(v)\n",
        "    if v.currency in currency_converter:\n",
        "      v_converted.value = currency_converter[v.currency] * v.value\n",
        "      v_converted.currency = 'RUB'\n",
        "      return v_converted\n",
        "    else:\n",
        "      display(HTML(as_error_html(\n",
        "        f\"–º—ã –Ω–µ –≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏ (–ø–æ–∫–∞) –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å {v.currency} --> RUB. –≠—Ç–æ –≤–æ–æ–±—â–µ –≤–∞–ª—é—Ç–∞ –∫–∞–∫–æ–π —Å—Ç—Ä–∞–Ω—ã? –†—É–º—ã–Ω–∏–∏?\")))\n",
        "      return v\n",
        "\n",
        "  best_value = contractAnlysingContext.find_contract_best_value(convert)\n",
        "\n",
        "  # rendering:----------------------------\n",
        "\n",
        "  def _render_violations(ranges_by_group, best_value):\n",
        "    \n",
        "    for group_key in ranges_by_group:\n",
        "      group = ranges_by_group[group_key]\n",
        "      display(HTML(as_headline_2(group['name'])))\n",
        "\n",
        "      for rk in group['ranges']:\n",
        "        r = group['ranges'][rk]\n",
        "        display(HTML(r.check_contract_value(best_value, convert, renderer)))\n",
        "\n",
        "        \n",
        "  renderer = GLOBALS__['renderer']\n",
        "  renderer.render_subj(contract)\n",
        "  \n",
        "  print('---')\n",
        "  print(\"–°—É–º–º–∞ –î–æ–≥–æ–≤–æ—Ä–∞:\")\n",
        "  renderer.render_values([best_value])\n",
        "  renderer.render_color_text(best_value.value.context.tokens, best_value.value.context.attention, _range=[0, 1])\n",
        "\n",
        "  violations_finder = ViolationsFinder()####//XXXX: remplaced\n",
        "  \n",
        "  \n",
        "  _render_violations(    \n",
        "    violations_finder.find_ranges_by_group(charter_constraints, convert, verbose=False),\n",
        "    best_value)\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "find_and_show_violations()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1xOiDjj3KQN-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "contract= GLOBALS__['ContractAnlysingContext'].contract\n",
        "charter = GLOBALS__['CharterAnlysingContext'].doc\n",
        "# if( GLOBALS__['ContractAnlysingContext'].contract.subject[0] == 'charity'):\n",
        "#   print('charity')\n",
        "\n",
        "charity_constraints =  GLOBALS__['CharterAnlysingContext'].charity_constraints\n",
        "for cc in charity_constraints:\n",
        "  if cc[:4]=='new.':\n",
        "    print(cc[4:].upper() )\n",
        "    constraints = charity_constraints[cc]\n",
        "    for constraint in constraints:\n",
        "#       print(constraint)\n",
        "      if constraint['subj_correlation'] > 0.5:\n",
        "        GLOBALS__['ContractAnlysingContext'].renderer.render_subj(contract)\n",
        "        print(contract.sections['subj'].body.untokenize_cc())\n",
        "#         GLOBALS__['ContractAnlysingContext'].renderer.render_color_text(contract.sections['subj'].tokens, contract.sections['subj'].)\n",
        "\n",
        "        print (f\"\\n–ö–æ—Ä–µ–ª—è—Ü–∏—è —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º —É—Å—Ç–∞–≤–∞: {constraint['subj_correlation']:.4f}\\n\\n\"  )\n",
        "        print(constraint['slice'])\n",
        "\n",
        "# contract.sections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2uZVU4M1osVo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DIST_FUNC(docA.embeddings,  docB.embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NQMHGw2NzZU1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# step 4. –ü—Ä–æ—Ç–æ–∫–æ–ª\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "85aO_7B1zKFq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "uploaded = interactive_upload('–ü—Ä–æ—Ç–æ–∫–æ–ª, –ø—Ä–æ—Ç–æ–∫—É—é –∏ –±—É–¥—É –ø—Ä–æ—Ç–æ–∫–æ–≤–∞—Ç—å')\n",
        "GLOBALS__['ProtocolAnlysingContext'].process(uploaded[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TKaWFEoWcK_u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## do preparation here   \n",
        "\n",
        "#1.\n",
        "_init_import_code_from_gh()\n",
        "#2.\n",
        "_init_embedder()\n",
        "#3.\n",
        "_init_the_code()\n",
        "#4. \n",
        "_init_charters()\n",
        "#5. \n",
        "# _init_contracts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jzn0JxepKxei",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sample Charter"
      ]
    },
    {
      "metadata": {
        "id": "BiDo5o2YcRkH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yi0yZHbPsXHg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SAMPLE=\"\"\"\n",
        " \n",
        "\n",
        "–û–±—â–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "–£—Å—Ç–∞–≤–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª\n",
        "\n",
        "\n",
        "xxvii –£—Å—Ç–∞–≤–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª –û–±—â–µ—Å—Ç–≤–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –∏–∑ –Ω–æ–º–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –¥–æ–ª–µ–π –µ–≥–æ –£—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç  6 734 244 615 (–®–µ—Å—Ç—å –º–∏–ª–ª–∏–∞—Ä–¥–æ–≤ —Å–µ–º—å—Å–æ—Ç —Ç—Ä–∏–¥—Ü–∞—Ç—å —á–µ—Ç—ã—Ä–µ –º–∏–ª–ª–∏–æ–Ω–∞ –¥–≤–µ—Å—Ç–∏ —Å–æ—Ä–æ–∫ —á–µ—Ç—ã—Ä–µ —Ç—ã—Å—è—á–∏ —à–µ—Å—Ç—å—Å–æ—Ç –ø—è—Ç–Ω–∞–¥—Ü–∞—Ç—å) —Ä—É–±–ª–µ–π.\n",
        "\n",
        "\n",
        "\n",
        "xxxv –û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –Ω–µ –≤–ø—Ä–∞–≤–µ –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ –æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –ø—Ä–∏–±—ã–ª–∏ –û–±—â–µ—Å—Ç–≤–∞ –º–µ–∂–¥—É –£—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏ –û–±—â–µ—Å—Ç–≤–∞:\n",
        "\n",
        "       ‚Ä¢ –¥–æ –ø–æ–ª–Ω–æ–π –æ–ø–ª–∞—Ç—ã –≤—Å–µ–≥–æ —É—Å—Ç–∞–≤–Ω–æ–≥–æ –∫–∞–ø–∏—Ç–∞–ª–∞ –û–±—â–µ—Å—Ç–≤–∞;\n",
        "\n",
        "     \n",
        "\n",
        "–û—Ä–≥–∞–Ω—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è\n",
        "\n",
        "\n",
        "lxxxiv –û—Ä–≥–∞–Ω–∞–º–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞ —è–≤–ª—è—é—Ç—Å—è:\n",
        "\n",
        "\n",
        "       ‚Ä¢ –û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞;\n",
        "\n",
        "\n",
        "       ‚Ä¢ –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ ‚Äì –ö–æ–ª–ª–µ–≥–∏–∞–ª—å–Ω—ã–π –æ—Ä–≥–∞–Ω —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è;\n",
        "\n",
        "\n",
        "       ‚Ä¢ –ü—Ä–∞–≤–ª–µ–Ω–∏–µ –û–±—â–µ—Å—Ç–≤–∞ - –ö–æ–ª–ª–µ–≥–∏–∞–ª—å–Ω—ã–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ä–≥–∞–Ω;\n",
        "\n",
        "\n",
        "       ‚Ä¢ –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä - –ï–¥–∏–Ω–æ–ª–∏—á–Ω—ã–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ä–≥–∞–Ω.\n",
        "\n",
        "\n",
        "–û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞\n",
        "\n",
        "\n",
        "lxxxvi –í—ã—Å—à–∏–º –æ—Ä–≥–∞–Ω–æ–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞ —è–≤–ª—è–µ—Ç—Å—è –û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞. –û—á–µ—Ä–µ–¥–Ω–æ–µ –û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞  —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –∏ —É—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –û–±—â–µ—Å—Ç–≤–∞ –∑–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –≥–æ–¥ –∏ –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è –≤ –ø–µ—Ä–∏–æ–¥ —Å 1 –º–∞—Ä—Ç–∞ –ø–æ 30 –∞–ø—Ä–µ–ª—è. –ü—Ä–æ–≤–æ–¥–∏–º—ã–µ –ø–æ–º–∏–º–æ –æ—á–µ—Ä–µ–¥–Ω–æ–≥–æ –û–±—â–∏–µ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ —è–≤–ª—è—é—Ç—Å—è –≤–Ω–µ–æ—á–µ—Ä–µ–¥–Ω—ã–º–∏. –í–Ω–µ–æ—á–µ—Ä–µ–¥–Ω—ã–µ –û–±—â–∏–µ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ –ø—Ä–æ–≤–æ–¥—è—Ç—Å—è –≤ —Å–ª—É—á–∞—è—Ö, –∫–æ–≥–¥–∞ —ç—Ç–æ–≥–æ —Ç—Ä–µ–±—É—é—Ç –∏–Ω—Ç–µ—Ä–µ—Å—ã –û–±—â–µ—Å—Ç–≤–∞.\n",
        "\n",
        "\n",
        "lxxxvii –ö –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ–π –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ –æ—Ç–Ω–æ—Å—è—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã:\n",
        "\n",
        "    \n",
        "\n",
        "       12) —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞, —Å–æ—Å—Ç–∞–≤–∞, —Ñ–æ—Ä–º—ã –∏ –ø–æ—Ä—è–¥–∫–∞ –≤–Ω–µ—Å–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–∫–ª–∞–¥–æ–≤, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—â–µ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ —Ç–∞–∫–∏—Ö –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–∫–ª–∞–¥–æ–≤, –∞ —Ç–∞–∫–∂–µ –∏–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π –≤–Ω–µ—Å–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–∫–ª–∞–¥–æ–≤ –£—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏ –û–±—â–µ—Å—Ç–≤–∞;\n",
        "       13) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Å–æ–≥–ª–∞—Å–∏–∏ –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –∏–ª–∏ –æ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º –æ–¥–æ–±—Ä–µ–Ω–∏–∏ –∫—Ä—É–ø–Ω—ã—Ö —Å–¥–µ–ª–æ–∫, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ–º, –æ—Ç—á—É–∂–¥–µ–Ω–∏–µ–º –∏–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ—Ç—á—É–∂–¥–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–æ–º –ø—Ä—è–º–æ –∏–ª–∏ –∫–æ—Å–≤–µ–Ω–Ω–æ –∏–º—É—â–µ—Å—Ç–≤–∞, —Ü–µ–Ω–∞ –∏–ª–∏ –±–∞–ª–∞–Ω—Å–æ–≤–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –∫–æ—Ç–æ—Ä–æ–≥–æ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 25 (–î–≤–∞–¥—Ü–∞—Ç—å –ø—è—Ç—å) –∏ –±–æ–ª–µ–µ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –±–∞–ª–∞–Ω—Å–æ–≤–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∏–º—É—â–µ—Å—Ç–≤–∞ –û–±—â–µ—Å—Ç–≤–∞ –ø–æ –¥–∞–Ω–Ω—ã–º –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–æ–π –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –æ—Ç—á–µ—Ç–Ω—É—é –¥–∞—Ç—É;\n",
        "       14) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Å–æ–≥–ª–∞—Å–∏–∏ –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –∏–ª–∏ –æ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º –æ–¥–æ–±—Ä–µ–Ω–∏–∏ —Å–¥–µ–ª–æ–∫, –≤ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–∏ –∫–æ—Ç–æ—Ä—ã—Ö –∏–º–µ–µ—Ç—Å—è –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å, –µ—Å–ª–∏ —Ü–µ–Ω–∞ –∏–ª–∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å –∏–º—É—â–µ—Å—Ç–≤–∞, —è–≤–ª—è—é—â–µ–≥–æ—Å—è –ø—Ä–µ–¥–º–µ—Ç–æ–º —Å–¥–µ–ª–∫–∏,  –ø—Ä–µ–≤—ã—à–∞–µ—Ç 10 (–¥–µ—Å—è—Ç—å) –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –±–∞–ª–∞–Ω—Å–æ–≤–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤  –±–∞–ª–∞–Ω—Å–æ–≤–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∏–º—É—â–µ—Å—Ç–≤–∞ –û–±—â–µ—Å—Ç–≤–∞ –ø–æ –¥–∞–Ω–Ω—ã–º –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–æ–π –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –æ—Ç—á–µ—Ç–Ω—É—é –¥–∞—Ç—É.\n",
        "       15) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏–ª–∏ –ª–∏–∫–≤–∏–¥–∞—Ü–∏–∏ –û–±—â–µ—Å—Ç–≤–∞;\n",
        "       26) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Å–æ–≥–ª–∞—Å–∏–∏ –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –∏–ª–∏ –æ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º –æ–¥–æ–±—Ä–µ–Ω–∏–∏ —Å–¥–µ–ª–æ–∫ –º–µ–Ω—ã, –¥–∞—Ä–µ–Ω–∏—è, –∏–Ω—ã—Ö —Å–¥–µ–ª–æ–∫, –ø—Ä–µ–¥—É—Å–º–∞—Ç—Ä–∏–≤–∞—é—â–∏—Ö –±–µ–∑–≤–æ–∑–º–µ–∑–¥–Ω–æ–µ –æ—Ç—á—É–∂–¥–µ–Ω–∏–µ –∏–º—É—â–µ—Å—Ç–≤–∞ –û–±—â–µ—Å—Ç–≤–∞ –ª–∏–±–æ –æ–ø–ª–∞—Ç—É (–≤—Å—Ç—Ä–µ—á–Ω–æ–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ) –≤ –Ω–µ–¥–µ–Ω–µ–∂–Ω–æ–π —Ñ–æ—Ä–º–µ,  –æ–¥–æ–±—Ä–µ–Ω–∏–µ –¥–æ–≥–æ–≤–æ—Ä–æ–≤ —Å–ø–æ–Ω—Å–æ—Ä—Å–∫–æ–≥–æ –∏ –±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Å—É–º–º—ã —Å–¥–µ–ª–∫–∏, –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ —Ç–∞–∫–∏–µ —Å–¥–µ–ª–∫–∏ —Ç—Ä–µ–±—É—é—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–∏—è –æ—Ä–≥–∞–Ω–æ–≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞ –∫–∞–∫ –∫—Ä—É–ø–Ω—ã–µ —Å–¥–µ–ª–∫–∏ –∏ —Å–¥–µ–ª–∫–∏ —Å –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å—é;\n",
        "       27) —Ä–µ—à–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤, –æ—Ç–Ω–µ—Å–µ–Ω–Ω—ã—Ö –∫ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤, –≤ —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –Ω–µ –∏–∑–±—Ä–∞–Ω;\n",
        "       28) —Ä–µ—à–µ–Ω–∏–µ –∏–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤, –æ—Ç–Ω–µ—Å–µ–Ω–Ω—ã—Ö –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –¥–µ–π—Å—Ç–≤—É—é—â–∏–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º –∫ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞.\n",
        "\n",
        "\n",
        "\n",
        "–°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞\n",
        "\n",
        "\n",
        "      1. –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç –æ–±—â–µ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –û–±—â–µ—Å—Ç–≤–∞, –∞ —Ç–∞–∫–∂–µ –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ–º —Ä–µ—à–µ–Ω–∏–π –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ –∏ –∏–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –µ–≥–æ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ä–≥–∞–Ω–∞.\n",
        "\n",
        "      2. –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ 4 (–ß–µ—Ç—ã—Ä–µ—Ö) —á–µ–ª–æ–≤–µ–∫.\n",
        "\n",
        "      3. –ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è:\n",
        "\n",
        "\n",
        "      14) —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ–¥—É—Ä –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è –∑–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ-—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –û–±—â–µ—Å—Ç–≤–∞, –≤ —Ç–æ–º —á–∏—Å–ª–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è –æ –≤–Ω—É—Ç—Ä–∏—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç—Ä–æ–ª–µ, –¥–æ–∫—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–∫–∞—Ö –∏ —Ä–µ–≤–∏–∑–∏—è—Ö;\n",
        "\n",
        "      15) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Å–æ–≥–ª–∞—Å–∏–∏ –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –∏–ª–∏ –æ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º –æ–¥–æ–±—Ä–µ–Ω–∏–∏ —Å–¥–µ–ª–æ–∫, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∏–µ–º –¥–µ–Ω–µ–∂–Ω—ã—Ö –≤—ã–ø–ª–∞—Ç –∏ (–∏–ª–∏) –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ–º, –æ—Ç—á—É–∂–¥–µ–Ω–∏–µ–º –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ—Ç—á—É–∂–¥–µ–Ω–∏—è, –æ–±—Ä–µ–º–µ–Ω–µ–Ω–∏–µ–º –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ–±—Ä–µ–º–µ–Ω–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–æ–º –∏–º—É—â–µ—Å—Ç–≤–∞, –≤ —Ä–∞–º–∫–∞—Ö –∫–æ—Ç–æ—Ä—ã—Ö —Ü–µ–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–ª–∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å –æ—Ç—á—É–∂–¥–∞–µ–º–æ–≥–æ –∏–º—É—â–µ—Å—Ç–≤–∞, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è –Ω–∞ –º–æ–º–µ–Ω—Ç —Å–æ–≤–µ—Ä—à–µ–Ω–∏—è —Å–¥–µ–ª–∫–∏, –ø—Ä–µ–≤—ã—à–∞–µ—Ç –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–π —Å–¥–µ–ª–∫–∏ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫, –∑–∞–∫–ª—é—á–µ–Ω–Ω—ã—Ö –≤ —Ç–µ—á–µ–Ω–∏–µ 6 (—à–µ—Å—Ç–∏) –º–µ—Å—è—Ü–µ–≤, –≤ —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏ 50 000 000 (–ü—è—Ç—å–¥–µ—Å—è—Ç –º–∏–ª–ª–∏–æ–Ω–æ–≤) —Ä—É–±–ª–µ–π –∏–ª–∏ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç –¥–∞–Ω–Ω–æ–π —Å—É–º–º—ã –≤ –∏–Ω–æ–π –≤–∞–ª—é—Ç–µ, –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ —Ç–∞–∫–∏–µ —Å–¥–µ–ª–∫–∏ —Ç—Ä–µ–±—É—é—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–∏—è –æ—Ä–≥–∞–Ω–æ–≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞  –∫–∞–∫ –∫—Ä—É–ø–Ω—ã–µ —Å–¥–µ–ª–∫–∏ –∏ —Å–¥–µ–ª–∫–∏ —Å –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å—é, –∞ —Ç–∞–∫–∂–µ –¥–ª—è —Å–¥–µ–ª–æ–∫, –æ–¥–æ–±—Ä—è–µ–º—ã—Ö –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º–∏ 22)-26) –ø—É–Ω–∫—Ç–∞ 11.2 –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –£—Å—Ç–∞–≤–∞, –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º–∏ 17) ‚Äì22), 30) –ø—É–Ω–∫—Ç–∞ 12.3 –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –£—Å—Ç–∞–≤–∞;\n",
        "\n",
        "      16) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ/—É—Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ –ª—é–±—ã—Ö —Å—É–¥–µ–±–Ω—ã—Ö —Å–ø–æ—Ä–æ–≤ –∏ —Ä–∞–∑–±–∏—Ä–∞—Ç–µ–ª—å—Å—Ç–≤, —Ü–µ–Ω–∞ –∏—Å–∫–∞ –ø–æ –∫–æ—Ç–æ—Ä—ã–º –ø—Ä–µ–≤—ã—à–∞–µ—Ç 50 000 000 (–ü—è—Ç—å–¥–µ—Å—è—Ç –º–∏–ª–ª–∏–æ–Ω–æ–≤) —Ä—É–±–ª–µ–π (–∏–ª–∏ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç –≤ –¥—Ä—É–≥–æ–π –≤–∞–ª—é—Ç–µ) –≤ —Ç–æ–º —á–∏—Å–ª–µ, –ø–æ–¥–ø–∏—Å–∞–Ω–∏–µ –º–∏—Ä–æ–≤–æ–≥–æ —Å–æ–≥–ª–∞—à–µ–Ω–∏—è, –ø—Ä–∏–∑–Ω–∞–Ω–∏–µ –∏—Å–∫–∞, –æ—Ç–∫–∞–∑ –æ—Ç –∏—Å–∫–∞, –∞ —Ç–∞–∫–∂–µ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π, –∫—Ä–æ–º–µ —Å—É–¥–µ–±–Ω—ã—Ö —Å–ø–æ—Ä–æ–≤, –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è, –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–∏ –∫–æ—Ç–æ—Ä—ã—Ö –æ—Ç–Ω–µ—Å–µ–Ω–æ –∫ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞;\n",
        "\n",
        "\n",
        "–ü—Ä–∞–≤–ª–µ–Ω–∏–µ –û–±—â–µ—Å—Ç–≤–∞\n",
        "\n",
        "\n",
        " 1. –ü—Ä–∞–≤–ª–µ–Ω–∏–µ —è–≤–ª—è–µ—Ç—Å—è –ö–æ–ª–ª–µ–≥–∏–∞–ª—å–Ω—ã–º –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –æ—Ä–≥–∞–Ω–æ–º –û–±—â–µ—Å—Ç–≤–∞. –ü—Ä–∞–≤–ª–µ–Ω–∏–µ –û–±—â–µ—Å—Ç–≤–∞ –∏–∑–±–∏—Ä–∞–µ—Ç—Å—è –û–±—â–∏–º —Å–æ–±—Ä–∞–Ω–∏–µ–º —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ  2 (–î–≤—É—Ö) —á–µ–ª–æ–≤–µ–∫ ‚Äì —á–ª–µ–Ω–æ–≤ –ü—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞.\n",
        "\n",
        "\n",
        "12. –í —Å–ª—É—á–∞–µ –Ω–µ–ø—Ä–∏–Ω—è—Ç–∏—è –ü—Ä–∞–≤–ª–µ–Ω–∏–µ–º —Ä–µ—à–µ–Ω–∏—è –ø–æ –æ–¥–Ω–æ–º—É –∏ —Ç–æ–º—É –∂–µ –≤–æ–ø—Ä–æ—Å—É –≤ —Ö–æ–¥–µ 2 (–î–≤—É—Ö) –Ω–∞–¥–ª–µ–∂–∞—â–µ —Å–æ–∑–≤–∞–Ω–Ω—ã—Ö –∑–∞—Å–µ–¥–∞–Ω–∏–π –ü—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ –ª—é–±—ã–º –ø—Ä–∏—á–∏–Ω–∞–º, –≤–∫–ª—é—á–∞—è –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫–≤–æ—Ä—É–º–∞ –∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≥–æ–ª–æ—Å–æ–≤ –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è, –≤–æ–ø—Ä–æ—Å, –ø–æ –∫–æ—Ç–æ—Ä–æ–º—É –Ω–µ –±—ã–ª–æ –ø—Ä–∏–Ω—è—Ç–æ —Ä–µ—à–µ–Ω–∏–µ, –≤—ã–Ω–æ—Å–∏—Ç—Å—è –Ω–∞ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ (–≤–∫–ª—é—á–∞–µ—Ç—Å—è –≤ –ø–æ–≤–µ—Å—Ç–∫—É –¥–Ω—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–æ–∑—ã–≤–∞–µ–º–æ–≥–æ –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤). –í–æ –∏–∑–±–µ–∂–∞–Ω–∏–µ —Å–æ–º–Ω–µ–Ω–∏–π, —Ä–µ—à–µ–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å—Å—è –∫–∞–∫ –Ω–µ–ø—Ä–∏–Ω—è—Ç–æ–µ –¥–ª—è —Ü–µ–ª–µ–π –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –ø—É–Ω–∫—Ç–∞, –≤ —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ —Ä–µ—à–µ–Ω–∏–µ –Ω–µ –ø—Ä–∏–Ω—è—Ç–æ –≤—Å–ª–µ–¥—Å—Ç–≤–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –ø—Ä–æ—Ç–∏–≤ –Ω–µ–≥–æ –ø—Ä–æ–≥–æ–ª–æ—Å–æ–≤–∞–ª–∏ –∏–ª–∏ –≤–æ–∑–¥–µ—Ä–∂–∞–ª–∏—Å—å –æ—Ç –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è –≤—Å–µ —á–ª–µ–Ω—ã –ü—Ä–∞–≤–ª–µ–Ω–∏—è.\n",
        "\n",
        "13. –ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –ü—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞ –æ—Ç–Ω–æ—Å—è—Ç—Å—è:\n",
        "\n",
        "\n",
        "\n",
        "         ‚Ä¢ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—É—Ä –Ω–∞ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π (–∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º —Ñ–∏–ª–∏–∞–ª–æ–≤ –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤) –û–±—â–µ—Å—Ç–≤–∞, –∞ —Ç–∞–∫–∂–µ —É—Å–ª–æ–≤–∏–π —Ç—Ä—É–¥–æ–≤—ã—Ö –¥–æ–≥–æ–≤–æ—Ä–æ–≤ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ –ª–∏—Ü–∞–º–∏, —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –æ—Ç –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –ª–∏—Ü;\n",
        "\n",
        "\n",
        "         ‚Ä¢ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Å–æ–≥–ª–∞—Å–∏–∏ –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –∏–ª–∏ –æ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º –æ–¥–æ–±—Ä–µ–Ω–∏–∏ —Å–¥–µ–ª–æ–∫, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∏–µ–º –¥–µ–Ω–µ–∂–Ω—ã—Ö –≤—ã–ø–ª–∞—Ç –∏ (–∏–ª–∏) –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ–º, –æ—Ç—á—É–∂–¥–µ–Ω–∏–µ–º –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ—Ç—á—É–∂–¥–µ–Ω–∏—è, –æ–±—Ä–µ–º–µ–Ω–µ–Ω–∏–µ–º –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ–±—Ä–µ–º–µ–Ω–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–æ–º –∏–º—É—â–µ—Å—Ç–≤–∞, —Å—Ç–æ–∏–º–æ—Å—Ç—å –∫–æ—Ç–æ—Ä–æ–≥–æ –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–π —Å–¥–µ–ª–∫–∏ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ –≤ —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ—Ç 1 000 000 (–û–¥–Ω–æ–≥–æ) –º–∏–ª–ª–∏–æ–Ω–∞ —Ä—É–±–ª–µ–π –¥–æ 50 000 000 (–ü—è—Ç—å–¥–µ—Å—è—Ç –º–∏–ª–ª–∏–æ–Ω–æ–≤) —Ä—É–±–ª–µ–π –∏–ª–∏ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç –¥–∞–Ω–Ω–æ–π —Å—É–º–º—ã –≤ –∏–Ω–æ–π –≤–∞–ª—é—Ç–µ, –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞  —Ç–∞–∫–∏–µ —Å–¥–µ–ª–∫–∏ —Ç—Ä–µ–±—É—é—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–∏—è –æ—Ä–≥–∞–Ω–æ–≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞  –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ó–∞–∫–æ–Ω–æ–º –∏ –£—Å—Ç–∞–≤–æ–º;\n",
        "\n",
        "\n",
        "         ‚Ä¢ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –ø–æ –ø—Ä–∏–µ–º–∫–µ –∏ –æ–ø–ª–∞—Ç–µ –û–±—â–µ—Å—Ç–≤–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö —Ä–∞–±–æ—Ç –ø–æ –ê–≥–µ–Ω—Ç—Å–∫–æ–º—É –¥–æ–≥–æ–≤–æ—Ä—É –Ω–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–∞ ¬´–Æ–∂–Ω–æ-–ü—Ä–∏–æ–±—Å–∫–∏–π –≥–∞–∑–æ–ø–µ—Ä–µ—Ä–∞–±–∞—Ç—ã–≤–∞—é—â–∏–π –∑–∞–≤–æ–¥ (–Æ–ü –ì–ü–ó). –ì–∞–∑–æ–∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä–Ω–∞—è —Å—Ç–∞–Ω—Ü–∏—è –Æ–õ–¢ –ü—Ä–∏–æ–±—Å–∫–æ–≥–æ –º–µ—Å—Ç–æ—Ä–æ–∂–¥–µ–Ω–∏—è¬ª ‚Ññ10-875 –æ—Ç 29.09.2010 –≥., –∑–∞–∫–ª—é—á–µ–Ω–Ω–æ–º—É –º–µ–∂–¥—É –û–±—â–µ—Å—Ç–≤–æ–º –∏ –û–û–û ¬´–ì–∞–∑–ø—Ä–æ–º–Ω–µ—Ñ—Ç—å-–•–∞–Ω—Ç–æ—Å¬ª.\n",
        "\n",
        "\n",
        "–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –û–±—â–µ—Å—Ç–≤–∞\n",
        "\n",
        "\n",
        "cvi –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ —Ç–µ–∫—É—â–µ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –û–±—â–µ—Å—Ç–≤–∞ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è –µ–¥–∏–Ω–æ–ª–∏—á–Ω—ã–º –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –æ—Ä–≥–∞–Ω–æ–º –û–±—â–µ—Å—Ç–≤–∞ - –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º. –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –∏–∑–±–∏—Ä–∞–µ—Ç—Å—è –û–±—â–∏–º —Å–æ–±—Ä–∞–Ω–∏–µ–º —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ —Å—Ä–æ–∫–æ–º –Ω–∞ 3 (–¢—Ä–∏) –≥–æ–¥–∞, –µ—Å–ª–∏ —Ä–µ—à–µ–Ω–∏–µ–º –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –Ω–µ –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω –∏–Ω–æ–π —Å—Ä–æ–∫. –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–µ—Ä–µ–∏–∑–±—Ä–∞–Ω —Ä–µ—à–µ–Ω–∏–µ–º –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑. –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –¥–µ–π—Å—Ç–≤—É–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –£—Å—Ç–∞–≤–∞ –û–±—â–µ—Å—Ç–≤–∞ –∏ —Ç—Ä—É–¥–æ–≤–æ–≥–æ –¥–æ–≥–æ–≤–æ—Ä–∞, –∑–∞–∫–ª—é—á–∞–µ–º–æ–≥–æ —Å –Ω–∏–º –û–±—â–µ—Å—Ç–≤–æ–º.\n",
        "\n",
        "\n",
        "       ‚Ä¢ —É—Ç–≤–µ—Ä–∂–¥–∞—Ç—å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, —Ä–µ–≥—É–ª–∏—Ä—É—é—â–∏–µ —Ç–µ–∫—É—â—É—é (–æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—É—é) –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å –û–±—â–µ—Å—Ç–≤–∞, –∏ –ª–æ–∫–∞–ª—å–Ω—ã–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –∞–∫—Ç—ã (–∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –ª–æ–∫–∞–ª—å–Ω—ã—Ö –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –∞–∫—Ç–æ–≤, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—â–∏—Ö —Å–∏—Å—Ç–µ–º—ã –æ–ø–ª–∞—Ç—ã —Ç—Ä—É–¥–∞ –∏ –¥—Ä—É–≥–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∫–æ—Ç–æ—Ä—ã—Ö –æ—Ç–Ω–µ—Å–µ–Ω–æ –∫ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –∏–Ω—ã—Ö –æ—Ä–≥–∞–Ω–æ–≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞);\n",
        "\n",
        "       ‚Ä¢ –≤–Ω–æ—Å–∏—Ç—å –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ –û–±—â–∏—Ö —Å–æ–±—Ä–∞–Ω–∏–π —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞, –∑–∞—Å–µ–¥–∞–Ω–∏—è –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤;\n",
        "\n",
        "       ‚Ä¢ –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ä–µ—à–µ–Ω–∏—è –ø–æ –¥—Ä—É–≥–∏–º –≤–æ–ø—Ä–æ—Å–∞–º, –æ—Ç–Ω–æ—Å—è—â–∏–º—Å—è –∫ –µ–≥–æ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏.\n",
        "\n",
        "\n",
        "\n",
        "cxlv –ù–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ª—é–±–æ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏—è –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –£—Å—Ç–∞–≤–∞ –Ω–µ –≤–ª–µ—á–µ—Ç –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –µ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏–π. –í —Å–ª—É—á–∞–µ –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è –≤ —Å–∏–ª—É –Ω–æ–≤—ã—Ö –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –∞–∫—Ç–æ–≤, –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –∫–æ—Ç–æ—Ä—ã–º–∏ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –£—Å—Ç–∞–≤–∞ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º–∏, –∏ –∫–æ—Ç–æ—Ä—ã–µ —Ç—Ä–µ–±—É—é—Ç –≤–Ω–µ—Å—Ç–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –£—Å—Ç–∞–≤, –£—á–∞—Å—Ç–Ω–∏–∫–∏ –æ–±—è–∑–∞–Ω—ã –ø—Ä–∏–Ω—è—Ç—å —Ä–µ—à–µ–Ω–∏—è –æ –≤–Ω–µ—Å–µ–Ω–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –Ω–∞—Å—Ç–æ—è—â–∏–π –£—Å—Ç–∞–≤.\n",
        "\n",
        "v –ü–æ–ª–Ω–æ–µ —Ñ–∏—Ä–º–µ–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –û–±—â–µ—Å—Ç–≤–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:\n",
        "\n",
        "      –û–±—â–µ—Å—Ç–≤–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é ¬´–Æ–∂–Ω–æ-–ü—Ä–∏–æ–±—Å–∫–∏–π –≥–∞–∑–æ–ø–µ—Ä–µ—Ä–∞–±–∞—Ç—ã–≤–∞—é—â–∏–π –∑–∞–≤–æ–¥¬ª.\n",
        "\n",
        "      –°–æ–∫—Ä–∞—â–µ–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:\n",
        "\n",
        "      –û–û–û ¬´–Æ–∂–Ω–æ-–ü—Ä–∏–æ–±—Å–∫–∏–π –ì–ü–ó¬ª.\n",
        "\n",
        "\n",
        "      –ü–æ–ª–Ω–æ–µ —Ñ–∏—Ä–º–µ–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –û–±—â–µ—Å—Ç–≤–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ: Yuzhno-Priobsky Gaz Processing Plant Limited Liability Company.\n",
        "\n",
        "\n",
        "      –°–æ–∫—Ä–∞—â–µ–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ:  Yuzhno-Priobsky GPP LLC.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "GLOBALS__['CharterAnlysingContext'].analyze_charter(SAMPLE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XpYNZGtEJRmR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from IPython.core.display import display, HTML\n",
        "doc = GLOBALS__['CharterAnlysingContext'].doc\n",
        "GLOBALS__['renderer'].render_contents(doc)\n",
        "\n",
        " \n",
        "GLOBALS__['renderer'].render_charter_parsing_results(GLOBALS__['CharterAnlysingContext'].org,GLOBALS__['CharterAnlysingContext'].constraints)\n",
        "\n",
        "\n",
        "def render_sections(sections):\n",
        "  html = '<h3>–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ —Å–µ–∫—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞</h4>'\n",
        "  html += \"<ul>\"\n",
        "  for section_type in sections:\n",
        "    section:HeadlineMeta = sections[section_type]\n",
        "    body = section.body.untokenize_cc()[:1000]\n",
        "    headline = section.subdoc.untokenize_cc()[:500]\n",
        "    #     line = doc.structure.structure[i].to_string(doc.tokens_cc)\n",
        "    html += f'<li><h3> {headline} <sup>type: {section_type}</sup> </h3> <p>{body}</p> </li>'\n",
        "  html += \"</ul>\"\n",
        "\n",
        "  display(HTML(html))\n",
        "  \n",
        "def render_contents(doc):\n",
        "  html = '<h3>–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞</h4>'\n",
        "  html += \"<ul>\"\n",
        "  for i in doc.structure.headline_indexes:\n",
        "    line = doc.structure.structure[i].to_string(doc.tokens_cc)\n",
        "    html += f'<li> {line} <sup>line {i}</sup></li>'\n",
        "  html += \"</ul>\"\n",
        "\n",
        "  display(HTML(html))\n",
        "  \n",
        "render_sections(doc.sections)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8tyMy_vPK8GQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6TUp36Q8K8ea",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Upload charter"
      ]
    },
    {
      "metadata": {
        "id": "twCGd5TFcTKI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  uploaded = interactive_upload('Charter')  \n",
        "  org, rz = GLOBALS__['CharterAnlysingContext'] .analyze_charter(uploaded[0])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dGRLbJ5kJuaO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_init_contracts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R6c9siQi9k_U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GLOBALS__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ZVFmJtpK_fG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Upload contract"
      ]
    },
    {
      "metadata": {
        "id": "HEyYz8iPJ-4X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "uploaded = interactive_upload('–î–æ–≥–æ–≤–æ—Ä')  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xIOjRq7EKQA9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GLOBALS__['ContractAnlysingContext'].verbosity_level=4\n",
        "GLOBALS__['ContractAnlysingContext'].analyze_contract(uploaded[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eb6EitqjLF3O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Violations"
      ]
    },
    {
      "metadata": {
        "id": "9YWejFEKKUrc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title –ù–∞—Å—Ç—Ä–æ–π–∫–∏ { run: \"auto\", display-mode: \"form\" }\n",
        "USD_to_RUB = 64.02 #@param {type:\"number\"}\n",
        "RUB_to_USD = 1.0/USD_to_RUB\n",
        "\n",
        "# print('USD_to_RUB=',USD_to_RUB)\n",
        "# print('RUB_to_USD=',RUB_to_USD)\n",
        "\n",
        "\n",
        "\n",
        "currency_converter = {\n",
        "  'USD': USD_to_RUB,\n",
        "  'RUB': 1.0\n",
        "}\n",
        "\n",
        "print(currency_converter)\n",
        "\n",
        "find_and_show_violations()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8igUeguItG3s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "doc=GLOBALS__['ContractAnlysingContext'].contract\n",
        "GLOBALS__['renderer'].render_contents(doc)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BhF8cq_PKKaK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "h = GLOBALS__['renderer'].render_constraint_values(GLOBALS__['CharterAnlysingContext'].constraints)\n",
        "display(HTML(h))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2HHEc7cCZv-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#violations (move and erase)"
      ]
    },
    {
      "metadata": {
        "id": "ffboeHGOCdcM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from transaction_values import ValueConstraint\n",
        "\n",
        "print('–ü–æ–∏—Å–∫ –Ω–∞—Ä—É—à–µ–Ω–∏–π')\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "contract = GLOBALS__['ContractAnlysingContext'].contract\n",
        "charter = GLOBALS__['CharterAnlysingContext'].doc\n",
        "charter_constraints = GLOBALS__['CharterAnlysingContext'].constraints  # XXX: move to doc\n",
        "\n",
        "#       h = GLOBALS__['renderer'].render_constraint_values(GLOBALS__['CharterAnlysingContext'].constraints)\n",
        "#       display(HTML(h))\n",
        "\n",
        "\n",
        "# def max_constraint_val(constraints):\n",
        "renderer = GLOBALS__['renderer']\n",
        "renderer.render_subj(contract)\n",
        "print()\n",
        "# GLOBALS__['renderer'].render_values(contract.contract_values)\n",
        "\n",
        "print(\"----------\")\n",
        "\n",
        "# GLOBALS__['renderer'].render_values([most_confident_value])\n",
        "# GLOBALS__['renderer'].render_color_text (most_confident_value.value.context[0], most_confident_value.value.context[1], _range=[0,1])\n",
        "\n",
        "# for c in contract.contract_values:\n",
        "#   print(c.confidence)\n",
        "#   print(c.value.value)\n",
        "# #   if c.value.value > best_c.value.value:\n",
        "\n",
        "\n",
        "# #   print(c.value.context)\n",
        "#   GLOBALS__['renderer'].render_color_text (c.value.context[0], c.value.context[1], _range=[0,1])\n",
        "\n",
        "# GLOBALS__['renderer'].render_contents(contract)\n",
        "\n",
        "\n",
        "# -------------------charter\n",
        "\n",
        "charter_constraints = GLOBALS__['CharterAnlysingContext'].constraints  # XXX: move to doc\n",
        "\n",
        "\n",
        "from ml_tools import ProbableValue\n",
        "\n",
        "currency_converter = {\n",
        "  'USD': USD_to_RUB,\n",
        "  'RUB': 1.0\n",
        "\n",
        "}\n",
        "import copy\n",
        "\n",
        "\n",
        "def convert(v, currency_converter=currency_converter):\n",
        "  v_converted = copy.copy(v)\n",
        "  if v.currency in currency_converter:\n",
        "    v_converted.value = currency_converter[v.currency] * v.value\n",
        "    v_converted.currency = 'RUB'\n",
        "    return v_converted\n",
        "  else:\n",
        "    display(HTML(as_error_html(\n",
        "      f\"–º—ã –Ω–µ –≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏ (–ø–æ–∫–∞) –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å {v.currency} --> RUB. –≠—Ç–æ –≤–æ–æ–±—â–µ –≤–∞–ª—é—Ç–∞ –∫–∞–∫–æ–π —Å—Ç—Ä–∞–Ω—ã? –†—É–º—ã–Ω–∏–∏?\")))\n",
        "    return v\n",
        "\n",
        "\n",
        "from text_tools import untokenize\n",
        "import numpy as np\n",
        "\n",
        "class VConstraint:\n",
        "  def __init__(self, lower, upper, head_group):\n",
        "    self.lower = ProbableValue( ValueConstraint(0, 'RUB', +1), 0 )\n",
        "    self.upper = ProbableValue( ValueConstraint(np.inf, 'RUB', -1), 0 )\n",
        "    \n",
        "    if lower is not None:\n",
        "      self.lower = lower\n",
        "     \n",
        "\n",
        "    if upper is not None:\n",
        "      self.upper = upper\n",
        "     \n",
        "      \n",
        "    self.head_group = head_group\n",
        "\n",
        "  def maybe_convert(self, v: ValueConstraint, currency_converter):\n",
        "    html = \"\"\n",
        "    v_converted = v\n",
        "    if v.currency != 'RUB':\n",
        "      v_converted = convert(v, currency_converter)\n",
        "      html += as_warning(f\"–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤–∞–ª—é—Ç {as_currency(v)} --> RUB \")\n",
        "      html += as_offset(as_warning(f\"–ø—Ä–∏–º–µ—Ä–Ω–æ: {as_currency(v)} ~~  {as_currency(v_converted)}  \"))\n",
        "    return v, v_converted, html\n",
        "\n",
        "  def check_contract_value(self, _v: ProbableValue, currency_converter):\n",
        "    greather_lower = False\n",
        "    greather_upper = False\n",
        "\n",
        "    if _v is None:\n",
        "      return as_error_html(\"—Å—É–º–º–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ –Ω–µ –∏–∑–≤–µ—Å—Ç–Ω–∞\")\n",
        "    v: ValueConstraint = _v.value\n",
        "\n",
        "    if v is None:\n",
        "      return as_error_html(\"—Å—É–º–º–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ –Ω–µ –≤–µ—Ä–Ω–∞\")\n",
        "\n",
        "    if v.value is None:\n",
        "      return as_error_html(f\"—Å—É–º–º–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ –Ω–µ –≤–µ—Ä–Ω–∞ {v.currency}\")\n",
        "    ###----\n",
        "\n",
        "    lower_v = None\n",
        "    upper_v = None\n",
        "    if self.lower is not None:\n",
        "      lower_v: ValueConstraint = self.lower.value\n",
        "    if self.upper is not None:\n",
        "      upper_v: ValueConstraint = self.upper.value\n",
        "\n",
        "    html = as_msg(f\"–¥–∏–∞–ø–∞–∑–æ–Ω: {as_currency(lower_v)} < ..... < {as_currency(upper_v)}\")\n",
        "\n",
        "    v, v_converted, h = self.maybe_convert(v, currency_converter)\n",
        "    html += h\n",
        "\n",
        "    if self.lower is not None:\n",
        "      lower_v: ValueConstraint = self.lower.value\n",
        "      lower_v, lower_converted, h = self.maybe_convert(lower_v, currency_converter)\n",
        "      html += h\n",
        "\n",
        "      if v_converted.value >= lower_converted.value:\n",
        "        greather_lower = True\n",
        "        html += as_warning(\"—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–¥–æ–±—Ä–µ–Ω–∏–µ...\".upper())\n",
        "        html += as_warning(\n",
        "          f\"—Å—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞  {as_currency(v_converted)}  –ë–û–õ–¨–®–ï –Ω–∏–∂–Ω–µ–π –ø–æ—Ä–æ–≥–æ–≤–æ–π {as_currency(lower_converted)} \")\n",
        "        html += as_quote(untokenize(lower_v.context[0]))\n",
        "\n",
        "    if self.upper is not None:\n",
        "\n",
        "      upper_v: ValueConstraint = self.upper.value\n",
        "      upper_v, upper_converted, h = self.maybe_convert(upper_v, currency_converter)\n",
        "      html += h\n",
        "\n",
        "      if v_converted.value >= upper_converted.value:\n",
        "\n",
        "        html += as_error_html(\n",
        "          f\"—Å—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞  {as_currency(v_converted)} –ë–û–õ–¨–®–ï –≤–µ—Ä—Ö–Ω–µ–π –ø–æ—Ä–æ–≥–æ–≤–æ–π {as_currency(upper_converted)} \")\n",
        "\n",
        "      elif greather_lower:\n",
        "        head_name = self.head_group['section']\n",
        "        html += as_error_html(f'—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–¥–æ–±—Ä–µ–Ω–∏–µ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã \"{head_name.upper()}\"')\n",
        "\n",
        "        if lower_v.context is not None:\n",
        "          html += as_quote(renderer.to_color_text(lower_v.context[0], lower_v.context[1], _range=[0, 1]))\n",
        "        if upper_v.context is not None:\n",
        "          html += '<br>'\n",
        "          html += as_quote(renderer.to_color_text(upper_v.context[0], upper_v.context[1], _range=[0, 1]))\n",
        "\n",
        "    return html\n",
        "\n",
        "\n",
        "# -----------\n",
        "\n",
        "\n",
        "def _combine_constraints_in_group(group_c, verbose=False):\n",
        "  # print(group_c)\n",
        "  # print(group_c['section'])\n",
        "\n",
        "  data = {\n",
        "    'name': group_c['section'],\n",
        "    'ranges': {}\n",
        "  }\n",
        "\n",
        "  sentences = group_c['sentences']\n",
        "  #   print (charter_constraints[head_group]['sentences'])\n",
        "  sentence_id = 0\n",
        "  for sentence in sentences:\n",
        "    constraint_low = None\n",
        "    constraint_up = None\n",
        "\n",
        "    sentence_id += 1\n",
        "    #     print (sentence['constraints'])\n",
        "\n",
        "    s_constraints = sentence['constraints']\n",
        "    # –±–æ–ª—å—à–∏–µ –∏—â–µ–º\n",
        "    maximals = [x for x in s_constraints if x.value.sign > 0]\n",
        "\n",
        "    if len(maximals) > 0:\n",
        "      constraint_low = min(maximals, key=lambda item: convert(item.value, currency_converter).value)\n",
        "      if verbose:\n",
        "        print(\"all maximals:\")\n",
        "        renderer.render_values(maximals)\n",
        "        print('\\t\\t\\t constraint_low', constraint_low.value.value)\n",
        "        renderer.render_values([constraint_low])\n",
        "\n",
        "    minimals = [x for x in s_constraints if x.value.sign <= 0]\n",
        "    if len(minimals) > 0:\n",
        "      constraint_up = min(minimals, key=lambda item: convert(item.value, currency_converter).value)\n",
        "      if verbose:\n",
        "        print(\"all: minimals\")\n",
        "        renderer.render_values(minimals)\n",
        "        print('\\t\\t\\t constraint_upper', constraint_up.value.value)\n",
        "        renderer.render_values([constraint_up])\n",
        "        print(\"----X\")\n",
        "\n",
        "    if constraint_low is not None or constraint_up is not None:\n",
        "      data['ranges'][sentence_id] = VConstraint(constraint_low, constraint_up, group_c)\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "def find_ranges_by_group(charter_constraints):\n",
        "  ranges_by_group = {}\n",
        "  for head_group in charter_constraints:\n",
        "    #     print('-' * 20)\n",
        "    group_c = charter_constraints[head_group]\n",
        "    data = _combine_constraints_in_group(group_c)\n",
        "    ranges_by_group[head_group] = data\n",
        "  return ranges_by_group\n",
        "\n",
        "\n",
        "def select_most_confident_if_almost_equal(a: ProbableValue, alternative: ProbableValue, equality_range=0):\n",
        "  if abs(convert(a.value).value - convert(alternative.value).value) < equality_range:\n",
        "    if a.confidence > alternative.confidence:\n",
        "      return a\n",
        "    else:\n",
        "      return alternative\n",
        "  return a\n",
        "\n",
        "\n",
        "def find_contract_best_value(contract):\n",
        "  best_value: ProbableValue = max(contract.contract_values,\n",
        "                                  key=lambda item: convert(item.value, currency_converter).value)\n",
        "\n",
        "  most_confident_value = max(contract.contract_values, key=lambda item: item.confidence)\n",
        "  best_value = select_most_confident_if_almost_equal(best_value, most_confident_value, 20)\n",
        "\n",
        "  return best_value\n",
        "\n",
        "\n",
        "best_value = find_contract_best_value(contract)\n",
        "\n",
        "\n",
        "# rendering:----------------------------\n",
        "\n",
        "\n",
        "def _render_violations(ranges_by_group, best_value):\n",
        "  for group_key in ranges_by_group:\n",
        "    group = ranges_by_group[group_key]\n",
        "    #   print(group['name'])\n",
        "    display(HTML(as_headline_2(group['name'])))\n",
        "\n",
        "    for rk in group['ranges']:\n",
        "      r = group['ranges'][rk]\n",
        "      display(HTML(r.check_contract_value(best_value, currency_converter)))\n",
        "\n",
        "\n",
        "print(\"–°—É–º–º–∞ –î–æ–≥–æ–≤–æ—Ä–∞:\")\n",
        "renderer.render_values([best_value])\n",
        "renderer.render_color_text(best_value.value.context[0], best_value.value.context[1], _range=[0, 1])\n",
        "\n",
        "_render_violations(\n",
        "  find_ranges_by_group(charter_constraints),\n",
        "  best_value)\n",
        "\n",
        "display(HTML(renderer.render_constraint_values(charter_constraints)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IdYrfpIZCnZp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## —á–∏—Å—Ç–æ–≤–∏–∫"
      ]
    },
    {
      "metadata": {
        "id": "dvXylOnCCqDN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from transaction_values import ValueConstraint\n",
        "\n",
        "print('–ü–æ–∏—Å–∫ –Ω–∞—Ä—É—à–µ–Ω–∏–π')\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "contract = GLOBALS__['ContractAnlysingContext'].contract\n",
        "charter = GLOBALS__['CharterAnlysingContext'].doc\n",
        "charter_constraints = GLOBALS__['CharterAnlysingContext'].constraints  # XXX: move to doc\n",
        "\n",
        " \n",
        "renderer = GLOBALS__['renderer']\n",
        "renderer.render_subj(contract)\n",
        "  \n",
        "\n",
        "charter_constraints = GLOBALS__['CharterAnlysingContext'].constraints  # XXX: move to doc\n",
        "\n",
        "\n",
        "from ml_tools import ProbableValue\n",
        "from text_tools import untokenize\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def convert(v):\n",
        "  \n",
        "  v_converted = copy.copy(v)\n",
        "  if v.currency in currency_converter:\n",
        "    v_converted.value = currency_converter[v.currency] * v.value\n",
        "    v_converted.currency = 'RUB'\n",
        "    return v_converted\n",
        "  else:\n",
        "    display(HTML(as_error_html(\n",
        "      f\"–º—ã –Ω–µ –≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏ (–ø–æ–∫–∞) –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å {v.currency} --> RUB. –≠—Ç–æ –≤–æ–æ–±—â–µ –≤–∞–ª—é—Ç–∞ –∫–∞–∫–æ–π —Å—Ç—Ä–∞–Ω—ã? –†—É–º—ã–Ω–∏–∏?\")))\n",
        "    return v\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "def _combine_constraints_in_group(group_c, verbose=False):\n",
        "  # print(group_c)\n",
        "  # print(group_c['section'])\n",
        "\n",
        "  data = {\n",
        "    'name': group_c['section'],\n",
        "    'ranges': {}\n",
        "  }\n",
        "\n",
        "  sentences = group_c['sentences']\n",
        "  #   print (charter_constraints[head_group]['sentences'])\n",
        "  sentence_id = 0\n",
        "  for sentence in sentences:\n",
        "    constraint_low = None\n",
        "    constraint_up = None\n",
        "\n",
        "    sentence_id += 1\n",
        "    #     print (sentence['constraints'])\n",
        "\n",
        "    s_constraints = sentence['constraints']\n",
        "    # –±–æ–ª—å—à–∏–µ –∏—â–µ–º\n",
        "    maximals = [x for x in s_constraints if x.value.sign > 0]\n",
        "\n",
        "    if len(maximals) > 0:\n",
        "      constraint_low = min(maximals, key=lambda item: convert(item.value, currency_converter).value)\n",
        "      if verbose:\n",
        "        print(\"all maximals:\")\n",
        "        renderer.render_values(maximals)\n",
        "        print('\\t\\t\\t constraint_low', constraint_low.value.value)\n",
        "        renderer.render_values([constraint_low])\n",
        "\n",
        "    minimals = [x for x in s_constraints if x.value.sign <= 0]\n",
        "    if len(minimals) > 0:\n",
        "      constraint_up = min(minimals, key=lambda item: convert(item.value, currency_converter).value)\n",
        "      if verbose:\n",
        "        print(\"all: minimals\")\n",
        "        renderer.render_values(minimals)\n",
        "        print('\\t\\t\\t constraint_upper', constraint_up.value.value)\n",
        "        renderer.render_values([constraint_up])\n",
        "        print(\"----X\")\n",
        "\n",
        "    if constraint_low is not None or constraint_up is not None:\n",
        "      data['ranges'][sentence_id] = VConstraint(constraint_low, constraint_up, group_c)\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "def find_ranges_by_group(charter_constraints):\n",
        "  ranges_by_group = {}\n",
        "  for head_group in charter_constraints:\n",
        "    #     print('-' * 20)\n",
        "    group_c = charter_constraints[head_group]\n",
        "    data = _combine_constraints_in_group(group_c)\n",
        "    ranges_by_group[head_group] = data\n",
        "  return ranges_by_group\n",
        "\n",
        "\n",
        "def select_most_confident_if_almost_equal(a: ProbableValue, alternative: ProbableValue, equality_range=0):\n",
        "  if abs(convert(a.value).value - convert(alternative.value).value) < equality_range:\n",
        "    if a.confidence > alternative.confidence:\n",
        "      return a\n",
        "    else:\n",
        "      return alternative\n",
        "  return a\n",
        "\n",
        "\n",
        "def find_contract_best_value(contract):\n",
        "  best_value: ProbableValue = max(contract.contract_values,\n",
        "                                  key=lambda item: convert(item.value, currency_converter).value)\n",
        "\n",
        "  most_confident_value = max(contract.contract_values, key=lambda item: item.confidence)\n",
        "  best_value = select_most_confident_if_almost_equal(best_value, most_confident_value, 20)\n",
        "\n",
        "  return best_value\n",
        "\n",
        "\n",
        "best_value = find_contract_best_value(contract)\n",
        "\n",
        "\n",
        "# rendering:----------------------------\n",
        "\n",
        "\n",
        "def _render_violations(ranges_by_group, best_value):\n",
        "  for group_key in ranges_by_group:\n",
        "    group = ranges_by_group[group_key]\n",
        "    #   print(group['name'])\n",
        "    display(HTML(as_headline_2(group['name'])))\n",
        "\n",
        "    for rk in group['ranges']:\n",
        "      r = group['ranges'][rk]\n",
        "      display(HTML(r.check_contract_value(best_value, currency_converter, renderer)))\n",
        "\n",
        "\n",
        "print(\"–°—É–º–º–∞ –î–æ–≥–æ–≤–æ—Ä–∞:\")\n",
        "renderer.render_values([best_value])\n",
        "renderer.render_color_text(best_value.value.context[0], best_value.value.context[1], _range=[0, 1])\n",
        "\n",
        "_render_violations(\n",
        "  find_ranges_by_group(charter_constraints),\n",
        "  best_value)\n",
        "\n",
        "display(HTML(renderer.render_constraint_values(charter_constraints)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T1D7Zdk9L5GY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#~~~~ Garbage, to be removed"
      ]
    },
    {
      "metadata": {
        "id": "ItuAG1-lClzz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m4fYh_qZL4Kb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ijcdJr7MCXgI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# violations "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IiDHL0oNGfOU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from IPython.core.display import display, HTML\n",
        "def render_subj(self, doc):\n",
        "      from demo import subject_types_dict\n",
        "      subj=doc.subject\n",
        "      s_name=subject_types_dict[ subj[0]].upper()\n",
        "      \n",
        "      display(HTML(f'–ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞:<h3 style=\"margin:0\">{s_name}<sup> {subj[0]}</sup> </h3> confidence:{subj[1]:20,.2f}'))\n",
        "\n",
        "r=GLOBALS__['renderer']\n",
        "# GLOBALS__['renderer'].render_subj = render_subj \n",
        "\n",
        "import types\n",
        "r.render_subj = types.MethodType( render_subj, r )\n",
        "\n",
        "contract = GLOBALS__['ContractAnlysingContext'].contract\n",
        "GLOBALS__['renderer'].render_subj(contract)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KcCp4a1F-gl0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "doc = GLOBALS__['CharterAnlysingContext'].doc\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "\n",
        "def render_contents(doc):\n",
        "  html='<h3>–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞</h4>'\n",
        "  html+=\"<ul>\"\n",
        "  for i in doc.structure.headline_indexes:\n",
        "    line = doc.structure.structure[i].to_string(doc.tokens_cc)\n",
        "    html+=f'<li> {line} <sup>line {i}</sup></li>'\n",
        "  html+=\"</ul>\"\n",
        " \n",
        "  \n",
        "  display(HTML(html))\n",
        "    \n",
        "render_contents(doc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uHc0PpyRMq5r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(GLOBALS__['ContractAnlysingContext'].contract)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P_2rjssX0KUp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# constraints = GLOBALS__['CharterAnlysingContext'].constraints\n",
        "\n",
        "# GLOBALS__['renderer'].render_values(GLOBALS__['ContractAnlysingContext'].contract_values)\n",
        "# GLOBALS__['renderer'].render_charter_parsing_results(GLOBALS__['CharterAnlysingContext'].org, GLOBALS__['CharterAnlysingContext'].constraints)\n",
        "\n",
        "\n",
        "# # for i in \n",
        "\n",
        "# for headkey in constraints:\n",
        "#   cc = constraints[headkey]\n",
        "#   print (cc)\n",
        "#   print (cc['section'])\n",
        "#   print (cc['caption'])\n",
        "  \n",
        "#   for s in cc['sentences']:\n",
        "#     print ('\\t\\t',s['constraints'])\n",
        "#     c = s['constraints']\n",
        "#     for vc in c:\n",
        "#       print(f'\\t\\t\\t {vc.value} \\t {vc.sign} \\t {vc.currency}')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}