{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84416aa0",
   "metadata": {
    "colab_type": "text",
    "id": "JbsxFAqC6pjQ",
    "papermill": {
     "duration": 0.02715,
     "end_time": "2021-08-03T13:00:10.959150",
     "exception": false,
     "start_time": "2021-08-03T13:00:10.932000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a63d3c58-2d3a-4f27-a017-c9acd65e4806",
   "metadata": {
    "papermill": {
     "duration": 0.021947,
     "end_time": "2021-08-03T13:00:10.998129",
     "exception": false,
     "start_time": "2021-08-03T13:00:10.976182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_DOC_ID = '612cdb1dea1085618e02fee3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d79173",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JoHJkn9yQIgg",
    "papermill": {
     "duration": 1.861673,
     "end_time": "2021-08-03T13:00:12.870686",
     "exception": false,
     "start_time": "2021-08-03T13:00:11.009013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - 2023-06-17 15:14:17,961 - retrain_ipynb - --=logging started=--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "Running on CPU:arm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import platform\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "logger = logging.getLogger('retrain_ipynb')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(levelname)s - %(asctime)s - %(name)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.debug('--=logging started=--')\n",
    "\n",
    "print(tf.__version__)\n",
    "CPU = platform.processor()\n",
    "print (f'Running on CPU:{CPU}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e198c1d",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZiBqnGnQfKWF",
    "papermill": {
     "duration": 0.016512,
     "end_time": "2021-08-03T13:00:12.895142",
     "exception": false,
     "start_time": "2021-08-03T13:00:12.878630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[gpn_config.py:18 -             <module>() ] config file\n",
      "[gpn_config.py:19 -             <module>() ] /Users/artem/work/nemo/analyser/config-test.yml\n",
      "[gpn_config.py:28 -           configured() ] ⚠️ GPN_WORK_DIR: config variable is not set, refer /Users/artem/work/nemo/analyser/config-test.yml\n",
      "/Users/artem/work/nemo/analyser/analyser/hyperparams.py:17: UserWarning: please set GPN_WORK_DIR environment variable\n",
      "  warnings.warn('please set GPN_WORK_DIR environment variable')\n",
      "[hyperparams.py:29 -             <module>() ] ⚙️ work_dir      [/Users/artem/work/nemo/work]\n",
      "[hyperparams.py:30 -             <module>() ] ⚙️ models_path   [/Users/artem/work/nemo/analyser/analyser/vocab]\n",
      "[hyperparams.py:31 -             <module>() ] ⚙️ reports_dir   [/Users/artem/work/nemo/analyser/analyser/training_reports]\n",
      "[hyperparams.py:32 -             <module>() ] ⚙️ datasets_dir  [/Users/artem/work/nemo/work/datasets]\n",
      "[hyperparams.py:33 -             <module>() ] ⚙️ notebooks_dir [/Users/artem/work/nemo/analyser/analyser/trainsets]\n",
      "[gpn_config.py:28 -           configured() ] ⚠️ TFHUB_CACHE_DIR: config variable is not set, refer /Users/artem/work/nemo/analyser/config-test.yml\n",
      "[gpn_config.py:28 -           configured() ] ⚠️ TRANSFORMERS_CACHE: config variable is not set, refer /Users/artem/work/nemo/analyser/config-test.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nemoware Analyser v23.6.8.1\n",
      "USING WORKDIR: [/Users/artem/work/nemo/work]\n",
      " configure GPN_WORK_DIR to override\n"
     ]
    }
   ],
   "source": [
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "import analyser.hyperparams \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c55a33b",
   "metadata": {
    "papermill": {
     "duration": 0.008023,
     "end_time": "2021-08-03T13:00:12.947888",
     "exception": false,
     "start_time": "2021-08-03T13:00:12.939865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34cde660",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "pexvDJbAtZM0",
    "outputId": "4f7e6e34-d675-423d-d102-1020d49d854f",
    "papermill": {
     "duration": 1.475714,
     "end_time": "2021-08-03T13:00:14.431563",
     "exception": false,
     "start_time": "2021-08-03T13:00:12.955849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[documents.py:266 -             __init__() ] loading word cases stats model from: /Users/artem/work/nemo/analyser/analyser/vocab/word_cases_stats.pickle\n",
      "[gpn_config.py:28 -           configured() ] ⚠️ GPN_CSGK_WSDL: config variable is not set, refer /Users/artem/work/nemo/analyser/config-test.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperParameters.subsidiary_name_match_min_jaro_similarity 0.9649122807017544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tools.py:28 -             __init__() ] model_checkpoint_path: /Users/artem/work/nemo/analyser/analyser/vocab\n",
      "[gpn_config.py:36 -               secret() ] ⚠️ GPN_CURRENCY_USER: environment variable is not set\n",
      "[gpn_config.py:36 -               secret() ] ⚠️ GPN_CURRENCY_PASSWORD: environment variable is not set\n",
      "[gpn_config.py:28 -           configured() ] ⚠️ GPN_CURRENCY_URL: config variable is not set, refer /Users/artem/work/nemo/analyser/config-test.yml\n",
      "[gpn_config.py:28 -           configured() ] ⚠️ GPN_CLASSIFIER_SERVICE_URL: config variable is not set, refer /Users/artem/work/nemo/analyser/config-test.yml\n",
      "[tools.py:28 -             __init__() ] model_checkpoint_path: /Users/artem/work/nemo/analyser/analyser/vocab\n",
      "[tools.py:117 -           init_model() ] weights loaded: /Users/artem/work/nemo/analyser/analyser/vocab/make_att_model_03.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"make_att_model_03\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_text_emb (InputLayer)     [(None, None, 1024)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_features (InputLayer)     [(None, None, 15)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_text_emb_norm (LayerNorma (None, None, 1024)   2048        input_text_emb[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "token_features_norm (LayerNorma (None, None, 15)     30          token_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "rmb_plus_tokens (Concatenate)   (None, None, 1039)   0           input_text_emb_norm[0][0]        \n",
      "                                                                 token_features_norm[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_reduced (Bidirectiona (None, None, 256)    1196032     rmb_plus_tokens[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "amnesia (Dropout)               (None, None, 256)    0           embedding_reduced[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, None, 256)    1024        amnesia[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_0/multiheadattention (M (None, None, 256)    263168      bn1[0][0]                        \n",
      "                                                                 bn1[0][0]                        \n",
      "                                                                 bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_0/att_dropout (Dropout) (None, None, 256)    0           encoder_0/multiheadattention[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, None, 256)    0           bn1[0][0]                        \n",
      "                                                                 encoder_0/att_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_0/att_layernormalizatio (None, None, 256)    512         tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_0/ffn (Sequential)      (None, None, 256)    65920       encoder_0/att_layernormalization[\n",
      "__________________________________________________________________________________________________\n",
      "encoder_0/ffn_dropout (Dropout) (None, None, 256)    0           encoder_0/ffn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, None, 256)    0           encoder_0/att_layernormalization[\n",
      "                                                                 encoder_0/ffn_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_0/ffn_layernormalizatio (None, None, 256)    512         tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/multiheadattention (M (None, None, 256)    263168      encoder_0/ffn_layernormalization[\n",
      "                                                                 encoder_0/ffn_layernormalization[\n",
      "                                                                 encoder_0/ffn_layernormalization[\n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/att_dropout (Dropout) (None, None, 256)    0           encoder_1/multiheadattention[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, None, 256)    0           encoder_0/ffn_layernormalization[\n",
      "                                                                 encoder_1/att_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/att_layernormalizatio (None, None, 256)    512         tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/ffn (Sequential)      (None, None, 256)    65920       encoder_1/att_layernormalization[\n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/ffn_dropout (Dropout) (None, None, 256)    0           encoder_1/ffn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, None, 256)    0           encoder_1/att_layernormalization[\n",
      "                                                                 encoder_1/ffn_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/ffn_layernormalizatio (None, None, 256)    512         tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "bn2 (BatchNormalization)        (None, None, 256)    1024        encoder_1/ffn_layernormalization[\n",
      "__________________________________________________________________________________________________\n",
      "O1_tagging_tanh (LSTM)          (None, None, 30)     34440       bn2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "some (Bidirectional)            (None, 32)           34944       bn2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "O1_tagging (ThresholdLayer)     (None, None, 30)     1           O1_tagging_tanh[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "O2_subject (Dense)              (None, 43)           1419        some[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 1,931,186\n",
      "Trainable params: 1,930,162\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "from integration.db import get_doc_by_id\n",
    "from analyser.persistence import DbJsonDoc\n",
    "from integration.db import get_mongodb_connection\n",
    "\n",
    "from analyser.ml_tools import SemanticTag, relu\n",
    "from analyser.runner import save_analysis \n",
    "\n",
    "from analyser.hyperparams import models_path\n",
    "\n",
    "from pymongo import ASCENDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91655b0f-55dd-4c58-88fd-4623fe2dada4",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ad79cd-e1cf-459b-812d-6aba572807c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_support.embedder_elmo import ElmoEmbedder\n",
    "\n",
    "embedder = ElmoEmbedder.get_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70d8cbbf-fc89-45b8-bff4-9c437a94add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_len = 400 #TODO: move to config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d0241f2-2fbe-4d68-9ff8-a3870cc636c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/artem/work/nemo/analyser/analyser/vocab'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230cd10b-c8bc-4ca9-becd-b62fd596b897",
   "metadata": {},
   "source": [
    "# Analysing sample doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7377e6b-d9d8-461e-8447-e3948b62886f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 512)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from bson import ObjectId\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "\n",
    "centroids = np.load(Path(models_path) / \"insides_patterns.npy\")\n",
    "print(centroids.shape)\n",
    "\n",
    "\n",
    "n_clusters = centroids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a38fa90-ef5a-4eab-9261-060b96739daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TEST_DOC_ID)\n",
    "sample_id     = ObjectId(TEST_DOC_ID) \n",
    "sample_db_doc = get_doc_by_id(sample_id)\n",
    "# print(sample_db_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1086a-6e64-40d5-b0a8-110bd6d97bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyser.legal_docs import tokenize_doc_into_sentences_map\n",
    "\n",
    "\n",
    "sample_j_doc  = DbJsonDoc(sample_db_doc)\n",
    "sample_doc    = sample_j_doc.asLegalDoc()\n",
    "\n",
    "\n",
    "\n",
    "sample_doc.sentence_map = tokenize_doc_into_sentences_map(sample_doc.tokens_map.get_full_text(), mean_len)\n",
    "\n",
    "\n",
    "\n",
    "doc_embeddings = embedder.embedd_strings(sample_doc.sentence_map.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b7fe60-c4fc-4841-94ca-5ce09278cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_doc.attributes_tree.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0672b351-d739-46a8-bf55-8f8bd1807225",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c63fc-8e20-4cd6-b0d8-0d587581e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = doc_embeddings\n",
    "distance_matrix = pairwise_distances(X, centroids, metric='cosine', n_jobs=1)\n",
    "# distance_matrix = relu ( ((distance_matrix * -1)+1) , _mx-0.01)\n",
    "\n",
    "distance_matrix = (distance_matrix * -1)+1.0\n",
    "distance_matrix = distance_matrix.T\n",
    "plt.figure(figsize=(30,4))\n",
    "plt.imshow( distance_matrix )\n",
    "# plt.plot(np.array(distance_matrix.T[0]))\n",
    "print(len(distance_matrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d985d00-993d-4189-bf97-10dd957603ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO: move to analyser code\n",
    "# sample_doc.attributes_tree.__dict__.update(sample_j_doc.analysis['attributes_tree']['contract'])\n",
    "print(distance_matrix.std())\n",
    "print(distance_matrix.mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf618850-ce6c-43e8-bb09-30f654090e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda5d57f-deb5-4ebb-ae07-9d9209cbc99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "eps = 0.01\n",
    "threshold = 0.82 #0.9 *  distance_matrix.max()\n",
    "print('threshold', threshold)\n",
    "print()\n",
    "sim_max = threshold\n",
    "i_max = 0\n",
    "plt.figure(figsize=(30,6))\n",
    "plt.plot([threshold]*len(sample_doc.sentence_map), alpha=0.4 )\n",
    "for k in range(n_clusters):    \n",
    "    print('-'*20)\n",
    " \n",
    "    av = distance_matrix[k]  #relu(v, threshold) ## attention vector\n",
    "    \n",
    "    ii = av.argmax()\n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "#     if (sim > threshold):\n",
    "        \n",
    "#         print (sample_doc.tokens_map.tokens[_span[0]:_span[1]  ] )\n",
    "        \n",
    "        \n",
    "    if av[ii] > sim_max:\n",
    "        plt.plot(av, alpha=0.5)\n",
    "        \n",
    "        print( f\"{k}=cluster \\t {av[ii]}=similarity, \\n {sample_doc.sentence_map.tokens[ii]} \")\n",
    "        char_span =  sample_doc.sentence_map.map[ii]\n",
    "        \n",
    "        \n",
    "        _span = sample_doc.sentence_map.remap_span((ii, ii+1), sample_doc.tokens_map)\n",
    "        print(\"span (chars):\", char_span, _span)\n",
    "        tag = SemanticTag( 'insideInformation','Unknown', span=_span, confidence=np.float(av[ii]))\n",
    "        print(tag)\n",
    "        \n",
    "        i_max = k\n",
    "        sim_max = av[ii]\n",
    "        \n",
    "        setattr(sample_doc.attributes_tree, \"insideInformation\", tag)\n",
    "plt.plot(distance_matrix.mean(axis=0), alpha=0.5, color='black')  \n",
    "plt.plot(distance_matrix[i_max] , alpha=0.9, color='red')  \n",
    "\n",
    "\n",
    "mean_ = distance_matrix.mean( )\n",
    "plt.plot([mean_]*len(sample_doc.sentence_map), alpha=0.4 )\n",
    "\n",
    "print(sim_max, i_max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984291da-3153-450f-9d6f-d9acbaeb14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# save_analysis(sample_j_doc, sample_doc, state = sample_j_doc.state )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b890e-3f6a-4ec1-9c42-7d533302bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,6))\n",
    "relu_threshold =  distance_matrix.mean(axis=0).max()*0.99\n",
    "plt.plot([relu_threshold]*len(sample_doc.sentence_map), alpha=0.4 )\n",
    "plt.plot(distance_matrix.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c53943-f670-4a2b-88f1-1f200ffdf60b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from colab_support.renderer import HtmlRenderer\n",
    "import matplotlib as matplotlib\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "\n",
    "class DemoRenderer(HtmlRenderer):\n",
    "  def render_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None, separator=' '):\n",
    "    html = self.to_color_text(tokens, weights, colormap, print_debug, _range, separator=separator)\n",
    "    display(HTML(html))\n",
    "\n",
    "  def to_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None, separator=' '):\n",
    "    return super()._to_color_text(tokens, weights, matplotlib, colormap=colormap, _range=_range, separator=separator)\n",
    "\n",
    "renderer_ = DemoRenderer()\n",
    "\n",
    "\n",
    "renderer_.render_color_text(sample_doc.sentence_map.tokens, relu(distance_matrix[i_max]-distance_matrix.mean(axis=0), 0.1), _range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c291b363-8006-4f3e-b1b3-b0b639de7927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9eF-UGHyh-C9",
    "7X_zYCYEdlPM",
    "lyI4hbTRFjyM"
   ],
   "name": "Local: structure keras uber model - clean train, evaluate, test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.184245,
   "end_time": "2021-08-03T13:00:20.283835",
   "environment_variables": {},
   "exception": null,
   "input_path": "trainsets/export_trainset.ipynb",
   "output_path": "trainsets/export_trainset.ipynb",
   "parameters": {},
   "start_time": "2021-08-03T13:00:10.099590",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
