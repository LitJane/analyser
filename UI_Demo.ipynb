{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UI-Demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/compartia/nlp_tools/blob/demo/UI_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "raaJNhjYXuoW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#.init"
      ]
    },
    {
      "metadata": {
        "id": "DmfQVYoSXqf8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##utils"
      ]
    },
    {
      "metadata": {
        "id": "YYCa_a2lXjxP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "import uuid\n",
        "from google.colab import output\n",
        "from google.colab import files\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "from google.colab import widgets\n",
        "from google.colab import output\n",
        "\n",
        "\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "def interactive_upload(filetype):\n",
        "  \n",
        "  import docx2txt\n",
        "  \n",
        "  print(f'Please select \"{filetype}\" .docx file:')\n",
        "  uploaded = files.upload()\n",
        "  docs=[]\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "    with open(fn, \"wb\") as df:\n",
        "      df.write(uploaded[fn])\n",
        "      df.close()\n",
        "\n",
        "    # extract text\n",
        "  \n",
        "    text = ''\n",
        "    try:\n",
        "      text = docx2txt.process(fn)\n",
        "    except:\n",
        "      print(\"Unexpected error:\", sys.exc_info())\n",
        "      os.system('antiword -w 0 \"' + fn + '\" > \"' + fn + '.txt\"')\n",
        "      with open(fn + '.txt') as f:\n",
        "        text = f.read()\n",
        "    print(\"–°–∏–º–≤–æ–ª–æ–≤ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ:\", len(text))\n",
        "    docs.append(text)\n",
        "    return docs\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "class InvokeButton(object):\n",
        "  def __init__(self, title, callback = None):\n",
        "    self.title = title\n",
        "    self.callback = callback\n",
        "\n",
        "#   def _repr_html_(self):\n",
        "  def render(self):\n",
        "    self.callback_id = 'button-' + str(uuid.uuid4())\n",
        "    if self.callback:\n",
        "      output.register_callback(self.callback_id, self.callback)\n",
        "\n",
        "    template =f'''<button style=\"padding:5px; font-size:16px; margin:15px\"  id=\"{self.callback_id}\">{self.title}</button>\n",
        "        <script>\n",
        "          document.querySelector(\"#{self.callback_id}\").onclick = (e) => {{\n",
        "            google.colab.kernel.invokeFunction(\"{self.callback_id}\", [], {{}})\n",
        "            e.preventDefault();\n",
        "          }};\n",
        "        </script>'''\n",
        "    display(IPython.display.HTML(template))\n",
        "    \n",
        "def upload_file_b(tb, type):\n",
        "  with output.redirect_to_element('#upload_area'): \n",
        "  \n",
        "    print(f'–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Ç–∏–ø–∞ \"{type}\"')\n",
        "    print('Select .docx files:')\n",
        "    uploaded = interactive_upload(type)\n",
        "\n",
        "#   with tb.output_to(type):\n",
        "#     for fn in uploaded:\n",
        "#       print(f'User uploaded file \"{fn[0:1000]}\" with length {len(fn)} bytes')\n",
        "\n",
        "def clear_div(elementID):\n",
        "  display(IPython.display.Javascript(f'document.getElementById(\"{elementID}\").innerHTML = \"\";'))\n",
        "\n",
        "def replace_self_elem(elementID, text):\n",
        "  #print(f'Replace: {elementID}')\n",
        "  display(IPython.display.Javascript(f'document.getElementById(\"{elementID}\").parentElement.innerHTML = \"{text}\";'))\n",
        "\n",
        "def toggle_element(elementId):\n",
        "  display(IPython.display.Javascript(f''' \n",
        "    var x = document.getElementById(\"{elementId}\");\n",
        "    if (x.style.display === \"none\")\n",
        "      x.style.display = \"block\";\n",
        "    else\n",
        "      x.style.display = \"none\";\n",
        "    '''))\n",
        "  \n",
        "def call_invoke(title, callback):\n",
        "  with output.redirect_to_element('#items'):    \n",
        "    InvokeButton(title, callback).render()\n",
        "    \n",
        "  clear_div(\"upload_area\")\n",
        "  \n",
        "  \n",
        "GLOBALS__ = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TTYEFnsrX_LL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#–î–µ–º–æ"
      ]
    },
    {
      "metadata": {
        "id": "st1uyXGyR1WN",
        "colab_type": "code",
        "outputId": "80ae0e17-cf29-45e1-c980-91e27edace99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title –ù–∞—Å—Ç—Ä–æ–π–∫–∏ { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "USD_to_RUB = 34.02 #@param {type:\"number\"}\n",
        "RUB_to_USD = 1.0/USD_to_RUB\n",
        "\n",
        "# print('USD_to_RUB=',USD_to_RUB)\n",
        "# print('RUB_to_USD=',RUB_to_USD)\n",
        "\n",
        "\n",
        "\n",
        "currency_converter = {\n",
        "  'USD': USD_to_RUB,\n",
        "  'RUB': 1.0\n",
        "}\n",
        "\n",
        "print(currency_converter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'USD': 164.02, 'RUB': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CPxjslnsM6Y2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# @title –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–µ—Ä—Å–∏–∏ { vertical-output: true, output-height: 800, display-mode: \"form\" }\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "def interactive_upload(filetype):\n",
        "  from google.colab import files\n",
        "  import docx2txt\n",
        "\n",
        "  print(f'Please select \"{filetype}\" .docx file:')\n",
        "  uploaded = files.upload()\n",
        "  docs = []\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "    with open(fn, \"wb\") as df:\n",
        "      df.write(uploaded[fn])\n",
        "      df.close()\n",
        "\n",
        "    # extract text\n",
        "\n",
        "    text = ''\n",
        "    try:\n",
        "      text = docx2txt.process(fn)\n",
        "    except:\n",
        "      print(\"Unexpected error:\", sys.exc_info())\n",
        "      os.system('antiword -w 0 \"' + fn + '\" > \"' + fn + '.txt\"')\n",
        "      with open(fn + '.txt') as f:\n",
        "        text = f.read()\n",
        "    print(\"–°–∏–º–≤–æ–ª–æ–≤ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ:\", len(text))\n",
        "    docs.append(text)\n",
        "    return docs\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# ====================================\n",
        "_git_branch = \"demo\"  # @param {type:\"string\"}\n",
        "# ====================================\n",
        "# ====================================\n",
        " \n",
        "\n",
        "\n",
        "# AZ:-IMPORT CODE GITHUB-----------------------------------------------------------------------------------\n",
        "def _init_import_code_from_gh():\n",
        "  if '_init_import_code_from_gh' in GLOBALS__:\n",
        "    print('üëå code already imported from GitHub!')\n",
        "    return\n",
        "\n",
        "  print(f\"fetching code from GitHub.....{_git_branch}\")\n",
        "  l1 = 'rm -r nlp_tools'\n",
        "  l2 = f'git clone --single-branch --branch {_git_branch} https://github.com/compartia/nlp_tools.git nlp_tools'\n",
        "  os.system(l1)\n",
        "  os.system(l2)\n",
        "  import subprocess\n",
        "  r = subprocess.check_output(\n",
        "    'cd nlp_tools\\ngit rev-list --reverse HEAD | awk \"{ print NR }\" | tail -n 1\\ngit branch\\ngit log -3 --pretty=%B',\n",
        "    shell=True)\n",
        "  print('ü¶ä GIT revision:', str(r).replace('\\\\n', '\\t'))\n",
        "\n",
        "  sys.path.insert(0, 'nlp_tools')\n",
        "\n",
        "  # self-test\n",
        "  from text_tools import untokenize\n",
        "  untokenize(['code', 'ok'])\n",
        "  print(untokenize(['code', 'imported', 'OK üëç']))\n",
        "\n",
        "  print('installing antiword...')\n",
        "  r = subprocess.check_output('sudo apt-get install antiword', shell=True)\n",
        "  print(r)\n",
        "\n",
        "  print('installing docx2txt...')\n",
        "  r = subprocess.check_output(\"pip install docx2txt\", shell=True)\n",
        "  r = print(r)\n",
        "  print(r)\n",
        "  GLOBALS__['_init_import_code_from_gh'] = True\n",
        "  print('‚ù§Ô∏è DONE importing Code fro GitHub')\n",
        "\n",
        "\n",
        "# AZ:-INIT ELMO-----------------------------------------------------------------------------------\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "\n",
        "def _import_elmo():\n",
        "  \"\"\"\n",
        "  ACHTUNG!! this method is called later by ElmoEmbedder\n",
        "  \"\"\"\n",
        "\n",
        "  #   if 'elmo' in GLOBALS__:\n",
        "  #     print('üëå Tensorflow hub.Module is already imported ')\n",
        "  #     return GLOBALS__['elmo']\n",
        "\n",
        "  elmo = hub.Module('https://storage.googleapis.com/az-nlp/elmo_ru-news_wmt11-16_1.5M_steps.tar.gz',\n",
        "                    trainable=False)  # twitter\n",
        "  print('‚ù§Ô∏è ‚ù§Ô∏è ‚ù§Ô∏è DONE (re)importing Tensorflow hub.Module ')\n",
        "  print('Tensorflow version is', tf.__version__)\n",
        "\n",
        "  return elmo\n",
        "\n",
        "\n",
        "#   GLOBALS__['elmo'] = elmo\n",
        "\n",
        "#   print(GLOBALS__['elmo'].__dict__)\n",
        "#   return GLOBALS__['elmo']\n",
        "\n",
        "\n",
        "# AZ:-INIT EMBEDDER-----------------------------------------------------------------------------------\n",
        "\n",
        "def _init_embedder():\n",
        "  if 'elmo_embedder' in GLOBALS__:\n",
        "    print('üëå Embedder is already created! ')\n",
        "    return\n",
        "\n",
        "  from embedding_tools import ElmoEmbedder\n",
        "  GLOBALS__['elmo_embedder'] = ElmoEmbedder(_import_elmo(), tf, 'elmo', _import_elmo)\n",
        "\n",
        "  print('‚ù§Ô∏è DONE creating words embedding model')\n",
        "  return GLOBALS__['elmo_embedder']\n",
        "\n",
        "\n",
        "# AZ:-Init chartes context-----------------------------------------------------------------------------------\n",
        "def _init_charters():\n",
        "  if 'CharterAnlysingContext' in GLOBALS__:\n",
        "    print('üëå Charters-related tools are already inited ')\n",
        "    return\n",
        "\n",
        "  from demo_charter import CharterAnlysingContext\n",
        "  GLOBALS__['CharterAnlysingContext'] = CharterAnlysingContext(GLOBALS__['elmo_embedder'], GLOBALS__['renderer'])\n",
        "  print('‚ù§Ô∏è DONE initing Charters-related tools and models ')\n",
        "\n",
        "\n",
        "def _init_contracts():\n",
        "  if 'ContractAnlysingContext' in GLOBALS__:\n",
        "    print('üëå Contracts-related tools are already inited ')\n",
        "    return\n",
        "\n",
        "  from demo import ContractAnlysingContext\n",
        "  GLOBALS__['ContractAnlysingContext'] = ContractAnlysingContext(GLOBALS__['elmo_embedder'], GLOBALS__['renderer'])\n",
        "  print('‚ù§Ô∏è DONE initing Contracts-related tools and models ')\n",
        "\n",
        "\n",
        "# AZ:- THE CODE----------------------------------------------------------------------------------\n",
        "def _init_the_code(reset=False):\n",
        "  if '_init_the_code' in GLOBALS__ and not reset:\n",
        "    print('üëå Code is alredy imported!')\n",
        "    return\n",
        "\n",
        "  import matplotlib as mpl\n",
        "  from IPython.core.display import display, HTML\n",
        "  import matplotlib.pyplot as plt\n",
        "  from renderer import AbstractRenderer, head_types_colors\n",
        "  from transaction_values import ValueConstraint\n",
        "  from legal_docs import org_types\n",
        "  from demo_charter import head_types_dict, head_types\n",
        "\n",
        "  class DemoRenderer(AbstractRenderer):\n",
        "\n",
        "    def render_subj(self, doc):\n",
        "      from demo import subject_types_dict\n",
        "      subj = doc.subject\n",
        "      s_name = subject_types_dict[subj[0]].upper()\n",
        "\n",
        "      display(\n",
        "        HTML(f'–ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞:<h3 style=\"margin:0\">{s_name}<sup> {subj[0]}</sup> </h3> confidence:{subj[1]:20,.2f}'))\n",
        "\n",
        "    def sign_to_text(self, sign: int):\n",
        "      if sign < 0: return \" &lt; \"\n",
        "      if sign > 0: return \" &gt; \"\n",
        "      return ' = '\n",
        "\n",
        "    def probable_value_to_html(self, pv):\n",
        "\n",
        "      vc = pv.value\n",
        "\n",
        "      color = '#333333'\n",
        "      if vc.sign > 0:\n",
        "        color = '#993300'\n",
        "      elif vc.sign < 0:\n",
        "        color = '#009933'\n",
        "\n",
        "      return f'<b style=\"color:{color}\">{self.sign_to_text(vc.sign)} {vc.currency} {vc.value:20,.2f} confidence={pv.confidence:20,.2f}</b> '\n",
        "\n",
        "    def render_contents(doc):\n",
        "      html = '<h3>–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞</h4>'\n",
        "      html += \"<ul>\"\n",
        "      for i in doc.structure.headline_indexes:\n",
        "        line = doc.structure.structure[i].to_string(doc.tokens_cc)\n",
        "        html += f'<li> {line} <sup>line {i}</sup></li>'\n",
        "      html += \"</ul>\"\n",
        "\n",
        "      display(HTML(html))\n",
        "\n",
        "    def render_sections(sections):\n",
        "      from legal_docs import HeadlineMeta\n",
        "      html = '<h3>–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ —Å–µ–∫—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞</h4>'\n",
        "      html += \"<ul>\"\n",
        "      for section_type in sections:\n",
        "        section: HeadlineMeta = sections[section_type]\n",
        "        body = section.body.untokenize_cc()[:1000]\n",
        "        headline = section.subdoc.untokenize_cc()[:500]\n",
        "        #     line = doc.structure.structure[i].to_string(doc.tokens_cc)\n",
        "        html += f'<li><h3> {headline} <sup>type: {section_type}</sup> </h3> <p>{body}</p> </li>'\n",
        "      html += \"</ul>\"\n",
        "\n",
        "      display(HTML(html))\n",
        "\n",
        "    def render_values(self, values):\n",
        "      if len(values) > 0:\n",
        "        for pv in values:\n",
        "          h = self.probable_value_to_html(pv)\n",
        "          display(HTML(h))\n",
        "      else:\n",
        "        display(HTML('—Å—É–º–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'))\n",
        "\n",
        "    def render_contents(self, doc):\n",
        "      html = '<h3>–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞</h4>'\n",
        "      html += \"<ul>\"\n",
        "      for i in doc.structure.headline_indexes:\n",
        "        line = doc.structure.structure[i].to_string(doc.tokens_cc)\n",
        "        html += f'<li> {line} <sup>line {i}</sup></li>'\n",
        "      html += \"</ul>\"\n",
        "\n",
        "      display(HTML(html))\n",
        "\n",
        "    def render_value_section_details(self, value_section_info):\n",
        "      value_section = value_section_info.body\n",
        "      headline_doc = value_section_info.subdoc\n",
        "\n",
        "      headline = headline_doc.untokenize_cc()\n",
        "\n",
        "      v_names = {\n",
        "        'value_attention_vector',\n",
        "        'novalue_attention_vector',\n",
        "\n",
        "        'novalue_attention_vector_local_contrast',\n",
        "        'value_attention_vector_tuned'}\n",
        "\n",
        "      fig = plt.figure(figsize=(20, 6))\n",
        "      ax = plt.axes()\n",
        "      for vector_name in v_names:\n",
        "        ax.plot(value_section.distances_per_pattern_dict[vector_name], label=vector_name, alpha=0.4);\n",
        "      ax.plot(value_section.distances_per_pattern_dict['value_attention_vector_tuned'], label=vector_name.upper(),\n",
        "              alpha=0.9, color='black');\n",
        "      plt.legend(loc='upper right')\n",
        "\n",
        "      text = self.to_color_text(value_section.tokens_cc,\n",
        "                                value_section.distances_per_pattern_dict['value_attention_vector_tuned'], _range=(0, 1))\n",
        "      html = f'<h3>{headline}</h3> <div style=\"margin-left:4em; font-size=90%\">{text}</div>'\n",
        "      display(HTML(html))\n",
        "\n",
        "    def to_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None):\n",
        "      if len(tokens) == 0:\n",
        "        return \" - empty -\"\n",
        "      if len(weights) != len(tokens):\n",
        "        raise ValueError(\"number of weights differs weights={} tokens={}\".format(len(weights), len(tokens)))\n",
        "\n",
        "      #   if()\n",
        "      vmin = weights.min()\n",
        "      vmax = weights.max()\n",
        "\n",
        "      if _range is not None:\n",
        "        vmin = _range[0]\n",
        "        vmax = _range[1]\n",
        "\n",
        "      if print_debug:\n",
        "        print(vmin, vmax)\n",
        "\n",
        "      norm = mpl.colors.Normalize(vmin=vmin - 0.5, vmax=vmax)\n",
        "      html = \"\"\n",
        "      cmap = mpl.cm.get_cmap(colormap)\n",
        "\n",
        "      for d in range(0, len(weights)):\n",
        "        word = tokens[d]\n",
        "        if word == ' ':\n",
        "          word = '&nbsp;_ '\n",
        "\n",
        "        html += '<span title=\"{} {:.4f}\" style=\"background-color:{}\">{} </span>'.format(\n",
        "          d,\n",
        "          weights[d],\n",
        "          mpl.colors.to_hex(cmap(norm(weights[d]))),\n",
        "          word)\n",
        "\n",
        "        #     html+='<span style=\"background-color:' +mpl.colors.to_hex(cmap(norm(weights[d]) ))+ '\">' + str(tokens[d]) + \" </span>\"\n",
        "        if tokens[d] == '\\n':\n",
        "          html += \"<br>\"\n",
        "\n",
        "      return html\n",
        "\n",
        "    def _render_sentence(self, sentence):\n",
        "      html = \"\"\n",
        "      constraints: List[ValueConstraint] = sentence['constraints']\n",
        "      for probable_v in constraints:\n",
        "        html += self.value_to_html(probable_v.value)\n",
        "\n",
        "      if len(constraints) > 0:\n",
        "        html += '<div style=\"border-bottom:1px solid #ccc; margin-top:1em\"></div>'\n",
        "        section = sentence['subdoc']\n",
        "        html += self.to_color_text(section.tokens, section.distances_per_pattern_dict['deal_value_attention_vector'])\n",
        "      return html\n",
        "\n",
        "    def render_constraint_values(self, rz):\n",
        "\n",
        "      html = ''\n",
        "      for head_type in rz.keys():\n",
        "\n",
        "        r_by_head_type = rz[head_type]\n",
        "\n",
        "        html += '<hr style=\"margin-top: 45px\">'\n",
        "        html += '<i style=\"padding:0; margin:0\">—Ä–µ—à–µ–Ω–∏—è –æ –ø–æ—Ä–æ–≥–æ–≤—ã—Ö —Å—É–º–º–∞—Ö, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç</i><h2 style=\"color:{}; padding:0;margin:0\">{}</h2>'.format(\n",
        "          head_types_colors[head_type],\n",
        "          head_types_dict[head_type])\n",
        "\n",
        "        sentences = r_by_head_type['sentences']\n",
        "        html += '<h4>{}</h4>'.format(r_by_head_type['caption'])\n",
        "        html += '<div style=\"padding-left:80px\">'\n",
        "\n",
        "        if True:\n",
        "          if len(sentences) > 0:\n",
        "            for sentence in sentences:\n",
        "              html += self._render_sentence(sentence)\n",
        "\n",
        "          else:\n",
        "            html += '<h4 style=\"color:crimson\">–ü–æ—Ä–æ–≥–æ–≤—ã–µ —Å—É–º–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω—ã</h4>'\n",
        "\n",
        "        html += '</div>'\n",
        "\n",
        "      return html\n",
        "\n",
        "    def render_charter_parsing_results(self, org, rz):\n",
        "      txt_html = self.to_color_text(org['tokens'], org['attention_vector'], _range=[0, 1])\n",
        "\n",
        "      html = '<div style=\"background:#eeeeff; padding:0.5em\"> recognized NE(s): <br><br> org type:<h3 style=\"margin:0\">  {} </h3>org full name:<h2 style=\"margin:0\">  {} </h2> <br>quote: <div style=\"font-size:90%; background:white\">{}</div> </div>'.format(\n",
        "        org['type_name'], org['name'], txt_html)\n",
        "      # html+=txt_html\n",
        "      html += self.render_constraint_values(rz)\n",
        "\n",
        "      display(HTML(html))\n",
        "\n",
        "    def render_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None):\n",
        "      html = self.to_color_text(tokens, weights, colormap, print_debug, _range)\n",
        "      display(HTML(html))\n",
        "\n",
        "    def print_results(self, doc, results):\n",
        "      result, (start, end), sentence, meta = results\n",
        "\n",
        "      html = \"<hr>\"\n",
        "\n",
        "      html += self._render_doc_subject_fragments(doc)\n",
        "\n",
        "      if result is None:\n",
        "        html += '<h2 style=\"color:red\">–°–£–ú–ú–ê –ù–ï –ù–ê–ô–î–ï–ù–ê</h2>'\n",
        "      else:\n",
        "        html += '<h2>' + str(result[0]) + ' ' + str(result[1]) + '</h2>'\n",
        "\n",
        "      for key in meta.keys():\n",
        "        html += '<div style=\"font-size:9px\">' + str(key) + \" = \" + str(meta[key]) + \"</div>\"\n",
        "\n",
        "      display(HTML(html))\n",
        "      self.render_color_text(doc.tokens[start:end], doc.sums[start:end])\n",
        "\n",
        "  GLOBALS__['renderer'] = DemoRenderer()\n",
        "\n",
        "  \n",
        "  # AZ:----------PROTOCOLS RENDERER-------------------------\n",
        "\n",
        "  from legal_docs import LegalDocument\n",
        "\n",
        "  import matplotlib as mpl\n",
        "  from IPython.core.display import display, HTML\n",
        "  from renderer import  as_headline_3\n",
        "  class ProtocolRenderer(DemoRenderer):\n",
        "\n",
        "    def winning_patterns_to_html(self, _tokens, ranges, winning_patterns, _range,\n",
        "                                 colormaps=['Reds', 'Purples', 'Blues', 'Greens', 'Greys']):\n",
        "      vmin = -ranges[1]\n",
        "      vmax = -ranges[0]\n",
        "\n",
        "      #     print(\"winning_patterns_to_html _range\", _range, \"min max=\", ranges)\n",
        "\n",
        "      norm = mpl.colors.Normalize(vmax=vmax, vmin=vmin)\n",
        "\n",
        "      cmaps = []\n",
        "\n",
        "      #     print (colormaps)\n",
        "      for n in colormaps:\n",
        "        cmap = mpl.cm.get_cmap(n)\n",
        "        cmaps.append(cmap)\n",
        "\n",
        "      html = \"\"\n",
        "\n",
        "      for d in _range:\n",
        "        winning_pattern_i = winning_patterns[d][0]\n",
        "        colormap = cmaps[winning_pattern_i % len(colormaps)]\n",
        "        normed = norm(-winning_patterns[d][1])\n",
        "        color = mpl.colors.to_hex(colormap(normed))\n",
        "        html += '<span title=\"' + '{} {:.2f}'.format(d, winning_patterns[d][\n",
        "          1]) + '\" style=\"background-color:' + color + '\">' + str(\n",
        "          _tokens[d]) + \" </span>\"\n",
        "        if _tokens[d] == '\\n':\n",
        "          html += \"<br>\"\n",
        "\n",
        "      return html\n",
        "\n",
        "    def _render_doc_subject_fragments(self, doc):\n",
        "      #     print(doc.per_subject_distances)\n",
        "\n",
        "      _html = \"\"\n",
        "      if doc.per_subject_distances is not None:\n",
        "\n",
        "        type = \"–î–æ–≥–æ–≤–æ—Ä  –±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏—è\"\n",
        "        if doc.per_subject_distances[0] > doc.per_subject_distances[1]:\n",
        "          type = \"–î–æ–≥–æ–≤–æ—Ä –≤–æ–∑–º–µ–∑–¥–Ω–æ–≥–æ –æ–∫–∞–∑–∞–Ω–∏—è —É—Å–ª—É–≥\"\n",
        "\n",
        "        _html += \"<h3>\" + type + \"</h3>\"\n",
        "\n",
        "        colormaps = ['PuRd'] * 5 + ['Blues'] * 7 + ['Greys']\n",
        "\n",
        "        _html += as_headline_4('–ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞')\n",
        "\n",
        "        for region in [doc.subj_range]:\n",
        "          _html += self.winning_patterns_to_html(_tokens=doc.tokens, ranges=doc.subj_ranges,\n",
        "                                                 winning_patterns=doc.winning_subj_patterns, _range=region,\n",
        "                                                 colormaps=colormaps)\n",
        "\n",
        "      return _html\n",
        "\n",
        "    def render_subject(self, counter):\n",
        "      html = as_headline_3('–ü—Ä–µ–¥–º–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ (X):') + self.subject_type_weights_to_html(counter)\n",
        "      display(HTML(html))\n",
        "\n",
        "    def print_results(self, _doc: LegalDocument, results=None):\n",
        "\n",
        "      if results is None:\n",
        "        results = _doc.found_sum\n",
        "\n",
        "      result, (start, end), sentence, meta = results\n",
        "\n",
        "      html = \"<hr>\"\n",
        "\n",
        "      html += self._render_doc_subject_fragments(_doc)\n",
        "\n",
        "      if result is None:\n",
        "        html += '<h2 style=\"color:red\">–°–£–ú–ú–ê –ù–ï –ù–ê–ô–î–ï–ù–ê</h2>'\n",
        "      else:\n",
        "        html += '<h2>' + str(result[0]) + ' ' + str(result[1]) + '</h2>'\n",
        "\n",
        "      for key in meta.keys():\n",
        "        html += '<div style=\"font-size:9px\">' + str(key) + \" = \" + str(meta[key]) + \"</div>\"\n",
        "\n",
        "      display(HTML(html))\n",
        "      self.render_color_text(_doc.tokens[start:end], _doc.sums[start:end])\n",
        "\n",
        "    def subject_type_weights_to_html(self, counter):\n",
        "      dict = {\n",
        "        't_dea': '–°–¥–µ–ª–∫–∞',\n",
        "        't_cha': '–ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å',\n",
        "        't_org': '–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è'\n",
        "      }\n",
        "\n",
        "      maxkey = \"None\"\n",
        "      for key in dict:\n",
        "        if counter[key] > counter[maxkey]:\n",
        "          maxkey = key\n",
        "\n",
        "      html = \"\"\n",
        "      for key in dict:\n",
        "        templ = \"<div>{}: {}</div>\"\n",
        "        if key == maxkey:\n",
        "          templ = '<b style=\"font-size:135%; color:maroon\">{}: {}</b>'\n",
        "        html += templ.format(counter[key], dict[key])\n",
        "\n",
        "      return html\n",
        "\n",
        "  GLOBALS__['ProtocolRenderer'] = ProtocolRenderer()\n",
        "  \n",
        "  from demo_protocols import ProtocolAnlysingContext\n",
        "  GLOBALS__['ProtocolAnlysingContext'] = ProtocolAnlysingContext(GLOBALS__['elmo_embedder'],\n",
        "                                                                 GLOBALS__['ProtocolRenderer'])\n",
        "  GLOBALS__['_init_the_code'] = True\n",
        "    # AZ:-------------------------------------------------Init Protocols context===\n",
        "  \n",
        "\n",
        "  # AZ:-------------------------------------------------Init Charters context====\n",
        "\n",
        "  def read_doc(fn):\n",
        "    import docx2txt, sys, os\n",
        "    text = ''\n",
        "    try:\n",
        "      text = docx2txt.process(fn)\n",
        "    except:\n",
        "      print(\"Unexpected error:\", sys.exc_info())\n",
        "      os.system('antiword -w 0 \"' + fn + '\" > \"' + fn + '.txt\"')\n",
        "      with open(fn + '.txt') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    return text\n",
        "\n",
        "  GLOBALS__['read_doc'] = read_doc\n",
        "\n",
        "  print(\"‚ù§Ô∏è DONE initializing the code\")\n",
        "\n",
        "\n",
        "# AZ:-FINDING_VIOLATIONS--------------------------------------------------------\n",
        "def find_and_show_violations():\n",
        "  from IPython.core.display import display, HTML\n",
        "\n",
        "  from demo import ContractAnlysingContext\n",
        "  from demo_charter import CharterAnlysingContext\n",
        "  from renderer import as_headline_2, as_error_html\n",
        "\n",
        "  print('–ü–æ–∏—Å–∫ –Ω–∞—Ä—É—à–µ–Ω–∏–π')\n",
        "\n",
        "  charterAnlysingContext: CharterAnlysingContext = GLOBALS__['CharterAnlysingContext']\n",
        "  contractAnlysingContext: ContractAnlysingContext = GLOBALS__['ContractAnlysingContext']\n",
        "\n",
        "  contract = contractAnlysingContext.contract\n",
        "  charter = charterAnlysingContext.doc\n",
        "  charter_constraints = charterAnlysingContext.constraints  # XXX: move to doc\n",
        "\n",
        "  renderer = GLOBALS__['renderer']\n",
        "  renderer.render_subj(contract)\n",
        "\n",
        "  import copy\n",
        "\n",
        "  def convert(v):\n",
        "    v_converted = copy.copy(v)\n",
        "    if v.currency in currency_converter:\n",
        "      v_converted.value = currency_converter[v.currency] * v.value\n",
        "      v_converted.currency = 'RUB'\n",
        "      return v_converted\n",
        "    else:\n",
        "      display(HTML(as_error_html(\n",
        "        f\"–º—ã –Ω–µ –≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏ (–ø–æ–∫–∞) –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å {v.currency} --> RUB. –≠—Ç–æ –≤–æ–æ–±—â–µ –≤–∞–ª—é—Ç–∞ –∫–∞–∫–æ–π —Å—Ç—Ä–∞–Ω—ã? –†—É–º—ã–Ω–∏–∏?\")))\n",
        "      return v\n",
        "\n",
        "  best_value = contractAnlysingContext.find_contract_best_value(convert)\n",
        "\n",
        "  # rendering:----------------------------\n",
        "\n",
        "  def _render_violations(ranges_by_group, best_value):\n",
        "    for group_key in ranges_by_group:\n",
        "      group = ranges_by_group[group_key]\n",
        "      display(HTML(as_headline_2(group['name'])))\n",
        "\n",
        "      for rk in group['ranges']:\n",
        "        r = group['ranges'][rk]\n",
        "        display(HTML(r.check_contract_value(best_value, convert, renderer)))\n",
        "\n",
        "  print(\"–°—É–º–º–∞ –î–æ–≥–æ–≤–æ—Ä–∞:\")\n",
        "  renderer.render_values([best_value])\n",
        "  renderer.render_color_text(best_value.value.context[0], best_value.value.context[1], _range=[0, 1])\n",
        "\n",
        "  _render_violations(\n",
        "    charterAnlysingContext.find_ranges_by_group(charter_constraints, convert, verbose=False),\n",
        "    best_value)\n",
        "\n",
        "\n",
        "#   display(HTML(renderer.render_constraint_values(charter_constraints)))\n",
        "\n",
        "\n",
        "# AZ:--------------------------------------------------------FINDING_VIOLATIONS-\n",
        "\n",
        "# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXXX\n",
        "# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXXX\n",
        "# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXXX\n",
        "# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QDIDCaXmVuB0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ { vertical-output: true, output-height: 800, display-mode: \"form\" }\n",
        "\n",
        "# VI: @artifex from here:\n",
        "\n",
        "def process_charter():\n",
        "  uploaded = interactive_upload('–£—Å—Ç–∞–≤')\n",
        "  try:\n",
        "\n",
        "    GLOBALS__['CharterAnlysingContext'].verbosity_level=2\n",
        "    org, rz = GLOBALS__['CharterAnlysingContext'].analyze_charter(uploaded[0], True)\n",
        "    doc = GLOBALS__['CharterAnlysingContext'].doc\n",
        "\n",
        "\n",
        "    GLOBALS__['renderer'].render_contents(doc)\n",
        "    GLOBALS__['renderer'].render_charter_parsing_results(org, rz)\n",
        "  except Exception as e:\n",
        "    print(f\"üí•\\033[1;31m–û—à–∏–±–∫–∞:{e}\\033[1;0m\")\n",
        "\n",
        "def process_contract():\n",
        "  uploaded = interactive_upload('–î–æ–≥–æ–≤–æ—Ä')\n",
        "\n",
        "  try:\n",
        "    GLOBALS__['ContractAnlysingContext'].analyze_contract(uploaded[0])\n",
        "    doc = GLOBALS__['ContractAnlysingContext'].contract\n",
        "\n",
        "    GLOBALS__['renderer'].render_subj(doc)\n",
        "    GLOBALS__['renderer'].render_contents(doc)\n",
        "  except Exception as e:\n",
        "    print(f\"üí•\\033[1;31m–û—à–∏–±–∫–∞:{e}\\033[1;0m\")\n",
        "\n",
        "  \n",
        "def start_wizard(tb):\n",
        "  def step1():\n",
        "    #toggle_element(b1.callback_id)\n",
        "    with tb.output_to(0):\n",
        "      print(f\"\\033[1;32m–°–º. —Å–ª–µ–¥—É—é—â–∏–µ —Ç–∞–±—ã\\u2713\")\n",
        "    \n",
        "    with tb.output_to(1):\n",
        "      b2.render()\n",
        "\n",
        "  def step2():\n",
        "    toggle_element(b2.callback_id)\n",
        "    with tb.output_to(1):      \n",
        "      process_charter() \n",
        "      \n",
        "      print(f\"\\033[1;32m–£—Å—Ç–∞–≤: —Å–¥–µ–ª–∞–Ω–æ\\u2713\")  \n",
        "      toggle_element(b2.callback_id)\n",
        "    \n",
        "    with tb.output_to(2):\n",
        "      b3.render()\n",
        "\n",
        "  def step3():    \n",
        "    toggle_element(b3.callback_id)\n",
        "    with tb.output_to(2):\n",
        "      process_contract()\n",
        "      \n",
        "      print(f\"\\033[1;32m–î–æ–≥–æ–≤–æ—Ä: —Å–¥–µ–ª–∞–Ω–æ\\u2713\")  \n",
        "      toggle_element(b3.callback_id)\n",
        "    \n",
        "    with tb.output_to(3):\n",
        "      b4.render()\n",
        "\n",
        "  def step4():\n",
        "    with tb.output_to(3):\n",
        "            \n",
        "      find_and_show_violations()\n",
        "      \n",
        "      print(f\"\\033[1;32m–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–π: —Å–¥–µ–ª–∞–Ω–æ\\u2713\")  \n",
        "      toggle_element(b4.callback_id)\n",
        "    \n",
        "    with tb.output_to(4):\n",
        "      b5.render()\n",
        "      \n",
        "  def step2():\n",
        "    toggle_element(b4.callback_id)\n",
        "    with tb.output_to(4):\n",
        "      print('–ü–æ–∏—Å–∫ –Ω–∞—Ä—É—à–µ–Ω–∏–π....')\n",
        "      ## do something here \n",
        "      \n",
        "      print(f\"\\033[1;32m–ü–æ–∏—Å–∫ –Ω–∞—Ä—É—à–µ–Ω–∏–π: —Å–¥–µ–ª–∞–Ω–æ\\u2713\")  \n",
        "      toggle_element(b4.callback_id)\n",
        "    \n",
        "    \n",
        "                                     \n",
        "  b1 = InvokeButton('–ù–∞—á–Ω—ë–º', step1)\n",
        "  b2 = InvokeButton('–£—Å—Ç–∞–≤...', step2)\n",
        "  b3 = InvokeButton('–î–æ–≥–æ–≤–æ—Ä...', step3)\n",
        "  b4 = InvokeButton('–ü—Ä–æ—Ç–æ–∫–æ–ª...', step4)\n",
        "  b5 = InvokeButton('–ò—Å–∫–∞—Ç—å –Ω–∞—Ä—É—à–µ–Ω–∏—è...', step5)\n",
        "  \n",
        "  with tb.output_to(0): \n",
        "    try:     \n",
        "      \n",
        "      ## do preparation here   \n",
        "      # 1.\n",
        "      _init_import_code_from_gh()\n",
        "      # 2.\n",
        "      _init_embedder()\n",
        "      # 3.\n",
        "      _init_the_code()\n",
        "      # 4.\n",
        "      _init_charters()\n",
        "      # 5.\n",
        "      _init_contracts()\n",
        "\n",
        "      b1.render()\n",
        "    except:\n",
        "      print(f\"üí•\\033[1;31m–û—à–∏–±–∫–∞:{sys.exc_info()}\\033[1;0m\")\n",
        "\n",
        "\n",
        "#@title Wizard2\n",
        "tb2 = widgets.TabBar(['–ù–∞—á–∞–ª–æ', '–£—Å—Ç–∞–≤', '–î–æ–≥–æ–≤–æ—Ä', '–ü–æ–∏—Å–∫ –Ω–∞—Ä—É—à–µ–Ω–∏–π', '–ü—Ä–æ—Ç–æ–∫–æ–ª'], location='top')    \n",
        "start_wizard(tb2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oC_jj3OrOFOy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}