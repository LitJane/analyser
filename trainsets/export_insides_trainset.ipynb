{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84416aa0",
   "metadata": {
    "colab_type": "text",
    "id": "JbsxFAqC6pjQ",
    "papermill": {
     "duration": 0.02715,
     "end_time": "2021-08-03T13:00:10.959150",
     "exception": false,
     "start_time": "2021-08-03T13:00:10.932000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d3c58-2d3a-4f27-a017-c9acd65e4806",
   "metadata": {
    "papermill": {
     "duration": 0.021947,
     "end_time": "2021-08-03T13:00:10.998129",
     "exception": false,
     "start_time": "2021-08-03T13:00:10.976182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMPORT_FRESH_ONLY = True # re-import all if False\n",
    "\n",
    "SELF_TEST = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d79173",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JoHJkn9yQIgg",
    "papermill": {
     "duration": 1.861673,
     "end_time": "2021-08-03T13:00:12.870686",
     "exception": false,
     "start_time": "2021-08-03T13:00:11.009013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import platform\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "logger = logging.getLogger('retrain_ipynb')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(levelname)s - %(asctime)s - %(name)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.debug('--=logging started=--')\n",
    "\n",
    "print(tf.__version__)\n",
    "CPU = platform.processor()\n",
    "print (f'Running on CPU:{CPU}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e198c1d",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZiBqnGnQfKWF",
    "papermill": {
     "duration": 0.016512,
     "end_time": "2021-08-03T13:00:12.895142",
     "exception": false,
     "start_time": "2021-08-03T13:00:12.878630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "import analyser.hyperparams \n",
    "analyser.hyperparams.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae495501",
   "metadata": {
    "papermill": {
     "duration": 0.007981,
     "end_time": "2021-08-03T13:00:12.911919",
     "exception": false,
     "start_time": "2021-08-03T13:00:12.903938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prepare workdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1029623",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jT7451NXspdw",
    "papermill": {
     "duration": 0.011883,
     "end_time": "2021-08-03T13:00:12.931780",
     "exception": false,
     "start_time": "2021-08-03T13:00:12.919897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "_work_dir_default = Path(analyser.hyperparams.__file__).parent.parent.parent / 'work'\n",
    "work_dir = os.environ.get('GPN_WORK_DIR', _work_dir_default)\n",
    "\n",
    "if not os.path.isdir(work_dir):\n",
    "    os.mkdir(work_dir)\n",
    "\n",
    "analyser.hyperparams.work_dir = work_dir\n",
    " \n",
    "\n",
    "print('work_dir=', analyser.hyperparams.work_dir)\n",
    "assert os.path.isdir(analyser.hyperparams.work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c55a33b",
   "metadata": {
    "papermill": {
     "duration": 0.008023,
     "end_time": "2021-08-03T13:00:12.947888",
     "exception": false,
     "start_time": "2021-08-03T13:00:12.939865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cde660",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "pexvDJbAtZM0",
    "outputId": "4f7e6e34-d675-423d-d102-1020d49d854f",
    "papermill": {
     "duration": 1.475714,
     "end_time": "2021-08-03T13:00:14.431563",
     "exception": false,
     "start_time": "2021-08-03T13:00:12.955849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "from analyser.finalizer import get_doc_by_id\n",
    "from analyser.persistence import DbJsonDoc\n",
    "from integration.db import get_mongodb_connection\n",
    "from pymongo import ASCENDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80bc438-04c3-4b77-9718-233d3da546e0",
   "metadata": {},
   "source": [
    "### Import docs having insideInformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26545c63-b9e7-4d0c-9f87-24f165faec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db = get_mongodb_connection()\n",
    "documents_collection = db['documents']\n",
    "sorting = [('analysis.analyze_timestamp', ASCENDING), ('user.updateDate', ASCENDING)]\n",
    "\n",
    "query = {\n",
    "  '$and': [\n",
    "#     {\"parse.documentType\": \"CONTRACT\"},      \n",
    "#     {\"state\": 15},\n",
    "    {'$or': [\n",
    "        {\"user.attributes_tree.contract.subject.insideInformation\": {\"$ne\": None}},\n",
    "        {\"user.attributes_tree.contract.insideInformation\": {\"$ne\": None}}\n",
    "    ]}\n",
    "  ]\n",
    "}\n",
    "\n",
    "res = documents_collection.find(filter=query, \n",
    "                                sort=sorting,\n",
    "                                projection={'_id': True, 'user.updateDate':True}\n",
    "\n",
    "                               ).limit(1000)\n",
    "\n",
    "res_inside = list([i for i in res])\n",
    "\n",
    "_s = f\"#### Всего документов с инсайдом  {len(res_inside)}\"\n",
    "display(Markdown(_s))\n",
    "\n",
    "if SELF_TEST:\n",
    "    res_inside[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590b7158-d5fd-42d4-abd2-d63df84e592a",
   "metadata": {},
   "source": [
    "### Вынимаем размеченные людьми инсайды из базы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53177099-abca-4b64-921c-32e90a9a8a24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lines=[]\n",
    "for k, oid in enumerate([i[\"_id\"] for i in res_inside]  ):\n",
    "    d = get_doc_by_id(oid)\n",
    "    jd = DbJsonDoc(d)\n",
    "    tree=jd.user['attributes_tree']\n",
    "    c = tree.get('contract', {})\n",
    "    ins = c.get('insideInformation') or  c.get('subject', {}).get('insideInformation', {}) \n",
    "    print('-'*100)\n",
    "    print(k, ins)\n",
    "#     doc=jd.asLegalDoc()\n",
    "#     quote = doc[ins['span']]\n",
    "    doc = jd.asLegalDoc()\n",
    "    s = ins['span']\n",
    "    quote = doc[s[0]: s[1]].get_text()\n",
    "    print(quote)\n",
    "    lines.append( [oid, s[0], s[1], quote, ins['value']]  )\n",
    "    \n",
    "insides = DataFrame(lines, columns=['uid', 'from','to', 'text', 'value'])\n",
    "insides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55ccca8-7f98-46de-b59e-4b3b597ad569",
   "metadata": {},
   "source": [
    "### Очистка, сортировка, удаление дупликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6136504-b3f5-4f83-a357-5de0d67c144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "insides = insides.drop_duplicates(subset=['text'], keep='last')\n",
    "insides.sort_values(['value']).to_csv('insides.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91655b0f-55dd-4c58-88fd-4623fe2dada4",
   "metadata": {},
   "source": [
    "## Embedding patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad79cd-e1cf-459b-812d-6aba572807c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_support.embedder_elmo import ElmoEmbedder\n",
    "\n",
    "embedder = ElmoEmbedder.get_instance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d760f706-1633-4d71-a906-4351c7964c22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strings = [ r.text for i,r in  insides.iterrows() ]\n",
    "strings[2:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68990ae-55b0-4147-95c1-1595ab613693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just test\n",
    "if False:\n",
    "    t1 = insides.iloc[0].text\n",
    "    t2 = insides.iloc[1].text\n",
    "    print(t1, t1)\n",
    "    embeddings = embedder.embedd_strings([t1, t2])\n",
    "    print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60bdbc7-68f1-4515-8439-52d678a91005",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedder.embedd_strings(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b561a0-0d32-46b4-a7e4-834e203aef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings.shape)\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.imshow(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d789c3f7-de6e-40c8-8774-b4d1b4490d2b",
   "metadata": {},
   "source": [
    "## pair-wise distances of Embeddings, removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d39db-9676-47fb-af33-54215851f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "X = embeddings\n",
    "distance_matrix = pairwise_distances(X, X, metric='cosine', n_jobs=1)\n",
    "distance_matrix\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767a344a-e677-4b77-bcf9-59fe14c265b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_excluded = set()\n",
    "_kept = set()\n",
    "\n",
    "display(Markdown('### Одинаковые:'))\n",
    "for i in range(distance_matrix.shape[0]):\n",
    "    for j in range(i+1, distance_matrix.shape[0]):\n",
    "        d = distance_matrix[i,j]\n",
    "        if d < 0.1:\n",
    "            print(i,'vs', j, ', cosine distance =',d)\n",
    "            _kept.add(i)\n",
    "            _excluded.add(j)\n",
    "            print(i, strings[i])\n",
    "            print('==')\n",
    "            print(j, strings[j])\n",
    "            print('-'*100)\n",
    "# _excluded\n",
    "\n",
    "print(_kept-_excluded)\n",
    "print(_excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560de82-216d-476e-8d9d-d3eb8c0986f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embeddings_filtered = np.delete(embeddings, list(_excluded), axis=0)\n",
    "strings_filtered = np.delete(strings, list(_excluded), axis=0)\n",
    "embeddings_filtered.shape\n",
    "\n",
    "display(Markdown(f'### {embeddings_filtered.shape[0]} -- Количество паттернов после удаления одинаковых'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa569fb-aa80-478e-a5ab-994466f13a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = embeddings_filtered\n",
    "distance_matrix = pairwise_distances(X, X, metric='cosine', n_jobs=1)\n",
    " \n",
    "            \n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d0b1ca-15ec-469d-8303-dc7a2d448e02",
   "metadata": {},
   "source": [
    "## Clustering, t-SNE try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce03d7f6-954b-40c7-b5cf-ff53c384ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(insides.value.unique())\n",
    "n_clusters = len(insides.value.unique())\n",
    "print('n_clusters', n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4118ca63-863d-46eb-98f6-1238e44f540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=1300, metric=\"precomputed\")\n",
    "tsne_results = tsne.fit_transform(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea4ea38-7bfa-491c-a06c-1120b712a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset={}\n",
    "df_subset['tsne-2d-one'] = tsne_results[:,0]\n",
    "df_subset['tsne-2d-two'] = tsne_results[:,1]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    data=df_subset,\n",
    "    alpha=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3563d41-37aa-4fda-bab5-1d8a2f308d8e",
   "metadata": {},
   "source": [
    "## Clustering, PCA, Birch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333054e6-1a9b-49b8-8860-edd0a0153217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(embeddings_filtered)\n",
    "\n",
    "df_subset={}\n",
    "df_subset['pca2d-one'] = pca_result[:,0]\n",
    "df_subset['pca2d-two'] = pca_result[:,1]\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import Birch\n",
    "import numpy as np\n",
    "\n",
    "# kmeans = KMeans(n_clusters = n_clusters, random_state=0).fit(np.array(pca_result))\n",
    "kmeans = Birch(n_clusters = n_clusters).fit(np.array(pca_result))\n",
    "\n",
    "\n",
    "# print(len(kmeans.labels_), kmeans.cluster_centers_)\n",
    "# print(len(kmeans.labels_), kmeans.labels_)\n",
    "\n",
    "df_subset['label'] = kmeans.labels_\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(\n",
    "    x=\"pca2d-one\", y=\"pca2d-two\",\n",
    "    data=df_subset,\n",
    "    hue=\"label\", palette=\"tab10\",\n",
    "    alpha=0.6, size=[200]*len(kmeans.labels_), sizes=(400, 500)\n",
    ")\n",
    "# print(pca_result[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5e0eec-5c4d-412f-8e53-9bb09e545a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "insides.to_csv('insides.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28463e-a267-48b3-9db9-10c3275ec551",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pca_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff33e1-847b-4fc1-9f48-b180dc1b456c",
   "metadata": {},
   "source": [
    "## Finding cluster centers (in embedding space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcfd5cf-6670-4c1a-a058-b916dee7c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colab_support.renderer import HtmlRenderer\n",
    "import matplotlib as matplotlib\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "class DemoRenderer(HtmlRenderer):\n",
    "  def render_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None, separator=' '):\n",
    "    html = self.to_color_text(tokens, weights, colormap, print_debug, _range, separator=separator)\n",
    "    display(HTML(html))\n",
    "\n",
    "  def to_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None, separator=' '):\n",
    "    return super()._to_color_text(tokens, weights, matplotlib, colormap=colormap, _range=_range, separator=separator)\n",
    "\n",
    "renderer_ = DemoRenderer()\n",
    "\n",
    "if SELF_TEST:\n",
    "    renderer_.render_color_text([\"слово 1\", \"слово 2\"], np.array( [1, 0]), _range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d8cbbf-fc89-45b8-bff4-9c437a94add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [ len (s) for s in strings]\n",
    "print(lens)\n",
    "\n",
    "mean_len = int(np.mean(lens) * 1.75)\n",
    "print(mean_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ff520-2044-4b8e-9374-6b7cb72bd76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = np.mean(embeddings_filtered, axis=0)\n",
    "centroids = []\n",
    "print(centroid)\n",
    "\n",
    "for k in range(n_clusters):\n",
    "    group=[]\n",
    "    for i in range(len(embeddings_filtered)):\n",
    "        if k == kmeans.labels_[i]:\n",
    "#             print (k)\n",
    "            group.append(embeddings_filtered[i])\n",
    "    print(len(group))\n",
    "    c = np.mean(group, axis=0)\n",
    "    centroids.append(c)\n",
    "    print( c )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0241f2-2fbe-4d68-9ff8-a3870cc636c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyser.hyperparams import models_path\n",
    "models_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81b995c-446a-401a-9527-b485666575f2",
   "metadata": {},
   "source": [
    "# Save patterns  (embeddings binary array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50424f55-e737-4c2b-a28d-a24836df8393",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(Path(models_path) / \"insides_patterns.npy\",  centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230cd10b-c8bc-4ca9-becd-b62fd596b897",
   "metadata": {},
   "source": [
    "# Analysing sample doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7377e6b-d9d8-461e-8447-e3948b62886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SELF_TEST:    \n",
    "    centroids = np.load(Path(models_path) / \"insides_patterns.npy\")\n",
    "    print(centroids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1086a-6e64-40d5-b0a8-110bd6d97bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SELF_TEST:\n",
    "    \n",
    "\n",
    "    sample_id     = res_inside[0][\"_id\"]\n",
    "    sample_db_doc = get_doc_by_id(sample_id)\n",
    "    sample_j_doc  = DbJsonDoc(sample_db_doc)\n",
    "    sample_doc    = sample_j_doc.asLegalDoc()\n",
    "\n",
    "\n",
    "    from analyser.legal_docs import tokenize_doc_into_sentences_map\n",
    "    sample_doc.sentence_map = tokenize_doc_into_sentences_map(sample_doc.tokens_map.get_full_text(), mean_len)\n",
    "\n",
    "    print(sample_doc)\n",
    "\n",
    "    doc_embeddings = embedder.embedd_strings(sample_doc.sentence_map.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0672b351-d739-46a8-bf55-8f8bd1807225",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(doc_embeddings.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bc020a-63c5-49db-892a-fe2448c913e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x: np.ndarray, relu_th: float = 0.0) -> np.ndarray:\n",
    "  _relu = x * (x > relu_th)\n",
    "  return _relu\n",
    "\n",
    "\n",
    "X = doc_embeddings\n",
    "distance_matrix = pairwise_distances(X, centroids, metric='cosine', n_jobs=1)\n",
    "# distance_matrix = relu ( ((distance_matrix * -1)+1) , _mx-0.01)\n",
    "\n",
    "distance_matrix = (distance_matrix * -1)+1.0\n",
    "distance_matrix = distance_matrix.T\n",
    "plt.figure(figsize=(30,4))\n",
    "plt.imshow( distance_matrix )\n",
    "# plt.plot(np.array(distance_matrix.T[0]))\n",
    "print(len(distance_matrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda5d57f-deb5-4ebb-ae07-9d9209cbc99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.01\n",
    "threshold = 0.8 #0.9 *  distance_matrix.max()\n",
    "print('threshold', threshold)\n",
    "print()\n",
    "sim_max=0\n",
    "i_max=0\n",
    "plt.figure(figsize=(30,6))\n",
    "plt.plot([threshold]*len(sample_doc.sentence_map), alpha=0.4 )\n",
    "for k in range(n_clusters):    \n",
    "    print('-'*20)\n",
    "    v = distance_matrix[k] \n",
    "    av = v #relu(v, threshold) ## attention vector\n",
    "    \n",
    "    ii = av.argmax()\n",
    "    sim = av[ii]\n",
    "    if (sim > threshold):\n",
    "        plt.plot(av)\n",
    "        print( f\"{k}=cluster \\t {av[ii]}=similarity, \\n {sample_doc.sentence_map.tokens[ii]} \")\n",
    "    \n",
    "    if sim>sim_max:\n",
    "        i_max = k\n",
    "        sim_max = sim\n",
    "print(sim_max, i_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c53943-f670-4a2b-88f1-1f200ffdf60b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "relu_threshold =  0.99 *  distance_matrix.max()\n",
    "renderer_.render_color_text(sample_doc.sentence_map.tokens, relu(distance_matrix[i_max], relu_threshold), _range=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba5db4-866d-410a-8f6a-c7c88ae8463d",
   "metadata": {},
   "source": [
    "## Test no-insides DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2879eac8-1693-43b9-ab15-6c9178d0f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson import ObjectId\n",
    "from analyser.legal_docs import tokenize_doc_into_sentences_map\n",
    "# doc =\n",
    "\n",
    "if SELF_TEST:\n",
    "    sample_db_doc    =  get_doc_by_id(ObjectId('60dec1f556214d9842813fcb'))    \n",
    "    sample_j_doc  = DbJsonDoc(sample_db_doc)\n",
    "    sample_doc    = sample_j_doc.asLegalDoc()\n",
    "    \n",
    "    \n",
    "    print(sample_doc)\n",
    "    sample_doc.sentence_map = tokenize_doc_into_sentences_map(sample_doc.tokens_map.get_full_text(), mean_len)\n",
    "\n",
    "#     print(sample_doc)\n",
    "\n",
    "    doc_embeddings = embedder.embedd_strings(sample_doc.sentence_map.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243a7ba-4331-4e76-ab5e-e6252236f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = doc_embeddings\n",
    "distance_matrix = pairwise_distances(X, centroids, metric='cosine', n_jobs=1)\n",
    "# distance_matrix = relu ( ((distance_matrix * -1)+1) , _mx-0.01)\n",
    "\n",
    "distance_matrix = (distance_matrix * -1)+1.0\n",
    "distance_matrix = distance_matrix.T\n",
    "plt.figure(figsize=(30,4))\n",
    "plt.imshow( distance_matrix )\n",
    "# plt.plot(np.array(distance_matrix.T[0]))\n",
    "print(len(distance_matrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c5922-0620-4385-a19e-ae258b26d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.01\n",
    "threshold = 0.85 #0.9 *  distance_matrix.max()\n",
    "print('threshold', threshold)\n",
    "print()\n",
    "sim_max=0\n",
    "i_max=0\n",
    "plt.figure(figsize=(30,6))\n",
    "plt.plot([threshold]*len(sample_doc.sentence_map), alpha=0.4 )\n",
    "for k in range(n_clusters):    \n",
    "    print('-'*20)\n",
    "    v = distance_matrix[k] \n",
    "    av = v #relu(v, threshold) ## attention vector\n",
    "    \n",
    "    ii = av.argmax()\n",
    "    sim = av[ii]\n",
    "    if (sim > threshold):\n",
    "        plt.plot(av)\n",
    "        print( f\"{k}=cluster \\t {av[ii]}=similarity, \\n {sample_doc.sentence_map.tokens[ii]} \")\n",
    "    \n",
    "    if sim>sim_max:\n",
    "        i_max = k\n",
    "        sim_max = sim\n",
    "print(sim_max, i_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d970a1-44ed-4936-9dda-19de61a6937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_threshold =  0.99 *  distance_matrix.max()\n",
    "renderer_.render_color_text(sample_doc.sentence_map.tokens, distance_matrix[i_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6656c836-7a15-4ea6-9835-079606836751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9eF-UGHyh-C9",
    "7X_zYCYEdlPM",
    "lyI4hbTRFjyM"
   ],
   "name": "Local: structure keras uber model - clean train, evaluate, test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.184245,
   "end_time": "2021-08-03T13:00:20.283835",
   "environment_variables": {},
   "exception": null,
   "input_path": "trainsets/export_trainset.ipynb",
   "output_path": "trainsets/export_trainset.ipynb",
   "parameters": {},
   "start_time": "2021-08-03T13:00:10.099590",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
