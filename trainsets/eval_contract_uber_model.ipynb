{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JoHJkn9yQIgg"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "logger = logging.getLogger('eva;_ipynb')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(levelname)s - %(asctime)s - %(name)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.debug('--=logging started=--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Dehw0fnKfSBF",
    "outputId": "3bcb61cd-401a-43d7-dccf-9a6022b2a576"
   },
   "outputs": [],
   "source": [
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print ('Running in colab:', IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZiBqnGnQfKWF"
   },
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "  nb_dir = os.path.split(os.getcwd())[0]\n",
    "  if nb_dir not in sys.path:\n",
    "      sys.path.append(nb_dir)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jT7451NXspdw"
   },
   "outputs": [],
   "source": [
    "import analyser.hyperparams\n",
    "analyser.hyperparams.work_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbsxFAqC6pjQ"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "pexvDJbAtZM0",
    "outputId": "4f7e6e34-d675-423d-d102-1020d49d854f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    " \n",
    "from trainsets.retrain_contract_uber_model import UberModelTrainsetManager\n",
    "from tf_support.super_contract_model import semantic_map_keys_contract\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from colab_support.renderer import HtmlRenderer\n",
    "import matplotlib as matplotlib\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "class DemoRenderer(HtmlRenderer):\n",
    "  def render_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None, separator=' '):\n",
    "    html = self.to_color_text(tokens, weights, colormap, print_debug, _range, separator=separator)\n",
    "    display(HTML(html))\n",
    "\n",
    "  def to_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None, separator=' '):\n",
    "    return super()._to_color_text(tokens, weights, matplotlib, colormap=colormap, _range=_range, separator=separator)\n",
    "\n",
    "renderer_ = DemoRenderer()\n",
    "\n",
    "\n",
    "# renderer_.render_color_text([\"—Å–ª–æ–≤–æ 1\", \"—Å–ª–æ–≤–æ 2\"], np.array( [1, 0]), _range=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRQOy7o0uyTv"
   },
   "source": [
    "# Prepare model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "work_dir = Path(analyser.hyperparams.work_dir)\n",
    "print(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "umtm = UberModelTrainsetManager (work_dir)\n",
    "umtm.load_contract_trainset_meta()\n",
    "stats = umtm.stats\n",
    "stats['sample_weight']=-1.0\n",
    "stats['subject_weight']=-1.0\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxEdSGOuq62R"
   },
   "source": [
    "# look into trainset (take a sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tf_support.super_contract_model import  validate_datapoint\n",
    "\n",
    "stats['valid'] = True\n",
    "stats['error'] = ''\n",
    "\n",
    "for i in stats.index:\n",
    "  \n",
    "  try:\n",
    "    validate_datapoint(str(i), stats)\n",
    "\n",
    "  except Exception as e:\n",
    "    logger.error(e)\n",
    "\n",
    "    stats.at[i, 'valid'] = False\n",
    "    stats.at[i, 'error'] = str(e)\n",
    "    \n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_valid = stats[stats['valid']]\n",
    "# stats_valid = stats_valid[stats_valid.source=='file']\n",
    "len(stats_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from bson import json_util\n",
    "\n",
    "fn = work_dir / 'documents.json'\n",
    "with open(fn) as file:\n",
    "    file_data = json.load(file, object_hook=json_util.object_hook)    \n",
    "    print(f'total docs in {fn} is {len(file_data)}')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from analyser.persistence import DbJsonDoc\n",
    "docs = {}\n",
    "for fd in file_data:\n",
    "    try:\n",
    "      validate_datapoint(str(fd['_id']), stats)\n",
    "      docs [fd['_id']] =  DbJsonDoc(fd)\n",
    "      print (fd['_id'])\n",
    "    except Exception as e:\n",
    "      logger.error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'total docs in {fn} is {len(list(docs.values()))}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sample doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DEBUG = True\n",
    "\n",
    "if _DEBUG:\n",
    "    a_doc_from_json = list(docs.values())[9]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(a_doc_from_json.get_tokens_map_unchaged().text[:2300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_doc_from_json.get_attributes_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_kJ0L2RnrHl3",
    "outputId": "4863cd27-1459-458a-951d-b054235ffaea"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from colab_support.renderer import plot_embedding, plot_cm\n",
    "from tf_support.super_contract_model import make_xyw\n",
    "\n",
    "SAMPLE_DOC_ID = str(a_doc_from_json.get_id())# stats_valid.index[0]\n",
    "\n",
    "print('SAMPLE_DOC_ID', SAMPLE_DOC_ID)\n",
    "\n",
    "(emb, tok_f), (sm, subj), (sample_weight, subject_weight) = make_xyw(SAMPLE_DOC_ID, stats)\n",
    " \n",
    "    \n",
    "print('semantic map shape is:', sm.shape)\n",
    "_crop = 700\n",
    "plot_embedding(tok_f[:_crop], title=f'Tokens features {SAMPLE_DOC_ID}') \n",
    "plot_embedding(emb[:_crop], title=f'Embedding {SAMPLE_DOC_ID}') \n",
    "plot_embedding(sm[:_crop], title=f'Semantic map {SAMPLE_DOC_ID}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAFmo0sG4H9k"
   },
   "source": [
    "# Models ü¶ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uber_detection_model_005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_support.super_contract_model import uber_detection_model_005_1_1\n",
    "from tf_support.super_contract_model import uber_detection_model_003\n",
    "\n",
    "model_factory_fn = uber_detection_model_005_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tf_support.tools import KerasTrainingContext\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "_train, _test = train_test_split(stats_valid, test_size=0.2, stratify=stats_valid[['subject']])\n",
    "\n",
    "train_indices = list(_train.index)\n",
    "test_indices = list(_test.index)\n",
    "\n",
    "ctx = KerasTrainingContext(umtm.work_dir, session_index=21)\n",
    "ctx.EVALUATE_ONLY = True\n",
    "ctx.set_batch_size_and_trainset_size(BATCH_SIZE, \n",
    "                                     len(test_indices), \n",
    "                                     4 * len(train_indices))\n",
    "\n",
    "\n",
    "# model_factory_fn = uber_detection_model_005_1_1\n",
    "\n",
    "\n",
    "\n",
    "# weights = Path(models_path) / f\"{model_factory_fn.__name__}-{keras.__version__}.h5\"\n",
    "weights = ctx.model_checkpoint_path / f'{model_factory_fn.__name__}.h5'\n",
    "if weights.is_file():\n",
    "    print (weights)\n",
    "    \n",
    "umodel = ctx.init_model(model_factory_fn, trained=True, trainable=True, weights=weights)\n",
    "umodel.trainable = False\n",
    "umodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUum89Tdhg-9"
   },
   "source": [
    "# Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_index = umtm.stats [umtm.stats['value']>0].index[2]\n",
    "print(SAMPLE_DOC_ID)\n",
    "\n",
    "\n",
    "x, y, _ = (emb, tok_f), (sm, subj), (sample_weight, subject_weight)# = umtm.make_xyw(SAMPLE_DOC_ID)\n",
    "\n",
    "# x, y, _ = umtm.make_xyw(sample_index)\n",
    "\n",
    "prediction = umodel.predict(x=[np.expand_dims(x[0], axis=0), np.expand_dims(x[1], axis=0)], batch_size=1)\n",
    "\n",
    "tagsmap = pd.DataFrame(prediction[0][0], columns=semantic_map_keys_contract)\n",
    "tagsmap_e = pd.DataFrame(sm, columns=semantic_map_keys_contract)\n",
    "# .T\n",
    "plot_embedding(tagsmap[:_crop], f'Predicted Semantic Map {tagsmap.shape}')\n",
    "plot_embedding(tagsmap[:_crop] - tagsmap_e[:_crop], title=f'DELTA Semantic map {tagsmap_e.shape}')\n",
    "plot_embedding(tagsmap_e[:_crop], title=f'EXPECTED Semantic map {tagsmap_e.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tagsmap.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av = tagsmap.sum(axis=1) #tagsmap['amount-begin'] + tagsmap['vat-begin'] + tagsmap['number-begin'] + tagsmap['org-name-begin']\n",
    "\n",
    "# av = tagsmap.sum(axis=1)\n",
    "renderer_.render_color_text(a_doc_from_json.get_tokens_map_unchaged().tokens[:1600], av[:1600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from analyser.documents import TextMap\n",
    "from analyser.ml_tools import SemanticTag\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting tag values from inferred semantic map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyser.contract_parser import nn_find_org_names, nn_get_subject, nn_get_contract_number, nn_get_contract_date, nn_get_tag_values\n",
    "from analyser.parsing import AuditContext\n",
    "\n",
    "ac = AuditContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas = nn_find_org_names(a_doc_from_json.get_tokens_map_unchaged(), tagsmap, ac)\n",
    "print(cas[0].name)\n",
    "print(cas[0].type)\n",
    "print(cas[0].alias)\n",
    "print()\n",
    "print(cas[1].name)\n",
    "print(cas[1].type)\n",
    "print(cas[1].alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = nn_get_tag_values('org-type',  a_doc_from_json.get_tokens_map_unchaged(), tagsmap, max_tokens=12, threshold=0.5, limit=2)\n",
    "for t in tag:\n",
    "  print(\"-\"*100)\n",
    "  print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = nn_get_tag_values('org-name',  a_doc_from_json.get_tokens_map_unchaged(), tagsmap, max_tokens=12, threshold=0.5, limit=2)\n",
    "for t in tag:\n",
    "  print(\"-\"*100)\n",
    "  print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = nn_get_tag_values('org-alias',  a_doc_from_json.get_tokens_map_unchaged(), tagsmap, max_tokens=4, threshold=0.9, limit=2)\n",
    "\n",
    "\n",
    "for t in tag:\n",
    "  print(\"-\"*100)\n",
    "  print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date/number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = nn_get_tag_values('date',  a_doc_from_json.get_tokens_map_unchaged(), tagsmap, max_tokens=6, threshold=0.3, limit=1, return_single=True)\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = nn_get_tag_values('number',  a_doc_from_json.get_tokens_map_unchaged(), tagsmap, max_tokens=5, threshold=0.3, limit=1, return_single=True)\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_tag = nn_get_contract_number(a_doc_from_json.get_tokens_map_unchaged(), tagsmap) \n",
    "number_tag = nn_get_contract_date(a_doc_from_json.get_tokens_map_unchaged(), tagsmap)\n",
    "print( date_tag)\n",
    "print( number_tag )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textmap = a_doc_from_json.get_tokens_map_unchaged()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from analyser.schemas import ContractPrice, merge_spans\n",
    "from analyser.legal_docs import find_value_sign\n",
    "from analyser.transaction_values import ValueSpansFinder\n",
    "from analyser.text_tools import to_float\n",
    "\n",
    "\n",
    "#---\n",
    "cps = nn_find_contract_value(textmap, tagsmap)\n",
    "if cps:\n",
    "  print(str(cps[0].get_span()))\n",
    "  for k in cps[0].list_children():\n",
    "    print(str(k))\n",
    "\n",
    "  print()\n",
    "  print()\n",
    "\n",
    "  print('brutto', str(cps[0].amount_brutto))\n",
    "  print('netto', str(cps[0].amount_netto))\n",
    "  print('amount', str(cps[0].amount))\n",
    "  print('vat', str(cps[0].vat))\n",
    "else:\n",
    "  print('nothing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags = []\n",
    "\n",
    "# # tags.append()\n",
    "# tags.append(nn_get_tag_value('sign', textmap,          tagsmap, max_tokens=10, threshold=0.4, limit=1))\n",
    "# tags.append(nn_get_tag_value('currency',textmap,       tagsmap, max_tokens=4, threshold=0.4, limit=1))\n",
    "# tags.append(nn_get_tag_value('amount_brutto', textmap, tagsmap, max_tokens=4, threshold=0.4, limit=1))\n",
    "# tags.append(nn_get_tag_value('amount_netto', textmap,  tagsmap, max_tokens=4, threshold=0.4, limit=1))\n",
    "# tags.append(nn_get_tag_value('value', textmap,         tagsmap, max_tokens=40, threshold=0.02, limit=1))\n",
    "# for tag in tags:\n",
    "#   print(\"-\"*100)\n",
    "#   for t in tag:\n",
    "#     print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "tag_name = 'subject-end'\n",
    "attention =  tagsmap[tag_name].values\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(attention)\n",
    "# plot_embedding(att[:400], title=f'{tag_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_tag = nn_get_tag_values('subject',  a_doc_from_json.get_tokens_map_unchaged(), tagsmap, max_tokens=200, threshold=0.02, limit=1, return_single=True)\n",
    "\n",
    "print(subject_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_hl = np.zeros(len(textmap))\n",
    "\n",
    "def hl(tag):\n",
    "  try:\n",
    "    tags_hl [ tag.span[0]:tag.span[1]] +=1\n",
    "  except:\n",
    "    pass\n",
    "  \n",
    "\n",
    "if cps:\n",
    "  hl(cps[0].amount_brutto)\n",
    "  hl(cps[0].amount_netto)\n",
    "  hl(cps[0].amount)\n",
    "  hl(cps[0].vat)\n",
    "  hl(cps[0].sign)\n",
    "  hl(cps[0].currency)\n",
    "  hl(cps[0])\n",
    "\n",
    "\n",
    "hl(cas[0].name)\n",
    "hl(cas[0].type)\n",
    "hl(cas[0].alias)\n",
    "\n",
    "hl(cas[1].name)\n",
    "hl(cas[1].type)\n",
    "hl(cas[1].alias)\n",
    "\n",
    "hl(number_tag)\n",
    "hl(date_tag)\n",
    "\n",
    "\n",
    "hl(subject_tag)\n",
    "\n",
    "renderer_.render_color_text(a_doc_from_json.get_tokens_map_unchaged().tokens[:1600], tags_hl[:1600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# agent_tags = ['org-1-name',\n",
    "#               'org-1-type',\n",
    "#               'org-1-alias',\n",
    "#               'org-2-name',\n",
    "#               'org-2-type',\n",
    "#               'org-2-alias']\n",
    "# solo_tags = [\n",
    "#   'date',\n",
    "#   'number',\n",
    "#   'sign_value_currency/value',\n",
    "#   'sign_value_currency/currency',\n",
    "#   'sign_value_currency/sign'\n",
    "# ]\n",
    "\n",
    "# # seq_labels_contract[-3:]\n",
    "\n",
    "# tagnames = solo_tags + agent_tags\n",
    "\n",
    "\n",
    "# from pandas import DataFrame\n",
    "\n",
    "# from analyser.contract_agents import ContractAgent, normalize_contract_agent\n",
    "\n",
    "# from analyser.persistence import DbJsonDoc\n",
    "# from analyser.text_tools import find_top_spans\n",
    "# # from tf_support.super_contract_model import seq_labels_contract\n",
    "# from tf_support.tf_subject_model import decode_subj_prediction\n",
    "\n",
    "# from analyser.contract_parser import nn_find_org_names, nn_get_tag_value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def fetch_tags_from_predicted_semantic_map(_id: str, tagsmap: DataFrame):\n",
    "#   jdoc = get_doc(_id)\n",
    "#   _map = jdoc.get_tokens_map_unchaged()\n",
    "\n",
    "#   results = {}\n",
    "#   for key in tagnames:\n",
    "#     t = nn_get_tag_value(key, _map, tagsmap )\n",
    "#     results[key] = t\n",
    "#     # print(t)\n",
    "\n",
    "# #   ca = ContractAgent()\n",
    "# #   ca.name =  results['org-1-name'] #TODO: check for NONE\n",
    "# #   ca.type =  results['org-1-type']\n",
    "# #   ca.alias = results['org-1-alias']\n",
    "   \n",
    "\n",
    "# #   ca2 = ContractAgent()\n",
    "# #   ca2.name =  results['org-2-name'] #TODO: check for NONE\n",
    "# #   ca2.type =  results['org-2-type']\n",
    "# #   ca2.alias = results['org-2-alias']\n",
    "# #   try:\n",
    "# #     normalize_contract_agent(ca)\n",
    "# #     normalize_contract_agent(ca2)\n",
    "# #   except Exception as e:\n",
    "# #         # TODO:\n",
    "# #     logger.error(f'{_id} {e}')\n",
    "\n",
    "#   if results['number'] is not None:\n",
    "#     results['number'].value = results['number'].value.strip().lstrip('‚Ññ').lstrip('N ').lstrip()\n",
    "\n",
    "#   return results, jdoc\n",
    "\n",
    "\n",
    "# def put_results_into_df(id_, results, df, jdoc: DbJsonDoc):\n",
    "#   org_atribs = ['name', 'alias', 'type']\n",
    "\n",
    "#   def v(x):\n",
    "#     if results[x] is not None:\n",
    "#       return results[x].value\n",
    "\n",
    "#   def swap(a, b):\n",
    "#     ab = [a, b]\n",
    "#     try:\n",
    "#       ab = sorted(ab)\n",
    "#     except:\n",
    "#       pass\n",
    "#     return ab\n",
    "\n",
    "#   def s(a, b):\n",
    "#     ab = swap(v(a), v(b))\n",
    "#     df.at[id_, f'p-{a}'] = ab[0]\n",
    "#     df.at[id_, f'p-{b}'] = ab[1]\n",
    "#     return ab\n",
    "\n",
    "#   for key in org_atribs:\n",
    "#     arr = s(f'org-1-{key}', f'org-2-{key}')\n",
    "\n",
    "#   def p(key):\n",
    "#     df.at[id_, f'p-{key}'] = v(key)\n",
    "\n",
    "#   p('sign_value_currency/value')\n",
    "#   p('sign_value_currency/currency')\n",
    "#   p('sign_value_currency/sign')\n",
    "\n",
    "#   p('date')\n",
    "#   p('number')\n",
    "\n",
    "#   # get_expected values\n",
    "#   for key in solo_tags:\n",
    "#     t = jdoc.get_attribute_value(key)\n",
    "#     df.at[id_, f'{key}'] = t\n",
    "\n",
    "#   for key in org_atribs:\n",
    "#     orgs = swap(jdoc.get_attribute_value(f'org-1-{key}'), jdoc.get_attribute_value(f'org-2-{key}'))\n",
    "#     df.at[id_, f'org-1-{key}'] = orgs[0]\n",
    "#     df.at[id_, f'org-2-{key}'] = orgs[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = umtm.stats [umtm.stats['score'] < 1000].index.values[0:500]\n",
    "# print(sample_index)\n",
    "from tf_support.tf_subject_model import decode_subj_prediction\n",
    "\n",
    "\n",
    "\n",
    "def make_subj_predictions(umodel, indices):\n",
    "  ev = umtm.stats.copy()\n",
    "  tags = pd.DataFrame()\n",
    "  \n",
    "#   for t in tagnames:\n",
    "#     tags['p-' + t] = ''\n",
    "#     tags[t] = ''\n",
    "\n",
    "  errors_report = pd.DataFrame()\n",
    "  errors_report['expected'] = ''\n",
    "  errors_report['predicted'] = ''\n",
    "\n",
    "  for i, _id in enumerate(indices):\n",
    "    logger.debug(f'validating {_id} {i} of {len(indices)}')\n",
    "    \n",
    "#     print (i, _id, type(ev))\n",
    "    x, y, _ = make_xyw(_id, ev)\n",
    "\n",
    "    prediction = umodel.predict(x=[np.expand_dims(x[0], axis=0), np.expand_dims(x[1], axis=0)], batch_size=1)\n",
    "    tagsmap = pd.DataFrame(prediction[0][0], columns=semantic_map_keys_contract)\n",
    "  \n",
    "#     r, jdoc = fetch_tags_from_predicted_semantic_map(_id, tagsmap)\n",
    "#     put_results_into_df(_id, r, tags, jdoc)\n",
    "    \n",
    "\n",
    "    subj_1hot = prediction[1][0]\n",
    "\n",
    "    expected = decode_subj_prediction(y[1])[0]\n",
    "    predicted = decode_subj_prediction(subj_1hot)[0]\n",
    "    \n",
    "\n",
    "\n",
    "    ev.at[_id, 'expected_subj'] = expected.name\n",
    "    ev.at[_id, 'predicted_subj'] = predicted.name\n",
    "\n",
    "    ev.at[_id, 'wrong'] = False\n",
    "    if expected != predicted:\n",
    "      print(f'{i} \\t {_id} \\t {expected} \\t{predicted}')\n",
    "      ev.at[_id, 'wrong'] = True\n",
    "\n",
    "  return ev, tags\n",
    "\n",
    "ev, tags = make_subj_predictions(umodel, sample_index)\n",
    "ev[pd.notna(ev.predicted_subj)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jh1WFsjprUr1"
   },
   "outputs": [],
   "source": [
    "# _cols = [  'wrong' ]\n",
    "# _tmp = ev[cols]\n",
    "# errors_report = _tmp[ _tmp.wrong == True] #.sort_values('subject')\n",
    "# print(len(errors_report), 'wrong subjects of', len(tags))\n",
    "# errors_report \n",
    "\n",
    "subj_pred = ev[pd.notna(ev.predicted_subj)][pd.notna(ev.expected_subj)]\n",
    "subj_df = subj_pred[['predicted_subj', 'expected_subj']].copy()\n",
    "subj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "# print(subj_df['predicted_subj'].values)\n",
    "labels = sorted(np.unique(subj_df['expected_subj'].values))\n",
    "print (labels)\n",
    "\n",
    "# cm = confusion_matrix(subj_df['expected_subj'].values, subj_df['predicted_subj'].values, labels=labels)\n",
    "# cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFh8SxP9J081"
   },
   "outputs": [],
   "source": [
    "def make_report(umodel, subj_df):\n",
    "  plot_cm(subj_df['expected_subj'].values, subj_df['predicted_subj'].values)\n",
    "  \n",
    "  img_path = os.path.join(umtm.work_dir, f'subjects-confusion-matrix-{umodel.name}.png')\n",
    "  plt.savefig(img_path, bbox_inches='tight')\n",
    "\n",
    "  report = classification_report(subj_df['expected_subj'], subj_df['predicted_subj'], digits=3)\n",
    "  print(umodel.name)\n",
    "  print(report)\n",
    "  \n",
    "  with open(os.path.join(umtm.work_dir, f'subjects-classification_report-{umodel.name}.txt'), \"w\") as text_file:\n",
    "    text_file.write(report)\n",
    "\n",
    "\n",
    "# subj_df = subj_df[['predicted_subj', 'expected_subj']].copy() #ev[~pd.isna(ev['predicted_subj'])]\n",
    "make_report(umodel, subj_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f1, subjects\n",
    "- 005: weighted avg      0.837     0.814     0.817       \n",
    "- 003: weighted avg      0.734     0.718     0.704       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mX5RUserhy0m"
   },
   "source": [
    "# Evaluate tags detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.fillna('-', inplace=True)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(d, f):\n",
    "    fn = os.path.join(umtm.work_dir, f)\n",
    "    d.to_csv(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_SUQNtsxVBp9"
   },
   "source": [
    "### Contract number validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "fGnSN-Bp87VW",
    "outputId": "0a23b5c6-91a3-44f7-dd1c-60f567a8f326"
   },
   "outputs": [],
   "source": [
    "wrong_numbers = tags [ tags['number'] != tags['p-number']].sort_values('number')\n",
    "print( f'Contract numbers: {len(wrong_numbers)} of {len(tags)}  ({100. * len(wrong_numbers) / len(tags) :0.1f}%) were detected wronggly')\n",
    "\n",
    "save_csv( wrong_numbers[['p-number', 'number']], 'wrong_numbers.csv')\n",
    "\n",
    "# wrong_numbers[['p-number', 'number']].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags ['sign_value_currency/currency'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x):\n",
    "    if type(x) is str:\n",
    "        v = x.replace(',','.').replace(' ','')\n",
    "    else: \n",
    "        v=x\n",
    "    try:\n",
    "        v=float(v)\n",
    "    except:\n",
    "        v=np.nan\n",
    "    return v \n",
    "\n",
    "tags['n-p-sign_value_currency/value'] = pd.to_numeric( tags['p-sign_value_currency/value'].apply(conv) )\n",
    "tags['n-sign_value_currency/value']   = pd.to_numeric( tags['sign_value_currency/value'].apply(conv) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_values = tags [  tags['n-p-sign_value_currency/value']  != tags['n-sign_value_currency/value']]\n",
    "cols = ['n-p-sign_value_currency/value', 'n-sign_value_currency/value']\n",
    "wrong_values = wrong_values[cols]\n",
    "\n",
    "wrong_values ['val_err'] = \\\n",
    "    np.log1p( np.abs(wrong_values['n-p-sign_value_currency/value'] - wrong_values['n-sign_value_currency/value']))\n",
    "wrong_values = wrong_values.sort_values('val_err', ascending=False)\n",
    "\n",
    "print(len(wrong_values))\n",
    "wrong_values.tail(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U8qtdCl3Zdt7"
   },
   "source": [
    "### Contract Org-1 validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oCUtMUEZZduA"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wrong_orgs1 = tags [ (tags['org-1-name'] != tags['p-org-1-name']) | (tags['org-2-name'] != tags['p-org-2-name']) ]\n",
    "print( f'Org-1 name: {len(wrong_orgs1)} of {len(tags)}  ({100. * len(wrong_orgs1) / len(tags):0.1f}%) were detected incorrectly')\n",
    "\n",
    "cols=['p-org-1-name', 'org-1-name', 'p-org-2-name', 'org-2-name']\n",
    "save_csv( wrong_orgs1[cols], 'wrong_orgs1.csv')\n",
    "\n",
    "wrong_orgs1[cols].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "colab_type": "code",
    "id": "HZrAdEP0iwjK",
    "outputId": "73b4e39b-6313-47a8-854e-7f4af1c76ee6"
   },
   "outputs": [],
   "source": [
    "wrong_aliases = tags [ (tags['org-1-alias'] != tags['p-org-1-alias']) | (tags['org-2-alias'] != tags['p-org-2-alias']) ]\n",
    "print( f'Aliases: {len(wrong_aliases)} of {len(tags)}  ({100. * len(wrong_aliases) / len(tags) : 0.1f}%) were detected incorrectly')\n",
    "\n",
    "cols=['p-org-1-alias', 'org-1-alias', 'p-org-2-alias', 'org-2-alias']\n",
    "save_csv( wrong_aliases[cols], 'wrong_aliases.csv')\n",
    "# wrong_aliases[cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6j8omO8Sk2Nv"
   },
   "outputs": [],
   "source": [
    "wrong_types = tags [ (tags['org-1-type'] != tags['p-org-1-type']) | (tags['org-2-type'] != tags['p-org-2-type'])]\n",
    "print( f'Types: {len(wrong_types)} of {len(tags)}  ({100. * len(wrong_types) / len(tags) : 0.1f}%) were detected incorrectly')\n",
    "cols=['p-org-1-type', 'p-org-2-type', 'org-1-type', 'org-2-type']\n",
    "save_csv( wrong_types[cols], 'wrong_types.csv')\n",
    "wrong_types[cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TLXWndqih-oE"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "arrays = [ wrong_orgs1, wrong_types, wrong_numbers, wrong_aliases]\n",
    "counter = Counter()\n",
    "for a in arrays:\n",
    "  for i in a.index:\n",
    "   counter[i]+=1\n",
    " \n",
    "\n",
    "print('–°–∞–º—ã–π —Å–ª–æ–∂–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç: ', counter.most_common()[0][0])\n",
    "print(\"–í—Å–µ–≥–æ –Ω–µ–¥–æ—á–µ—Ç–æ–≤:\", len(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "colab_type": "code",
    "id": "uvG2pH1rt6G_",
    "outputId": "5b9173d2-c781-49bf-cccb-be2b481edee4"
   },
   "outputs": [],
   "source": [
    "umtm.stats['errors'] = 0\n",
    "for c in counter:\n",
    "  umtm.stats.at[c, 'errors'] = counter[c]\n",
    "\n",
    "\n",
    "calculate_samples_weights(umtm)\n",
    "umtm._save_stats()\n",
    "umtm.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_CR9W8NDH8B-"
   },
   "source": [
    "## Single doc eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFzr4k-cpOzX"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  !wget https://raw.githubusercontent.com/nemoware/analyser/uber-models/tests/contract_db_1.json\n",
    "\n",
    "  with open('contract_db_1.json', 'rb') as handle:    \n",
    "    jdata = json.load(handle, object_hook=json_util.object_hook)\n",
    "\n",
    "  jdoc = DbJsonDoc(jdata)\n",
    "\n",
    "else:\n",
    "  from integration.db import get_mongodb_connection\n",
    "  from bson.objectid import ObjectId\n",
    "\n",
    "  def get_doc(objid):\n",
    "    logger.debug(f'fetching {objid}')\n",
    "    db = get_mongodb_connection()\n",
    "    documents_collection = db['documents']\n",
    "    jdata =  documents_collection.find_one({'_id': ObjectId(objid)})\n",
    "    return DbJsonDoc(jdata)\n",
    "\n",
    "  SAMPLE_DOC_ID = counter.most_common()[0][0] #umtm.stats.index[10]\n",
    "    \n",
    "    \n",
    "    \n",
    "  SAMPLE_DOC_ID = '5eea27adc28b75807f3dae66'\n",
    "  print('SAMPLE_DOC_ID:', SAMPLE_DOC_ID)\n",
    "  dp = umtm.make_xyw(SAMPLE_DOC_ID)\n",
    "  (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = dp\n",
    "\n",
    "  jdoc = get_doc(SAMPLE_DOC_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfHQOFhw3yuO"
   },
   "outputs": [],
   "source": [
    "from analyser.legal_docs import embedd_tokens\n",
    "\n",
    "if IN_COLAB:\n",
    "  embedder = ElmoEmbedder.get_instance('elmo')  # lazy init\n",
    "  emb = embedd_tokens(jdoc.get_tokens_for_embedding(),\n",
    "                             embedder,\n",
    "                             verbosity=2,\n",
    "                             log_key='tmp')\n",
    "\n",
    "  tok_f = get_tokens_features(jdoc.get_tokens_map_unchaged().tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yF9kgac_hZr"
   },
   "outputs": [],
   "source": [
    "###############\n",
    "prediction = umodel.predict(   x=[  np.expand_dims(emb, axis=0), np.expand_dims(tok_f, axis=0)] , batch_size=1)\n",
    "##############\n",
    "print(len(prediction), umodel.name)\n",
    "subj_1hot = prediction[1][0]\n",
    "print('Subject:', decode_subj_prediction(subj_1hot))\n",
    "\n",
    "\n",
    "tagging = pd.DataFrame( prediction[0][0], columns=seq_labels_contract)\n",
    "plot_embedding(tagging, title = f'Predictions of {umodel.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBRtwOj5QvNf"
   },
   "outputs": [],
   "source": [
    "def render_slices(slices, tokens, attention_v, ht='') -> str:\n",
    "  ht += '<ol>'\n",
    "  for _s in slices:\n",
    "    ht += '<li>'\n",
    "    t = tokens[_s]\n",
    "    l = attention_v[_s]\n",
    "    ht += to_color_text(t, l, _range=(0, 1.2))\n",
    "    ht += '<br><hr>'\n",
    "    ht += '</li>'\n",
    "  ht += '</ol>'\n",
    "\n",
    "  return ht\n",
    "\n",
    "for t in seq_labels_contract:\n",
    "  spans = list( find_top_spans( tagging[t].values, threshold=0.3))  \n",
    "  display(HTML(render_slices(spans, jdoc.get_tokens_map_unchaged().tokens, tagging[t].values)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mean_ = tagging.values.max(-1)*0.5\n",
    "# print (mean_.shape)\n",
    "# display(HTML( to_color_text (jdoc.get_tokens_map_unchaged().tokens[:24000],  mean_[:24000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = '5edbadd7da3678279fbcaabf\n",
    "5edbc660da3678279fbcaeac\n",
    "5edbc668da3678279fbcaf6e\n",
    "5edbc65dda3678279fbcae56\n",
    "5edbc66bda3678279fbcafe6\n",
    "5edbc615da3678279fbcadc9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9eF-UGHyh-C9",
    "7X_zYCYEdlPM",
    "lyI4hbTRFjyM"
   ],
   "name": "Local: structure keras uber model - clean train, evaluate, test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
