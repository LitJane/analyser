{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JoHJkn9yQIgg",
    "outputId": "6be2f655-1ae2-4dc4-bdb3-a5a69740dfed"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('retrain_contract_uber_model')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.info('logging started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Dehw0fnKfSBF",
    "outputId": "ecfbf2e3-00a9-4c32-c184-88f940a55c47"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print ('Running in colab:', IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ZiBqnGnQfKWF",
    "outputId": "cdf6ade3-0054-4682-8775-42ba618ecb99"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not IN_COLAB:\n",
    "  nb_dir = os.path.split(os.getcwd())[0]\n",
    "  if nb_dir not in sys.path:\n",
    "      sys.path.append(nb_dir)\n",
    "else:\n",
    "  %tensorflow_version 1.x\n",
    "  import tensorflow as tf\n",
    "  print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "colab_type": "code",
    "id": "H5cLtueagMru",
    "outputId": "9f796a4b-1613-4f58-f488-2f1f970c9c0f"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  !pip install --upgrade pip\n",
    "  !pip --version\n",
    "  !pip install --no-deps --upgrade git+https://www.github.com/nemoware/analyser.git@uber-models\n",
    "  !pip install -q pyjarowinkler overrides\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "jT7451NXspdw",
    "outputId": "8da0d25e-5fc1-426d-cdb0-a91a2c46fd91"
   },
   "outputs": [],
   "source": [
    "\n",
    "if not IN_COLAB:\n",
    "  import analyser.hyperparams  \n",
    "  _work_dir_default = os.path.realpath(os.path.join(  analyser.hyperparams.__file__, '..', '..', '..', 'work'))\n",
    "  work_dir = os.environ.get('GPN_WORK_DIR', _work_dir_default)\n",
    "  \n",
    "  if not os.path.isdir(work_dir):\n",
    "    os.mkdir(work_dir)\n",
    "\n",
    "  analyser.hyperparams.work_dir = work_dir\n",
    "else:\n",
    "  import analyser.hyperparams\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  os.environ['GPN_WORK_DIR']='/content/drive/My Drive/GazpromOil/trainsets/uber_2'\n",
    "  analyser.hyperparams.work_dir = os.environ['GPN_WORK_DIR']\n",
    "\n",
    "print('work_dir=', analyser.hyperparams.work_dir)\n",
    "assert os.path.isdir(analyser.hyperparams.work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbsxFAqC6pjQ"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "pexvDJbAtZM0",
    "outputId": "2ffc3c48-fe2f-42b3-a588-6374d7d87b71"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    " \n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "from os import path\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "from colab_support.renderer import *\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bson import json_util\n",
    "\n",
    "from analyser.legal_docs import LegalDocument, make_headline_attention_vector\n",
    "from analyser.headers_detector import make_predicted_headline_attention_vector, get_tokens_features\n",
    "from analyser.hyperparams import models_path\n",
    "from analyser.text_tools import find_top_spans\n",
    "\n",
    "from trainsets.trainset_tools import TrainsetBalancer, SubjectTrainsetManager\n",
    "from trainsets.retrain_contract_uber_model import DbJsonDoc, UberModelTrainsetManager\n",
    "\n",
    "from tf_support import super_contract_model\n",
    "from tf_support.super_contract_model import get_base_model, seq_labels_contract\n",
    "from tf_support.super_contract_model import uber_detection_model_005_1_1\n",
    "from tf_support.tf_subject_model import decode_subj_prediction\n",
    "from tf_support.tools import KerasTrainingContext\n",
    "from tf_support.embedder_elmo import ElmoEmbedder\n",
    "\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Conv1D, LSTM, GRU, BatchNormalization, TimeDistributed, Dense, Bidirectional, Input, Dropout, Lambda\n",
    "from keras.layers import concatenate, SpatialDropout1D, ActivityRegularization\n",
    "from keras.layers import MaxPooling1D, Activation, ThresholdedReLU, GaussianNoise\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRQOy7o0uyTv"
   },
   "source": [
    "# Prepare trainset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gIWUsIvPv2ia",
    "outputId": "89864a7a-f982-4e0a-e0cb-b381f00d8047"
   },
   "outputs": [],
   "source": [
    "umtm = UberModelTrainsetManager ( analyser.hyperparams.work_dir)\n",
    "\n",
    "if not IN_COLAB:\n",
    "  umtm.import_recent_contracts()\n",
    "  umtm.calculate_samples_weights()\n",
    "  umtm.validate_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "colab_type": "code",
    "id": "8pe_gZIK3JFh",
    "outputId": "19e0f014-679b-493f-9289-54f24193c00c"
   },
   "outputs": [],
   "source": [
    "umtm.stats = umtm.stats[  pd.isna(umtm.stats.value_span) + (umtm.stats.value_span < 10000) ] #remove big docs from TS\n",
    "umtm.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "id": "ouUjO_T7xf8A",
    "outputId": "cb348044-912e-4409-bb51-45e44544f881"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "subj_count = umtm.stats['subject'].value_counts()\n",
    "\n",
    "#plot distribution---------------------\n",
    "sns.barplot(subj_count.values, subj_count.index)\n",
    "plt.title('Frequency Distribution of subjects')\n",
    "plt.xlabel('Number of Occurrences')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print ('\\nmin', min (subj_count.values))\n",
    "print ('max', max (subj_count.values))\n",
    "print ('total', sum (subj_count.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "colab_type": "code",
    "id": "Ld_KZaHwqf_G",
    "outputId": "b7a13e6f-2733-445f-9676-9e627d02d76a"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from trainsets.trainset_tools import get_feature_log_weights\n",
    "\n",
    "_classes = umtm.stats['subject'].unique().tolist()\n",
    "\n",
    "print(f'classes: {_classes}')\n",
    "\n",
    "# class_weights = class_weight.compute_class_weight('balanced', _classes, umtm.stats['subject'])\n",
    "# class_weights = dict(zip(_classes, class_weights))\n",
    "\n",
    "\n",
    "class_weights = get_feature_log_weights(umtm.stats, 'subject')\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "Cs6cZtPy6Je1",
    "outputId": "267816e1-3d6a-447f-f9f2-761f4fdbdccc"
   },
   "outputs": [],
   "source": [
    "from trainsets.trainset_tools import get_feature_log_weights\n",
    "\n",
    "def calculate_samples_weights(self):\n",
    "  # TODO: sync with github!\n",
    "  self.stats: DataFrame = self.load_contract_trainset_meta()\n",
    "  subject_weights = get_feature_log_weights(self.stats, 'subject')\n",
    "  \n",
    "  value_median = self.stats.value_log1p.median()\n",
    "\n",
    "  for i, row in self.stats.iterrows():\n",
    "    subj_name = row['subject']\n",
    "\n",
    "    tagging_weight = 1.0\n",
    "    if not pd.isna(row['user_correction_date']):  # MORE weight for user-corrected datapoints\n",
    "      tagging_weight = 10.0  # TODO: must be estimated anyhow smartly\n",
    "\n",
    "    value_weight = value_median\n",
    "    if not pd.isna(row['value_log1p']):\n",
    "      # вес пропорционален логорифму цены контракта,\n",
    "      # чтобы было меньше ошибок в контрактах на большие суммы)\n",
    "      value_weight = row['value_log1p']\n",
    "\n",
    "    tagging_weight *= value_weight\n",
    "    subject_weight = tagging_weight * class_weights[subj_name]\n",
    "    self.stats.at[i, 'subject_weight'] = subject_weight\n",
    "    self.stats.at[i, 'sample_weight']  = tagging_weight\n",
    "\n",
    "  # normalize weights, so the sum == Number of samples\n",
    "  self.stats.sample_weight /= self.stats.sample_weight.mean()\n",
    "  self.stats.subject_weight /= self.stats.subject_weight.mean()\n",
    "\n",
    "  self._save_stats()\n",
    "\n",
    "calculate_samples_weights(umtm)\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "\n",
    "umtm.stats['subject_weight'].hist(bins=20)\n",
    "umtm.stats['sample_weight'].hist(bins=20)\n",
    "\n",
    "plt.xscale('linear') # log?\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "id": "_DjNv8UQ956S",
    "outputId": "ddd6090e-a08d-4bd0-de16-30dac08cd787"
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"subject_weight\", y=\"sample_weight\", data=umtm.stats )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxEdSGOuq62R"
   },
   "source": [
    "### look into trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CRb_AJUliUft",
    "outputId": "e7bbddca-5aaa-4df0-c142-73d98126a0ff"
   },
   "outputs": [],
   "source": [
    "# umtm.calculate_samples_weights()\n",
    "SAMPLE_DOC_ID = umtm.stats.index[0]\n",
    "print('SAMPLE_DOC_ID', SAMPLE_DOC_ID)\n",
    "dp = umtm.make_xyw(SAMPLE_DOC_ID)\n",
    "(emb, tok_f), (sm, subj), (sample_weight, subject_weight) = dp\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_kJ0L2RnrHl3",
    "outputId": "053f745e-d63f-45bb-bc47-14288ba409d6"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plot_embedding(tok_f[:500], title=f'Tokens features {SAMPLE_DOC_ID}') \n",
    "plot_embedding(emb[:500], title=f'Embedding {SAMPLE_DOC_ID}') \n",
    "plot_embedding(sm[:500], title=f'Semantic map {SAMPLE_DOC_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "niaa4g6g2Q7g"
   },
   "source": [
    "## Batch generator & TODOs 🙏\n",
    "\n",
    "\n",
    "- [X] TODO: add outliers to the trainset ?\n",
    "- [ ] TODO: try sparse_categorical_entropy instead of one-hot encodings\n",
    "- [ ] TODO: model 5.2, 5.1: bipolar concat layer is wrong because we concatenate thongs of different magnitudes. Add a Sigmoid activation layer\n",
    "- [ ] TODO: chechk what is better: to pad with zeros or to pad with means\n",
    "- [X] TODO: add weights to samples\n",
    "- [ ] TODO: sum semantic map alongside vertical axis, and mutiply it (as a mask) by the subject detection seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1CFzuOP4w9mB"
   },
   "outputs": [],
   "source": [
    "def make_generator(self, indices: [int], batch_size: int, augment_samples=False):\n",
    "\n",
    "  np.random.seed(42)\n",
    "\n",
    "  while True:\n",
    "    # next batch\n",
    "    batch_indices = np.random.choice(a=indices, size=batch_size)\n",
    "\n",
    "    max_len = 128 * 12\n",
    "    start_from = 0\n",
    "\n",
    "    if augment_samples:\n",
    "      max_len =  random.randint(300, 1400)\n",
    "\n",
    "    batch_input_emb = []\n",
    "    batch_input_token_f = []\n",
    "    batch_output_sm = []\n",
    "    batch_output_subj = []\n",
    "\n",
    "    weights = []\n",
    "    weights_subj = []\n",
    "\n",
    "    # Read in each input, perform preprocessing and get labels\n",
    "    for doc_id in batch_indices:\n",
    "\n",
    "      dp = self.make_xyw(doc_id)\n",
    "      (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = dp\n",
    "\n",
    "      subject_weight_K=1.0\n",
    "      if augment_samples:\n",
    "        start_from = 0\n",
    "        \n",
    "        row = self.stats.loc[doc_id]\n",
    "        if random.randint(1, 2) == 1:  # 50% of samples\n",
    "          segment_center = random.randint(0, len(emb)-1) ##select random token as a center\n",
    "          if not pd.isna(row['value_span']) and random.random()<0.7:        \n",
    "            segment_center = int(row['value_span'])\n",
    "\n",
    "          _off = random.randint(max_len // 4, max_len // 2)\n",
    "          start_from = segment_center - _off\n",
    "          if start_from < 0:\n",
    "            start_from = 0\n",
    "          subject_weight_K = 0.1 #lower subject weight because there mighе be no information about subject around doc. value\n",
    "\n",
    "      dp = self.trim_maxlen(dp, start_from, max_len)\n",
    "      # TODO: find samples maxlen\n",
    "\n",
    "      (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = dp\n",
    "      subject_weight *= subject_weight_K\n",
    "\n",
    "      batch_input_emb.append(emb)\n",
    "      batch_input_token_f.append(tok_f)\n",
    "\n",
    "      batch_output_sm.append(sm)\n",
    "      batch_output_subj.append(subj)\n",
    "\n",
    "      weights.append(sample_weight)\n",
    "      weights_subj.append(subject_weight)\n",
    "      # end if emb\n",
    "    # end for loop\n",
    "\n",
    "    # Return a tuple of (input, output, weights) to feed the network\n",
    "    yield ([np.array(batch_input_emb), np.array(batch_input_token_f)],\n",
    "            [np.array(batch_output_sm), np.array(batch_output_subj)],\n",
    "            [np.array(weights), np.array(weights_subj)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zrKMJ2bsn6yx",
    "outputId": "97d2df0e-d2b2-45a2-a641-ffac39717880"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 24\n",
    "EMB =  1024\n",
    " \n",
    "_SELFTEST = True\n",
    "\n",
    "\n",
    "_train, _test = train_test_split(umtm.stats, test_size=0.2, stratify=umtm.stats[['subject']])\n",
    "train_indices = list(_train.index)\n",
    "test_indices = list(_test.index)\n",
    "\n",
    "\n",
    "print('train_indices[0]:', train_indices[0])\n",
    "print('test_indices[0]:', test_indices[0])\n",
    "\n",
    "\n",
    "def plot_subject_distr(df, title):  \n",
    "  target='subject'\n",
    "  plt.figure(figsize=(16,4))   \n",
    "  sns.set(style=\"whitegrid\")\n",
    "  chart = sns.countplot(data=df, y=target)\n",
    "  plt.title(f'Frequency Distribution of subjects :{title}')\n",
    "\n",
    " \n",
    "plot_subject_distr(umtm.stats, 'ALL')\n",
    "plot_subject_distr(umtm.stats[umtm.stats.index.isin(train_indices)], 'train')\n",
    "plot_subject_distr(umtm.stats[umtm.stats.index.isin(test_indices)], 'test')\n",
    "\n",
    "\n",
    "if _SELFTEST:\n",
    "  # test_gen = make_generator(umtm, test_indices, BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, train_indices, BATCH_SIZE, augment_samples=True)\n",
    "  \n",
    "  x, y, w = next(train_gen)\n",
    "  \n",
    "  print('X:', len(x), 'X[0]=', x[0].shape, 'X[1]=', x[1].shape)\n",
    "  print('Y:', len(y), 'Y[0]=', y[0].shape, 'Y[1]=', y[1].shape)\n",
    "  \n",
    "\n",
    "  plot_embedding(x[0][0], 'X2: Token Embeddings')\n",
    "  plot_embedding(x[1][0], 'X1: Token Features')\n",
    "  plot_embedding(y[0][0], 'Y: Semantic Map')\n",
    "  \n",
    "  print(y[0][1])\n",
    "\n",
    "  # del x 5edbc665da3678279fbcaf1c\n",
    "  del y\n",
    "  del train_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "RIRaSgxCP3Jt",
    "outputId": "4f3862a2-9019-4905-b74f-3f3187e30ebc"
   },
   "outputs": [],
   "source": [
    "\n",
    "ctx = KerasTrainingContext(umtm.work_dir, session_index=21)\n",
    "\n",
    "ctx.set_batch_size_and_trainset_size(BATCH_SIZE, \n",
    "                                     len(test_indices), \n",
    "                                     4 * len(train_indices))\n",
    "\n",
    "DEFAULT_TRAIN_CTX = ctx\n",
    "CLASSES = 43\n",
    "FEATURES = 14\n",
    "\n",
    "metrics = ['kullback_leibler_divergence', 'mse', 'binary_crossentropy']\n",
    "\n",
    "\n",
    "def train(umodel):\n",
    "  test_gen = make_generator(umtm, test_indices, BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, train_indices, BATCH_SIZE, augment_samples=True) \n",
    "  ctx.train_and_evaluate_model(umodel, generator=train_gen, test_generator=test_gen)\n",
    "\n",
    "def overtrain(umodel):\n",
    "  test_gen = make_generator(umtm, list(train_indices) + list(test_indices), BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, list(train_indices) + list(test_indices), BATCH_SIZE, augment_samples=True) \n",
    "  ctx.train_and_evaluate_model(umodel, generator=train_gen, test_generator=test_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6gXvyjKr509e"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def init_model(model_fn) -> (Model, KerasTrainingContext):\n",
    "  model_name = model_fn.__name__\n",
    "  model = model_fn(name=model_name, ctx=ctx, trained=True)\n",
    "  model.name = model_name\n",
    "\n",
    "  weights_file_old = os.path.join(models_path, model_name + \".weights\")\n",
    "  weights_file_new = os.path.join(umtm.work_dir, model_name + \".weights\")\n",
    "\n",
    "  try:\n",
    "    model.load_weights(weights_file_new, by_name=True )\n",
    "    logger.info(f'weights loaded: {weights_file_new}')\n",
    "\n",
    "  except:\n",
    "    msg = f'cannot load  {model_name} from  {weights_file_new}'\n",
    "    warnings.warn(msg)\n",
    "    logger.warning(msg)\n",
    "    model.load_weights(weights_file_old, by_name=True )\n",
    "    logger.info(f'weights loaded: {weights_file_old}')\n",
    "\n",
    "  # freeze bottom 6 layers, including 'embedding_reduced' #TODO: this must be model-specific parameter\n",
    "  for l in model.layers[0:6]:\n",
    "    l.trainable = False\n",
    "\n",
    "  model.compile(loss=super_contract_model.losses, optimizer='Nadam', metrics=super_contract_model.metrics)\n",
    "  model.summary()\n",
    "\n",
    "  return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAFmo0sG4H9k"
   },
   "source": [
    "# Models 🦖"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eF7Ktdfo9aa7"
   },
   "source": [
    "### 5.1.1 💕💕 uber_detection_model_005_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OpgUW39m9abE"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "umodel = init_model(uber_detection_model_005_1_1)\n",
    "\n",
    "######################\n",
    "# Phase I retraining\n",
    "# ❄️ frozen bottom layers\n",
    "######################\n",
    "test_gen = make_generator(umtm, test_indices, BATCH_SIZE)\n",
    "train_gen = make_generator(umtm, train_indices, BATCH_SIZE, augment_samples=True) \n",
    "\n",
    "ctx.EPOCHS = 25\n",
    "ctx.EVALUATE_ONLY = False\n",
    "ctx.train_and_evaluate_model(umodel, generator=train_gen, test_generator=test_gen, retrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LJAH6Fjn9abL"
   },
   "outputs": [],
   "source": [
    "######################\n",
    "## Phase II finetuning\n",
    "#  all unfrozen, entire trainset, low LR\n",
    "######################\n",
    "ctx.unfreezeModel(umodel)\n",
    "umodel.compile(loss=super_contract_model.losses, optimizer='Nadam', metrics=super_contract_model.metrics)\n",
    "umodel.summary()\n",
    "\n",
    "ctx.EPOCHS *= 2\n",
    "\n",
    "test_gen = make_generator(umtm, train_indices + test_indices, BATCH_SIZE)\n",
    "train_gen = make_generator(umtm, train_indices + test_indices, BATCH_SIZE, augment_samples=True) \n",
    " \n",
    "ctx.train_and_evaluate_model(umodel, train_gen, test_generator=test_gen, retrain=False, lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUum89Tdhg-9"
   },
   "source": [
    "# Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NJ9uhDBaJlO"
   },
   "outputs": [],
   "source": [
    "# umodel = ctx.init_model(uber_detection_model_005_1_1, weights_file_override='/content/uber_detection_model_005_1_1', trained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NLRR4qmKImgQ"
   },
   "source": [
    "### training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "me1LdIP5Ik9z"
   },
   "outputs": [],
   "source": [
    "def plot_compare_models(\n",
    "    models: [str],\n",
    "    metrics, \n",
    "    title=\"metric/epoch\",\n",
    "    image_save_path = umtm.work_dir):\n",
    "    \n",
    "  _metrics = [m for m in metrics if not m.startswith('val_')]\n",
    "\n",
    "  for i, m in enumerate(models):\n",
    "\n",
    "    data: pd.DataFrame = ctx.get_log(m)\n",
    "\n",
    "    if data is not None:\n",
    "      data.set_index('epoch')\n",
    "\n",
    "      for metric in _metrics:\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        plt.grid()\n",
    "        plt.title(f'{metric}')\n",
    "        for metric_variant in ['', 'val_']:\n",
    "          key = metric_variant + metric\n",
    "          if key in data:\n",
    "\n",
    "            x = data['epoch'][-100:]\n",
    "            y = data[key][-100:]\n",
    "\n",
    "\n",
    "            c = 'red'  # plt.cm.jet_r(i * colorstep)\n",
    "            if metric_variant == '':\n",
    "              c = 'blue'\n",
    "            plt.plot(x, y, label=f'{key}', alpha=0.2, color=c)\n",
    "\n",
    "            y = y.rolling(4, win_type='gaussian').mean(std=4)\n",
    "            plt.plot(x, y, label=f'{key} SMOOTH', color=c)\n",
    "\n",
    "            plt.legend(loc='upper right')\n",
    "\n",
    "        \n",
    "        plt.title(f'{m} {title}')\n",
    "        plt.grid()\n",
    "        img_path = os.path.join(image_save_path, f'{m}-{metric}.png')\n",
    "        plt.savefig(img_path, bbox_inches='tight')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    else:\n",
    "      logger.error('cannot plot')\n",
    "    \n",
    "\n",
    "models = list(ctx.trained_models.keys())\n",
    "\n",
    "\n",
    "plot_compare_models(models, ['loss'], 'Loss')\n",
    "\n",
    "plot_compare_models(models, ['O1_tagging_kullback_leibler_divergence'], 'TAGS: Kullback Leibler divergence')\n",
    "plot_compare_models(models, ['O1_tagging_mse'], 'TAGS: MSE')\n",
    "plot_compare_models(models, ['O2_subject_kullback_leibler_divergence'], 'Subj: Kullback Leibler divergence')\n",
    "plot_compare_models(models, ['O2_subject_mse'],  'Subjects: MSE')\n",
    "\n",
    "plot_compare_models(models, ['O1_tagging_loss', 'O2_subject_loss'], 'Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v1p8Mqpi32Bf"
   },
   "source": [
    "## Contract subj Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJLgtkpo-NUY"
   },
   "outputs": [],
   "source": [
    "def plot_cm(y_true, y_pred, figsize=(12, 12), title=None):\n",
    "  cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "  cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "  cm_perc = cm / cm_sum.astype(float) * 100\n",
    "  annot = np.empty_like(cm).astype(str)\n",
    "  nrows, ncols = cm.shape\n",
    "  for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "      c = cm[i, j]\n",
    "      p = cm_perc[i, j]\n",
    "      if i == j:\n",
    "        s = cm_sum[i]\n",
    "        annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "      elif c == 0:\n",
    "        annot[i, j] = ''\n",
    "      else:\n",
    "        annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "\n",
    "  cm = pd.DataFrame(cm_perc, index=np.unique(y_true), columns=np.unique(y_true))\n",
    "  cm.index.name = 'Actual'\n",
    "  cm.columns.name = 'Predicted'\n",
    "  fig, ax = plt.subplots(figsize=figsize)\n",
    "  sns.heatmap(cm, cmap=\"YlGnBu\", annot=annot, fmt='', ax=ax)\n",
    "  plt.title(title)\n",
    "\n",
    "\n",
    "def make_subj_predictions(umodel, indices):\n",
    "  ev = umtm.stats.copy()\n",
    "\n",
    "  errors_report = pd.DataFrame()\n",
    "  errors_report['expected'] = ''\n",
    "  errors_report['predicted'] = ''\n",
    "\n",
    "  for _id in indices:\n",
    "\n",
    "    x, y, _ = umtm.make_xyw(_id)\n",
    "    embeddings = x[0]\n",
    "    token_features = x[1]\n",
    "    prediction = umodel.predict(x=[np.expand_dims(embeddings, axis=0), np.expand_dims(token_features, axis=0)],\n",
    "                                batch_size=1)\n",
    "\n",
    "    subj_1hot = prediction[1][0]\n",
    "\n",
    "    expected = decode_subj_prediction(y[1])[0]\n",
    "    predicted = decode_subj_prediction(subj_1hot)[0]\n",
    "\n",
    "    ev.at[_id, 'expected_subj']=expected.name\n",
    "    ev.at[_id, 'predicted_subj']=predicted.name\n",
    "\n",
    "    ev.at[_id, 'wrong'] = False\n",
    "    if expected != predicted:\n",
    "      eval.at[_id, 'wrong'] = True       \n",
    "\n",
    "  return ev\n",
    "\n",
    "\n",
    "\n",
    "subset = umtm.stats[~pd.isna(umtm.stats['user_correction_date'])].sort_values('analyze_date')\n",
    "ev = make_subj_predictions(umodel, subset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "colab_type": "code",
    "id": "Jh1WFsjprUr1",
    "outputId": "53318327-6bcf-479e-aeef-b7b580ca3cfd"
   },
   "outputs": [],
   "source": [
    "ev=eval\n",
    "errors_report = ev [ ev.wrong == True].sort_values('expected_subj')\n",
    "print(len(errors_report), 'wrong subjects of', len(subset))\n",
    "errors_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MFh8SxP9J081",
    "outputId": "bbc7373e-e764-43cf-ab39-b53c62e7c551"
   },
   "outputs": [],
   "source": [
    "def make_report(umodel, ev):\n",
    "  plot_cm(ev['expected_subj'], ev['predicted_subj'], title=umodel.name)\n",
    "  \n",
    "  img_path = os.path.join(umtm.work_dir, f'subjects-confusion-matrix-{umodel.name}.png')\n",
    "  plt.savefig(img_path, bbox_inches='tight')\n",
    "\n",
    "  report = classification_report(ev['expected_subj'], ev['predicted_subj'], digits=3)\n",
    "  print(umodel.name)\n",
    "  print(report)\n",
    "  \n",
    "  with open(os.path.join(umtm.work_dir, f'subjects-classification_report-{umodel.name}.txt'), \"w\") as text_file:\n",
    "    text_file.write(report)\n",
    "\n",
    "\n",
    "make_report(umodel, ev[~pd.isna(ev['predicted_subj'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_CR9W8NDH8B-"
   },
   "source": [
    "## Single doc eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "tFzr4k-cpOzX",
    "outputId": "7acfd961-6d63-4d8d-c513-214198d310fe"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  !wget https://raw.githubusercontent.com/nemoware/analyser/uber-models/tests/contract_db_1.json\n",
    "\n",
    "  with open('contract_db_1.json', 'rb') as handle:    \n",
    "    jdata = json.load(handle, object_hook=json_util.object_hook)\n",
    "\n",
    "  jdoc = DbJsonDoc(jdata)\n",
    "\n",
    "else:\n",
    "  from integration.db import get_mongodb_connection\n",
    "  from bson.objectid import ObjectId\n",
    "\n",
    "  SAMPLE_DOC_ID = umtm.stats.index[10]\n",
    "  print('SAMPLE_DOC_ID', SAMPLE_DOC_ID)\n",
    "  dp = umtm.make_xyw(SAMPLE_DOC_ID)\n",
    "  (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = dp\n",
    "\n",
    "\n",
    "  print(f'fetching {SAMPLE_DOC_ID}')\n",
    "  db = get_mongodb_connection()\n",
    "  documents_collection = db['documents']\n",
    "  jdata =  documents_collection.find_one({'_id': ObjectId(SAMPLE_DOC_ID)})\n",
    "  jdoc = DbJsonDoc(jdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "TfHQOFhw3yuO",
    "outputId": "aa42f86e-706c-4225-e807-62ff244e2727"
   },
   "outputs": [],
   "source": [
    "from analyser.legal_docs import embedd_tokens\n",
    "\n",
    "if IN_COLAB:\n",
    "  embedder = ElmoEmbedder.get_instance('elmo')  # lazy init\n",
    "  emb = embedd_tokens(jdoc.get_tokens_for_embedding(),\n",
    "                             embedder,\n",
    "                             verbosity=2,\n",
    "                             log_key='tmp')\n",
    "\n",
    "  tok_f = get_tokens_features(jdoc.get_tokens_map_unchaged().tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "-yF9kgac_hZr",
    "outputId": "a91d4e93-e868-4b26-870b-1190cc6690b1"
   },
   "outputs": [],
   "source": [
    "###############\n",
    "prediction = umodel.predict(   x=[  np.expand_dims(emb, axis=0), np.expand_dims(tok_f, axis=0)] , batch_size=1)\n",
    "##############\n",
    "print(len(prediction), umodel.name)\n",
    "tagging = prediction[0][0]\n",
    "\n",
    "subj_1hot = prediction[1][0]\n",
    "print('Subject:', decode_subj_prediction(subj_1hot))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(tagging, columns=seq_labels_contract)\n",
    "\n",
    "plot_embedding(df, title = f'Predictions of {umodel.name}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBRtwOj5QvNf"
   },
   "outputs": [],
   "source": [
    "def render_slices(slices, tokens, attention_v, ht='') -> str:\n",
    "  ht += '<ol>'\n",
    "  for _s in slices:\n",
    "    ht += '<li>'\n",
    "    t = tokens[_s]\n",
    "    l = attention_v[_s]\n",
    "    ht += to_color_text(t, l, _range=(0, 1.2))\n",
    "    ht += '<br><hr>'\n",
    "    ht += '</li>'\n",
    "  ht += '</ol>'\n",
    "\n",
    "  return ht\n",
    "\n",
    "for t in seq_labels_contract:\n",
    "  spans = list( find_top_spans( df[t].values, threshold=0.3))  \n",
    "  print(t.upper(), spans)\n",
    "  display(HTML(render_slices(spans, jdoc.get_tokens_map_unchaged().tokens, df[t].values)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BtKQtmZ48U1f"
   },
   "outputs": [],
   "source": [
    "mean_ = df.values.max(-1)*0.5\n",
    "print (mean_.shape)\n",
    "display(HTML( to_color_text (jdoc.get_tokens_map_unchaged().tokens[:14000],  mean_[:14000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9eF-UGHyh-C9",
    "7X_zYCYEdlPM",
    "lyI4hbTRFjyM"
   ],
   "name": "Local: structure keras uber model - clean train, evaluate, test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
