{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2058ddee",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JoHJkn9yQIgg",
    "papermill": {
     "duration": 0.020788,
     "end_time": "2023-01-26T10:09:21.502764",
     "exception": false,
     "start_time": "2023-01-26T10:09:21.481976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger('retrain_ipynb')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(levelname)s - %(asctime)s - %(name)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.debug('--=logging started=--')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6c90a",
   "metadata": {
    "papermill": {
     "duration": 0.006423,
     "end_time": "2023-01-26T10:09:21.516481",
     "exception": false,
     "start_time": "2023-01-26T10:09:21.510058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb8e62",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "TRAIN = False\n",
    "\n",
    "USE_CONTROL_SET = True\n",
    "\n",
    "\n",
    "TRAIN_TEST_SPLIT_SEED = 49\n",
    "TEST_SIZE = 0.1\n",
    "TRAIN_FROM_CP = True  \n",
    "\n",
    "# CP===check point\n",
    "\n",
    "# EPOCHS = 120\n",
    "EPOCHS = 120\n",
    "LR = 5.000e-4\n",
    "\n",
    "#learning rate\n",
    "\n",
    "TEST_FLOW = False\n",
    "DEBUG = False\n",
    "\n",
    "\n",
    "# CHECKPOINT_URL = 'runs:/89d43de209874227af95fcbeaf048340/model'\n",
    "CHECKPOINT_URL = None\n",
    "\n",
    "\n",
    "BATCH_SIZE = 72\n",
    "EMB =  1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fccb910",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Dehw0fnKfSBF",
    "outputId": "3bcb61cd-401a-43d7-dccf-9a6022b2a576",
    "papermill": {
     "duration": 0.010629,
     "end_time": "2023-01-26T10:09:21.533624",
     "exception": false,
     "start_time": "2023-01-26T10:09:21.522995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print (f'{USE_CONTROL_SET=}')\n",
    "print (f'{TRAIN_FROM_CP=}')\n",
    "print (f'{LR=}')\n",
    "print (f'{EPOCHS=}')\n",
    "print (f'{TRAIN=}')\n",
    "print (f'{DEBUG=}')\n",
    "print (f'{CHECKPOINT_URL=}')\n",
    "\n",
    "\n",
    "print (f'{BATCH_SIZE=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15dacfb",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZiBqnGnQfKWF",
    "papermill": {
     "duration": 0.010891,
     "end_time": "2023-01-26T10:09:21.551366",
     "exception": false,
     "start_time": "2023-01-26T10:09:21.540475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "  sys.path.append(nb_dir)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3c7e2",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jT7451NXspdw",
    "papermill": {
     "duration": 0.01449,
     "end_time": "2023-01-26T10:09:21.616569",
     "exception": false,
     "start_time": "2023-01-26T10:09:21.602079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eddb4ff",
   "metadata": {
    "colab_type": "text",
    "id": "JbsxFAqC6pjQ",
    "papermill": {
     "duration": 0.006596,
     "end_time": "2023-01-26T10:09:21.643082",
     "exception": false,
     "start_time": "2023-01-26T10:09:21.636486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df140a0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "pexvDJbAtZM0",
    "outputId": "4f7e6e34-d675-423d-d102-1020d49d854f",
    "papermill": {
     "duration": 5.563081,
     "end_time": "2023-01-26T10:09:27.212769",
     "exception": false,
     "start_time": "2023-01-26T10:09:21.649688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "\n",
    "print(f'{tf.__version__=}')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import DataFrame \n",
    "\n",
    "from bson import json_util\n",
    "\n",
    " \n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.models import Sequential, Model, load_model\n",
    " \n",
    "\n",
    "\n",
    "#-------- ours\n",
    "\n",
    "from analyser.legal_docs import LegalDocument, make_headline_attention_vector\n",
    "from analyser.headers_detector import TOKEN_FEATURES\n",
    "from analyser.hyperparams import models_path, work_dir, notebooks_dir, reports_dir\n",
    "from analyser.persistence import DbJsonDoc\n",
    "\n",
    "from trainsets.retrain_contract_uber_model import UberModelTrainsetManager\n",
    "\n",
    "from tf_support import super_contract_model\n",
    "from tf_support.super_contract_model import semantic_map_keys_contract\n",
    "from tf_support.super_contract_model import validate_datapoint\n",
    "from tf_support.super_contract_model import make_xyw\n",
    "from tf_support.super_contract_model import config, make_att_model\n",
    "from tf_support.super_contract_model import FEATURES \n",
    "from tf_support.super_contract_model import sigmoid_focal_crossentropy, losses\n",
    "\n",
    "from tf_support.tf_subject_model import decode_subj_prediction\n",
    "from tf_support.tools import KerasTrainingContext\n",
    "\n",
    "from colab_support.renderer import *\n",
    " \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7445d095-02ad-4c55-b0c2-63c907528350",
   "metadata": {},
   "source": [
    "# Init mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cf9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "ml_flow_url = configured('MLFLOW_URL')\n",
    "mlflow.set_tracking_uri(ml_flow_url)\n",
    "print(f'{ml_flow_url=}', 'set MLFLOW_URL env var to re-define')\n",
    "mlflow.set_experiment(\"Обучение анализатора\")\n",
    "\n",
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ad469b",
   "metadata": {
    "colab_type": "text",
    "id": "HRQOy7o0uyTv",
    "papermill": {
     "duration": 0.006884,
     "end_time": "2023-01-26T10:09:27.896593",
     "exception": false,
     "start_time": "2023-01-26T10:09:27.889709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare trainset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6c097-3545-48b9-a9f3-ce23f3979b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from integration.db import get_mongodb_connection  \n",
    "from bson.objectid import ObjectId\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cb31f9",
   "metadata": {
    "papermill": {
     "duration": 0.010796,
     "end_time": "2023-01-26T10:09:27.928015",
     "exception": false,
     "start_time": "2023-01-26T10:09:27.917219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "COLLECTION_NAME = 'documents'\n",
    "if USE_CONTROL_SET:\n",
    "    COLLECTION_NAME = 'documents_temp'\n",
    "    \n",
    "mongodb_connection = get_mongodb_connection()\n",
    "\n",
    "if USE_CONTROL_SET: \n",
    "    documents_collection = mongodb_connection[COLLECTION_NAME]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185edf0-b9e0-4a54-ad8b-4b3b73e84909",
   "metadata": {},
   "source": [
    "## Load DS metafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10512f7f",
   "metadata": {
    "papermill": {
     "duration": 1.744057,
     "end_time": "2023-01-26T10:09:29.711406",
     "exception": false,
     "start_time": "2023-01-26T10:09:27.967349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "umtm = UberModelTrainsetManager (work_dir, reports_dir=reports_dir)\n",
    "\n",
    "umtm.load_contract_trainset_meta() # 'contract_trainset_meta.csv'\n",
    "stats = umtm.stats\n",
    "\n",
    "if DEBUG:\n",
    "    stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f306b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats[ ['org-1-alias', 'org-2-alias'] ]\n",
    "\n",
    "user_dataset = stats[ stats['unseen']==False]\n",
    "\n",
    "print(f'{len(user_dataset)=}')\n",
    "print(f'{len(stats)=}')\n",
    "\n",
    "\n",
    "# mlflow.log_param('dataset_len_user', len(user_dataset) )\n",
    "# mlflow.log_param('dataset_len', len(stats) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06044745",
   "metadata": {
    "papermill": {
     "duration": 0.011182,
     "end_time": "2023-01-26T10:09:29.761289",
     "exception": false,
     "start_time": "2023-01-26T10:09:29.750107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    user_dataset[user_dataset.subj_len>=150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b43cfe",
   "metadata": {
    "papermill": {
     "duration": 0.007218,
     "end_time": "2023-01-26T10:09:29.776017",
     "exception": false,
     "start_time": "2023-01-26T10:09:29.768799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weights: вычисление весов samples  \n",
    "\n",
    " - weight id proportional to log of contract price (less errors in expencive contracts)\n",
    " - more weight for user-corrected datapoints\n",
    " - normalize weights, so the sum == Number of samples\n",
    " - smaller weight for docs with human mark-up errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda10df",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_file = reports_dir / 'user_markup_errors.csv'\n",
    "print(f'{errors_file=}')\n",
    "try:\n",
    "  errors_df = pd.read_csv(errors_file, index_col=0)\n",
    "except:\n",
    "  print(f'cannot read {errors_file}')\n",
    "  errors_df = DataFrame(columns=['errors severity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb0d92",
   "metadata": {
    "papermill": {
     "duration": 0.007249,
     "end_time": "2023-01-26T10:09:29.790575",
     "exception": false,
     "start_time": "2023-01-26T10:09:29.783326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "stats = umtm.stats\n",
    "stats = stats[stats.documentType != 'ANNEX']\n",
    "stats = stats[stats.documentType != 'undefined']\n",
    "\n",
    "print(len(stats))\n",
    "get_feature_log_weights(stats, 'documentType')\n",
    "\n",
    "# stats.sort_values(['Дата']) \n",
    "\n",
    "if DEBUG:\n",
    "    stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc0c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from trainsets.trainset_tools import get_feature_log_weights\n",
    "# _w=get_feature_log_weights(umtm.stats, 'subject')\n",
    "# _w*_w*_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c5a14",
   "metadata": {
    "papermill": {
     "duration": 0.565472,
     "end_time": "2023-01-26T10:09:30.363404",
     "exception": false,
     "start_time": "2023-01-26T10:09:29.797932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import datetime\n",
    "from trainsets.trainset_tools import get_feature_log_weights\n",
    "\n",
    "subject_weights = get_feature_log_weights(stats, 'subject')\n",
    "subject_weights = subject_weights * subject_weights * subject_weights\n",
    "\n",
    "for i, row in stats.iterrows():\n",
    "  subj_name = row['subject']\n",
    "\n",
    "  #error weight\n",
    "  error_weight = 1.0 \n",
    "  if i in errors_df.index:\n",
    "      error_weight = 1.0 + errors_df.at[i, 'errors severity']\n",
    "\n",
    "\n",
    "  sample_weight = 0.5 \n",
    "  value_weight = 1.0\n",
    "    \n",
    "  if i in errors_df.index:\n",
    "       \n",
    "      if type(errors_df.at[i, 'Дата'])==str:\n",
    "#             print (errors_df.at[i, 'Дата'], i, 'EXISTS')\n",
    "          value_weight *=1.5\n",
    "    \n",
    "  if not pd.isna(row['user_correction_date']):  # more weight for user-corrected datapoints\n",
    "    sample_weight = 5.0   # TODO: must be estimated anyhow smartly    \n",
    "\n",
    "  \n",
    "  if not pd.isna(row['value_log1p']):\n",
    "    # чтобы всех запутать, вес пропорционален логорифму цены контракта\n",
    "    # (чтобы было меньше ошибок в контрактах на большие суммы)\n",
    "    value_weight = 1.0 + row['value_log1p']\n",
    "\n",
    "  sample_weight *=  value_weight \n",
    "  subject_weight =  subject_weights[subj_name] \n",
    "    \n",
    "  sample_weight /= error_weight  \n",
    "\n",
    "  stats.at[i, 'subject_weight'] = subject_weight + random.random()*0.05\n",
    "  stats.at[i, 'sample_weight'] = sample_weight + random.random()*0.05\n",
    "\n",
    "# normalize weights, so the sum == Number of samples\n",
    "# stats.sample_weight /= stats.sample_weight.mean()\n",
    "# stats.subject_weight /= stats.subject_weight.mean()\n",
    "\n",
    "print(f'{stats.sample_weight.mean()=}')\n",
    "print(f'{stats.subject_weight.mean()=}')\n",
    "print(f'{stats.sample_weight.min()=}')\n",
    "print(f'{stats.subject_weight.min()=}')\n",
    "print(f'{stats.sample_weight.max()=}')\n",
    "print(f'{stats.subject_weight.max()=}')\n",
    "\n",
    "stats.to_csv( work_dir / 'contract_trainset_meta.csv', index=True)\n",
    "\n",
    "# stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0c25d2",
   "metadata": {
    "papermill": {
     "duration": 0.007515,
     "end_time": "2023-01-26T10:09:30.397876",
     "exception": false,
     "start_time": "2023-01-26T10:09:30.390361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Validating training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358608d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "colab_type": "code",
    "id": "8pe_gZIK3JFh",
    "outputId": "7b923b06-f592-4b11-bb35-d215566e017d",
    "papermill": {
     "duration": 9.602735,
     "end_time": "2023-01-26T10:09:40.008113",
     "exception": false,
     "start_time": "2023-01-26T10:09:30.405378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# stats['valid'] = True\n",
    "stats['error'] = ''\n",
    "\n",
    " \n",
    "pos = 0 \n",
    "for i in stats.index:\n",
    "\n",
    "  try:\n",
    "    validate_datapoint(str(i), stats)\n",
    "\n",
    "  except Exception as e:\n",
    "    ms = f'{pos} of {len(stats.index)} : {e}' \n",
    "    logger.error(ms)\n",
    "\n",
    "    stats.at[i, 'valid'] = False\n",
    "    stats.at[i, 'error'] = str(e)\n",
    "  pos += 1\n",
    "# stats\n",
    "\n",
    " \n",
    "\n",
    "umtm.stats = umtm.stats[  pd.isna(umtm.stats.value_span) + (umtm.stats.value_span < 10000) ] #remove big docs from TS\n",
    "stats_valid = stats[stats['valid']]\n",
    "\n",
    "del stats\n",
    "print(len(stats_valid))\n",
    "stats = stats_valid\n",
    "umtm.stats = stats_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6644b1bc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'{stats.sample_weight.mean()=}')\n",
    "print(f'{stats.subject_weight.mean()=}')\n",
    "\n",
    "stats.sample_weight /= stats.sample_weight.mean()\n",
    "stats.subject_weight /= stats.subject_weight.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792906a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{stats.sample_weight.mean()=}')\n",
    "print(f'{stats.subject_weight.mean()=}')\n",
    "\n",
    "print('\\n\\nsample_weight')\n",
    "print('MIN\\t', stats.sample_weight.min())\n",
    "print('MAX\\t', stats.sample_weight.max())\n",
    "print('MEAN\\t', stats.sample_weight.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37250b34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "colab_type": "code",
    "id": "Ld_KZaHwqf_G",
    "outputId": "c974398a-62a1-44e8-b73c-6589766b05c7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from trainsets.trainset_tools import get_feature_log_weights\n",
    "\n",
    "_classes = stats_valid['subject'].unique().tolist()\n",
    "\n",
    "print(f'classes: {_classes}')\n",
    "\n",
    "# class_weights = class_weight.compute_class_weight('balanced', _classes, umtm.stats['subject'])\n",
    "# class_weights = dict(zip(_classes, class_weights))\n",
    "\n",
    "\n",
    "class_weights = get_feature_log_weights(stats_valid, 'subject')\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd30110e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "colab_type": "code",
    "id": "Cs6cZtPy6Je1",
    "outputId": "f0a39fff-f3c5-4418-b087-0eef915b7a81",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trainsets.trainset_tools import get_feature_log_weights\n",
    "import mlflow\n",
    "\n",
    "fig = plt.figure(figsize=(13, 6))\n",
    "\n",
    "stats_valid['subject_weight'].hist(bins=40, alpha=0.5)\n",
    "stats_valid['sample_weight'].hist(bins=40, alpha=0.5)\n",
    "\n",
    "plt.xscale('linear') # log?\n",
    "plt.show()\n",
    "mlflow.log_figure(fig, 'Weights Distribution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8068a03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "id": "_DjNv8UQ956S",
    "outputId": "6ded6bae-e1f0-4a77-9024-64da80c6e47f",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(13, 6))\n",
    "\n",
    "p = sns.jointplot(x=\"subject_weight\", y=\"sample_weight\", data=stats_valid)\n",
    "plt.show()\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522545b",
   "metadata": {
    "colab_type": "text",
    "id": "IxEdSGOuq62R",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# look into trainset (take a sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d593f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CRb_AJUliUft",
    "outputId": "0369b8f3-7423-45f3-a0ed-3459408ccec0",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# umtm.calculate_samples_weights()\n",
    " \n",
    "if True:   \n",
    "    SAMPLE_DOC_ID =  stats_valid.index[2]\n",
    "\n",
    "    print('SAMPLE_DOC_ID', SAMPLE_DOC_ID)\n",
    "    (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = make_xyw(SAMPLE_DOC_ID, stats)\n",
    "\n",
    "\n",
    "    print('semantic map shape is:', sm.shape)\n",
    "    _crop = 500\n",
    "    # plot_embedding(tok_f[:_crop], title=f'Tokens features {SAMPLE_DOC_ID}') \n",
    "    # plot_embedding(emb[:_crop], title=f'Embedding {SAMPLE_DOC_ID}') \n",
    "    plot_embedding(sm[:_crop], title=f'Semantic map {SAMPLE_DOC_ID}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78fd4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if DEBUG: \n",
    "  plot_embedding(sm[:, 1::2][:200], title=f'Semantic map {SAMPLE_DOC_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc44d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:   \n",
    "    nonzerozz = np.where(sm[:, 1::2] > 0)[0]\n",
    "    max_len = 1536\n",
    "    # nonzerozz = list(set(nonzerozz))\n",
    "    # nonzerozz\n",
    "\n",
    "    # c=random.choice(nonzerozz)\n",
    "    # sm[c-1:c]\n",
    "    sm = sm*100.\n",
    "    for i in range(0,2000):\n",
    "        segment_center = random.choice(nonzerozz)\n",
    "\n",
    "        _off = random.randint(-max_len//40, max_len//2)\n",
    "        start_from = segment_center - _off\n",
    "        if start_from < 0:\n",
    "            start_from = 0\n",
    "        if start_from >=len(emb):\n",
    "            start_from = len(emb)-1\n",
    "\n",
    "        sm[start_from: start_from+max_len]+=1\n",
    "\n",
    "    plot_embedding(sm, title=f'Semantic map {SAMPLE_DOC_ID}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ed6ec2",
   "metadata": {
    "colab_type": "text",
    "id": "niaa4g6g2Q7g",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Batch generator & TODOs 🙏\n",
    "\n",
    "\n",
    "- [X] TODO: add outliers to the trainset ?\n",
    "- [ ] TODO: try sparse_categorical_entropy instead of one-hot encodings\n",
    "- [ ] TODO: model 5.2, 5.1: bipolar concat layer is wrong because we concatenate thongs of different magnitudes. Add a Sigmoid activation layer\n",
    "- [ ] TODO: chechk what is better: to pad with zeros or to pad with means\n",
    "- [X] TODO: add weights to samples\n",
    "- [ ] TODO: sum semantic map alongside vertical axis, and mutiply it (as a mask) by the subject detection seq\n",
    "- [ ] TODO: introduce individual per tag threshosholds, also, the current 0.3 threshold is strange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2a3ef2",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1CFzuOP4w9mB",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "MAX_LEN = 1536\n",
    "def make_generator(self, indices: [int], batch_size: int, augment_samples=False):\n",
    "  #   np.random.seed(43)\n",
    "\n",
    "  while True:\n",
    "    # next batch\n",
    "    batch_indices = np.random.choice(a=indices, size=batch_size)\n",
    "\n",
    "    max_len = MAX_LEN\n",
    "    start_from = 0\n",
    "\n",
    "    if augment_samples:\n",
    "      max_len = random.randint(300, MAX_LEN)\n",
    "\n",
    "    batch_input_emb = []\n",
    "    batch_input_token_f = []\n",
    "    batch_output_sm = []\n",
    "    batch_output_subj = []\n",
    "\n",
    "    weights = []\n",
    "    weights_subj = []\n",
    "\n",
    "    # Read in each input, perform preprocessing and get labels\n",
    "    for doc_id in batch_indices:\n",
    "\n",
    "      dp = make_xyw(doc_id, stats)\n",
    "      (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = dp\n",
    "\n",
    "      #       print(dp)\n",
    "\n",
    "      subject_weight_K = 1.0\n",
    "      if augment_samples:\n",
    "        start_from = 0\n",
    "\n",
    "        # row = stats_valid.loc[doc_id]\n",
    "        if random.random() < 0.6:  # 60% of samples\n",
    "          nonzerozz = np.where(sm[:, 1::2] > 0)[0] #take every second row, because these are end marks\n",
    "#           nonzerozz = nonzerozz\n",
    "          \n",
    "          segment_center = random.choice(nonzerozz)\n",
    "          if len(nonzerozz)==0:\n",
    "             segment_center=0\n",
    "\n",
    "\n",
    "          # segment_center = random.randint(0, len(emb) - 1)  ##select random token as a center\n",
    "\n",
    "          # if not pd.isna(row['value_span']) and random.random() < 0.7:  ##select value token as a center\n",
    "          #   segment_center = int(row['value_span'])\n",
    "\n",
    "          # _off = random.randint(max_len // 4, max_len // 2)\n",
    "          _off = random.randint(-max_len//10, max_len//2)\n",
    "          start_from = segment_center - _off\n",
    "          if start_from < 0:\n",
    "            start_from = 0\n",
    "          if start_from >=len(emb):\n",
    "            start_from = len(emb)-1\n",
    "#           print('start_from', start_from)\n",
    "#           if random_row != 1:#subject row, see semantic_map_keys\n",
    "#               subject_weight_K = 0.1  # lower subject weight because there mighе be no information about subject around doc. value\n",
    "\n",
    "      # dp = self.trim_maxlen(dp, start_from, max_len)\n",
    "      dp = UberModelTrainsetManager.trim_maxlen(dp, start_from, max_len)\n",
    "\n",
    "      # TODO: find samples maxlen\n",
    "\n",
    "      (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = dp\n",
    "      #       print((sample_weight, subject_weight))\n",
    "      subject_weight *= subject_weight_K\n",
    "\n",
    "      batch_input_emb.append(emb)\n",
    "      batch_input_token_f.append(tok_f)\n",
    "\n",
    "      batch_output_sm.append(sm)\n",
    "      batch_output_subj.append(subj)\n",
    "\n",
    "      if np.isnan(sample_weight):\n",
    "        raise ValueError()\n",
    "\n",
    "      if np.isnan(subject_weight):\n",
    "        raise ValueError()\n",
    "\n",
    "      weights.append(sample_weight)\n",
    "      weights_subj.append(subject_weight)\n",
    "      # end if emb\n",
    "    # end for loop\n",
    "\n",
    "    # Returns a tuple of (input, output, weights) to feed the network\n",
    "    #     print('batch_output_subj', len(batch_output_subj))\n",
    "    #     print('batch_output_sm', len(batch_output_subj))\n",
    "\n",
    "    yield ([np.array(batch_input_emb), np.array(batch_input_token_f)],\n",
    "           [np.array(batch_output_sm), np.array(batch_output_subj)],\n",
    "           [np.array(weights), np.array(weights_subj)])\n",
    "    \n",
    "\n",
    "    \n",
    "_train, _test = train_test_split(stats_valid, test_size=TEST_SIZE, stratify=stats_valid[['subject']], random_state=TRAIN_TEST_SPLIT_SEED)\n",
    "\n",
    "train_indices = list(_train.index)\n",
    "test_indices = list(_test.index)\n",
    "\n",
    "    \n",
    "####---test\n",
    "_gen = make_generator(umtm, train_indices, batch_size=10, augment_samples=True)\n",
    "\n",
    "sample = next(_gen)\n",
    "# print(len(sample))\n",
    "del _gen\n",
    " \n",
    "(emb, tok_f), (sm, subj), (sample_weight, subject_weight) = sample\n",
    "    \n",
    "print('semantic map shape is:', sm.shape)\n",
    "_crop = 1500\n",
    "_ = plot_embedding(tok_f[0][:_crop], title=f'Tokens features') \n",
    "# plot_embedding(emb[:_crop],   title=f'Embedding {SAMPLE_DOC_ID}') \n",
    "_ = plot_embedding(pd.DataFrame( sm[0], columns= semantic_map_keys_contract) [:_crop],    title=f'Semantic map', height=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5342db82",
   "metadata": {},
   "source": [
    "## [debug] Diagnose SM Rows in TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3865769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_embedding(pd.DataFrame( sm[0], columns= semantic_map_keys_contract) [:_crop],    title=f'Semantic map', height=8)\n",
    "if DEBUG:\n",
    "    _crop = 350\n",
    "    batch_size=100\n",
    "    mtx = np.zeros((batch_size, _crop))\n",
    "\n",
    "\n",
    "    _gen = make_generator(umtm, train_indices, batch_size=batch_size, augment_samples=True) \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    for i in range(0, batch_size):\n",
    "\n",
    "        sample = next(_gen)\n",
    "        (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = sample\n",
    "\n",
    "\n",
    "        sub = sm[0][:,4:6][:_crop] #pd.DataFrame( sm[0], columns= semantic_map_keys_contract) [:_crop][['date-begin']]\n",
    "\n",
    "    #     print(sub[:,0].max())\n",
    "        mtx [i][0:len(sub[:,0])] = sub[:,0]\n",
    "\n",
    "    fig = plot_embedding(mtx.T,    title=f'Semantic map, combined Date rows of {batch_size} samples', height=5)\n",
    "    mlflow.log_figure(fig, 'Diagnose SM Rows in TS.png')\n",
    "    del _gen\n",
    "    del mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "mlflow.log_param('training set', len(train_indices) )\n",
    "mlflow.log_param('evaluation set', len(test_indices) )\n",
    "\n",
    "_s = f\"#### {len(train_indices)} -- total  docs training set\"\n",
    "display(Markdown(_s))\n",
    "_s = f\"#### {len(test_indices)} -- total  docs validation set\"\n",
    "display(Markdown(_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c5ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    dp = make_xyw(stats.index[0], stats_valid)\n",
    "\n",
    "    (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = dp\n",
    "\n",
    "    fig = plot_embedding(sm[:500],    title=f'Semantic map ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a3f015",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "zrKMJ2bsn6yx",
    "outputId": "f39d06b8-8af2-4570-fa72-481633dfe61c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('train_indices[0]:', train_indices[0])\n",
    "print('test_indices[0]:', test_indices[0])\n",
    "\n",
    "\n",
    "def plot_subject_distr(df:DataFrame, title):  \n",
    "    target='subject'\n",
    "    fig = plt.figure(figsize=(16,4))   \n",
    "    sns.set(style=\"whitegrid\")\n",
    "    chart = sns.countplot(data=df.sort_values(target), y=target)\n",
    "    t = f'{title}: Frequency Distribution of subjects; {len(df)} total'\n",
    "    plt.title(t) \n",
    "\n",
    "    _fn = reports_dir / f'Distribution of subjects -{title}.png'\n",
    "    plt.savefig(_fn , bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()\n",
    "\n",
    "    mlflow.log_artifact(_fn)\n",
    "\n",
    "\n",
    " \n",
    "plot_subject_distr(stats_valid, 'ALL')\n",
    "plot_subject_distr(stats_valid[stats_valid.index.isin(train_indices)], 'training')\n",
    "plot_subject_distr(stats_valid[stats_valid.index.isin(test_indices)], 'eval')\n",
    "\n",
    "\n",
    "\n",
    "if DEBUG:   \n",
    "  # test_gen = make_generator(umtm, test_indices, BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, train_indices, BATCH_SIZE, augment_samples=True)\n",
    "  \n",
    "  x, y, w = next(train_gen)\n",
    "  \n",
    "#   print('X:', len(x), 'X[0]=', x[0].shape, 'X[1]=', x[1].shape)\n",
    "#   print('Y:', len(y), 'Y[0]=', y[0].shape, 'Y[1]=', y[1].shape)\n",
    "  \n",
    "\n",
    "#   plot_embedding(x[0][0], 'X2: Token Embeddings')\n",
    "#   plot_embedding(x[1][0], 'X1: Token Features')\n",
    "#   plot_embedding(y[0][0], 'Y: Semantic Map')\n",
    "  \n",
    "#   print(y[0][1])\n",
    "\n",
    "#   del x\n",
    "#   del w\n",
    "#   del y\n",
    "#   del train_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b776a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "RIRaSgxCP3Jt",
    "outputId": "4f253294-c07c-481f-ca0f-5cbea0d31d97",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "ctx = KerasTrainingContext(checkpoints_path=umtm.reports_dir, session_index=1)\n",
    "\n",
    "ctx.set_batch_size_and_trainset_size(BATCH_SIZE, \n",
    "                                     len(test_indices), \n",
    "                                     4 * len(train_indices))\n",
    "\n",
    "DEFAULT_TRAIN_CTX = ctx\n",
    "CLASSES = 43\n",
    "FEATURES = 14\n",
    "\n",
    "metrics = [  'mse', 'binary_crossentropy']\n",
    "# metrics = ['kullback_leibler_divergence', 'mse', 'binary_crossentropy']\n",
    "\n",
    "\n",
    "def train(umodel):\n",
    "  test_gen = make_generator(umtm, test_indices, BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, train_indices, BATCH_SIZE, augment_samples=True) \n",
    "  ctx.train_and_evaluate_model(umodel, generator=train_gen, test_generator=test_gen)\n",
    "\n",
    "def overtrain(umodel):\n",
    "  test_gen = make_generator(umtm, list(train_indices) + list(test_indices), BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, list(train_indices) + list(test_indices), BATCH_SIZE, augment_samples=True) \n",
    "  ctx.train_and_evaluate_model(umodel, generator=train_gen, test_generator=test_gen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17dbb8",
   "metadata": {
    "colab_type": "text",
    "id": "gAFmo0sG4H9k",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Models 🦖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedecdc5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import analyser\n",
    "def get_weights_filename(model_factory_fn):\n",
    "    weights = ctx.model_checkpoint_path / f'{model_factory_fn.__name__}.h5'\n",
    "    print(weights.is_file(), weights)\n",
    "    if not weights.is_file():\n",
    "        weights = Path(analyser.hyperparams.models_path) / f'{model_factory_fn.__name__}.h5'\n",
    "        print(weights.is_file(), weights)\n",
    "    \n",
    "    return weights\n",
    "\n",
    "# get_weights_filename(uber_detection_model_005_1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0e0d09",
   "metadata": {},
   "source": [
    "## 🥰 Att model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44020ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_factory_fn = make_att_model      \n",
    "# TRAIN_FROM_CP = True\n",
    "if TRAIN_FROM_CP:\n",
    "    weights = get_weights_filename(model_factory_fn)\n",
    "else:\n",
    "    # weights = Path(analyser.hyperparams.models_path) / f'{model_factory_fn.__name__}.h5'\n",
    "    #TODO: fix this mess with TRAIN_FROM_CP and CHECKPOINT_URL flags\n",
    "    weights = None\n",
    "    # \n",
    "    \n",
    "# weights = Path(analyser.hyperparams.models_path) / f'{model_factory_fn.__name__}.h5'\n",
    "\n",
    "\n",
    "# TRAIN_FROM_CP=True        \n",
    "if not TEST_FLOW:\n",
    "    \n",
    "    umodel = make_att_model() \n",
    "    \n",
    "    print(f'{umodel.name=}')    \n",
    "\n",
    "    if CHECKPOINT_URL is not None:\n",
    "        logger.info(f'LOADING {CHECKPOINT_URL}')\n",
    "        umodel = mlflow.tensorflow.load_model(CHECKPOINT_URL)\n",
    "        # TODO:TEST IT, FIX IT\n",
    "    else:\n",
    "        if TRAIN_FROM_CP:\n",
    "            logger.info(f'LOADING {weights}')\n",
    "            print(f'LOADING {weights=}')\n",
    "            umodel.load_weights(weights, by_name=True, skip_mismatch=True)\n",
    "        else:\n",
    "            logger.warning(f'skip loading weights, because {TRAIN_FROM_CP=}')\n",
    "\n",
    "    # if DEBUG:    \n",
    "    umodel.summary()\n",
    "\n",
    "# raise \"forsibly stopped\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_img_file = f'{umodel.name}.png'\n",
    "# keras.utils.plot_model(umodel, to_file=dot_img_file, show_shapes=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43116bee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(self, model:Model, generator, test_generator, retrain=False, lr=None):\n",
    "    print(f'model.name == {model.name}')\n",
    "    self.trained_models[model.name] = model.name\n",
    "    if self.EVALUATE_ONLY:\n",
    "      print(f'training skipped EVALUATE_ONLY = {self.EVALUATE_ONLY}')\n",
    "      return\n",
    "\n",
    "    _log_fn = f'{model.name}.{self.session_index}.log.csv'\n",
    "    _logger1 = CSVLogger(self.model_checkpoint_path / _log_fn, separator=',', append=not retrain)\n",
    "    _logger2 = CSVLogger(_log_fn, separator=',', append=not retrain)\n",
    "\n",
    "    checkpoint_weights = ModelCheckpoint(self.model_checkpoint_path / (model.name + \".h5\"),\n",
    "                                         monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True,\n",
    "                                         verbose=1)\n",
    "\n",
    "    lr_logged = None\n",
    "    if not retrain:\n",
    "      lr_logged, epoch = self.get_lr_epoch_from_log(model.name)\n",
    "    else:\n",
    "      epoch = 0\n",
    "\n",
    "    if lr_logged is not None:\n",
    "      K.set_value(model.optimizer.lr, lr_logged)\n",
    "\n",
    "    if lr is not None:\n",
    "      K.set_value(model.optimizer.lr, lr)\n",
    "\n",
    "    print(f'continue: lr:{K.get_value(model.optimizer.lr)}, epoch:{epoch}')\n",
    "\n",
    "\n",
    "    history = model.fit(\n",
    "                    generator, batch_size=BATCH_SIZE,\n",
    "#                     steps_per_epoch=train_steps,\n",
    "                    epochs=self.EPOCHS,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=self.validation_steps,\n",
    "                    steps_per_epoch=self.steps_per_epoch,\n",
    "#                     class_weight=class_weights,\n",
    "                    initial_epoch=epoch, \n",
    "#                     workers=8,\n",
    "                    callbacks=[self.reduce_lr, checkpoint_weights, _logger2, _logger1]\n",
    "                    )\n",
    "    \n",
    "    \n",
    "\n",
    "    self.HISTORIES[model.name] = history\n",
    "    self.save_stats(model.name)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "if not TEST_FLOW:\n",
    "\n",
    "    if TRAIN:\n",
    "      config.LR = LR\n",
    "      ctx.unfreezeModel(umodel)\n",
    "    #   umodel.summary()\n",
    "\n",
    "      ctx.EPOCHS = EPOCHS\n",
    "      ctx.EVALUATE_ONLY = False\n",
    "\n",
    "      BATCH_SIZE = 96\n",
    "      test_gen = make_generator(umtm, train_indices + test_indices, BATCH_SIZE)\n",
    "      train_gen = make_generator(umtm, train_indices + test_indices, BATCH_SIZE, augment_samples=True) \n",
    "\n",
    "      train_and_evaluate_model(ctx, umodel, train_gen, test_generator=test_gen, retrain=True, lr=config.LR)\n",
    "    else:\n",
    "      logger.warning(f'skip training, because TRAIN={TRAIN}')\n",
    "\n",
    "\n",
    "    threshold = umodel.get_layer('O1_tagging').get_weights()\n",
    "    if threshold:\n",
    "        print('threshold=', threshold[0][0])\n",
    "\n",
    "        mlflow.log_metric('trained_tags_threshold', threshold[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c83915-7ac9-493b-80bd-d77f25830fe9",
   "metadata": {},
   "source": [
    "## Register model in MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace3c0dc-70a5-4c15-a8fc-246902a1a15c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlflow.log_artifact(ctx.model_checkpoint_path / f'{model_factory_fn.__name__}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd58c6b",
   "metadata": {
    "colab_type": "text",
    "id": "JUum89Tdhg-9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f12e828",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NJ9uhDBaJlO",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not TEST_FLOW:\n",
    "    if umodel:\n",
    "        del umodel\n",
    "\n",
    "    #######################################\n",
    "    #######################################\n",
    "    model_fn = make_att_model\n",
    "    # model_fn = uber_detection_model_003\n",
    "    #######################################\n",
    "    #######################################\n",
    "\n",
    "\n",
    "    weights = ctx.model_checkpoint_path /  f'{model_factory_fn.__name__}.h5'\n",
    "    logger.info(f'LOADING {weights}')\n",
    "    print(f'LOADING {weights}')\n",
    "\n",
    "    umodel = make_att_model() \n",
    "    umodel.load_weights(weights, by_name=False, skip_mismatch=False)\n",
    "    umodel.trainable = False\n",
    "    umodel.summary()\n",
    "\n",
    "    # umodel = ctx.init_model(model_fn, trained=True, trainable=False, weights=ctx.model_checkpoint_path / f'{model_fn.__name__}.h5')\n",
    "\n",
    "\n",
    "\n",
    "    #TODO: remove next 2 lines\n",
    "    ctx.trained_models[umodel.name] = umodel.name\n",
    "    models = ctx.trained_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec371e0",
   "metadata": {
    "colab_type": "text",
    "id": "NLRR4qmKImgQ",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8fda3e",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "me1LdIP5Ik9z",
    "outputId": "1bf81b8f-1f09-4760-a0f3-868a523652d9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_compare_models(\n",
    "    models: [str],\n",
    "    metrics, \n",
    "    title=\"metric/epoch\",\n",
    "    image_save_path = umtm.reports_dir):\n",
    "    \n",
    "  _metrics = [m for m in metrics if not m.startswith('val_')]\n",
    "\n",
    "  for i, m in enumerate(models):\n",
    "\n",
    "    data: pd.DataFrame = ctx.get_log(m)\n",
    "\n",
    "    if data is not None:\n",
    "      data.set_index('epoch')\n",
    "\n",
    "      for metric in _metrics:\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        plt.grid(True)\n",
    "        plt.title(f'{metric} [{m}]')\n",
    "        for metric_variant in ['', 'val_']:\n",
    "          key = metric_variant + metric\n",
    "          if key in data:\n",
    "\n",
    "            x = data['epoch'][-100:]\n",
    "            y = data[key][-100:]\n",
    "\n",
    "\n",
    "            c = 'red'  # plt.cm.jet_r(i * colorstep)\n",
    "            if metric_variant == '':\n",
    "              c = 'blue'\n",
    "            plt.plot(x, y, label=f'{key}', alpha=0.2, color=c)\n",
    "\n",
    "            y = y.rolling(4, win_type='gaussian').mean(std=4)\n",
    "            plt.plot(x, y, label=f'{key} SMOOTH', color=c)\n",
    "\n",
    "            plt.legend(loc='upper right')\n",
    "\n",
    "        \n",
    "        plt.title(f'{[m]} {title}')\n",
    "        plt.grid(True)\n",
    "        img_path = os.path.join(image_save_path, f'{m}-{metric}.png')\n",
    "        \n",
    "        plt.savefig(img_path, bbox_inches='tight')        \n",
    "        plt.show()\n",
    "    else:\n",
    "      logger.error('cannot plot')\n",
    "    \n",
    "if not TEST_FLOW:\n",
    "    models = list(ctx.trained_models.keys())\n",
    "\n",
    "\n",
    "    plot_compare_models(models, ['loss'], 'Loss')\n",
    "\n",
    "    # plot_compare_models(models, ['O1_tagging_kullback_leibler_divergence'], 'TAGS: Kullback Leibler divergence')\n",
    "    # plot_compare_models(models, ['O1_tagging_mse'], 'TAGS: MSE')\n",
    "    # plot_compare_models(models, ['O2_subject_kullback_leibler_divergence'], 'Subj: Kullback Leibler divergence')\n",
    "    # plot_compare_models(models, ['O2_subject_mse'],  'Subjects: MSE')\n",
    "\n",
    "    plot_compare_models(models, ['O1_tagging_loss', 'O2_subject_loss'], 'Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041d7c73",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tf_support.super_contract_model import make_xyw\n",
    "logger.error(\"fix prediction!!\")\n",
    "if False:\n",
    "    sample_index = umtm.stats [umtm.stats['value']>0].index[2]\n",
    "    logger.info(f'making prediction for sample doc {sample_index}')\n",
    "\n",
    "    x, y, _ = make_xyw(sample_index, umtm.stats)\n",
    "    print(f'shape of x[0]={x[0].shape}')\n",
    "    print(f'shape of x[1]={x[1].shape}')\n",
    "\n",
    "    t1 = np.expand_dims(x[0], axis=0)\n",
    "    t2 = np.expand_dims(x[1], axis=0)\n",
    "\n",
    "    print(f'shape of t1={t1.shape}')\n",
    "    print(f'shape of t2={t2.shape}')\n",
    "    print(f'umodel.name ={umodel.name}')\n",
    "\n",
    "    prediction = umodel.predict(x=[t1, t2], batch_size=1)\n",
    "\n",
    "    tagsmap = pd.DataFrame(prediction[0][0], columns=semantic_map_keys_contract)\n",
    "    # .T\n",
    "    plot_embedding(tagsmap[:500], f'Predicted Semantic Map {tagsmap.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fd349d",
   "metadata": {},
   "source": [
    "# Evaluate recent model (with external notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b30f54",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not TEST_FLOW:\n",
    "    %run -i -t {notebooks_dir}/eval_contract_uber_model.ipynb\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41099a96",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('see results at')\n",
    "print(f'{mlflow.get_registry_uri()}/#/experiments/{mlflow.last_active_run().info.experiment_id}/runs/{mlflow.last_active_run().info.run_id}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9eF-UGHyh-C9",
    "7X_zYCYEdlPM",
    "lyI4hbTRFjyM"
   ],
   "name": "Local: structure keras uber model - clean train, evaluate, test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.612159,
   "end_time": "2023-01-26T10:09:40.188121",
   "environment_variables": {},
   "exception": null,
   "input_path": "trainsets/retrain_contract_uber_model.ipynb",
   "output_path": "trainsets/retrain_contract_uber_model.ipynb",
   "parameters": {},
   "start_time": "2023-01-26T10:09:20.575962",
   "version": "2.4.0"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
