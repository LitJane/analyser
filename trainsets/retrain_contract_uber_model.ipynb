{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2058ddee",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JoHJkn9yQIgg",
    "papermill": {
     "duration": 0.020788,
     "end_time": "2023-01-26T10:09:21.502764",
     "exception": false,
     "start_time": "2023-01-26T10:09:21.481976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger('retrain_ipynb')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(levelname)s - %(asctime)s - %(name)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.debug('--=logging started=--')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6c90a",
   "metadata": {
    "papermill": {
     "duration": 0.006423,
     "end_time": "2023-01-26T10:09:21.516481",
     "exception": false,
     "start_time": "2023-01-26T10:09:21.510058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb8e62",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "TRAIN = False\n",
    "\n",
    "USE_CONTROL_SET = True\n",
    "\n",
    "\n",
    "TRAIN_TEST_SPLIT_SEED = 49\n",
    "TEST_SIZE = 0.1\n",
    "TRAIN_FROM_CP = True  \n",
    "\n",
    "# CP===check point\n",
    "\n",
    "# EPOCHS = 120\n",
    "EPOCHS = 120\n",
    "LR = 5.000e-4\n",
    "\n",
    "#learning rate\n",
    "\n",
    "TEST_FLOW = False\n",
    "DEBUG = False\n",
    "\n",
    "\n",
    "# CHECKPOINT_URL = 'runs:/89d43de209874227af95fcbeaf048340/model'\n",
    "CHECKPOINT_URL = None\n",
    "\n",
    "\n",
    "BATCH_SIZE = 72\n",
    "EMB =  1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fccb910",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Dehw0fnKfSBF",
    "outputId": "3bcb61cd-401a-43d7-dccf-9a6022b2a576",
    "papermill": {
     "duration": 0.010629,
     "end_time": "2023-01-26T10:09:21.533624",
     "exception": false,
     "start_time": "2023-01-26T10:09:21.522995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print (f'{USE_CONTROL_SET=}')\n",
    "print (f'{TRAIN_FROM_CP=}')\n",
    "print (f'{LR=}')\n",
    "print (f'{EPOCHS=}')\n",
    "print (f'{TRAIN=}')\n",
    "print (f'{DEBUG=}')\n",
    "print (f'{CHECKPOINT_URL=}')\n",
    "\n",
    "\n",
    "print (f'{BATCH_SIZE=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15dacfb",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZiBqnGnQfKWF",
    "papermill": {
     "duration": 0.010891,
     "end_time": "2023-01-26T10:09:21.551366",
     "exception": false,
     "start_time": "2023-01-26T10:09:21.540475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "  sys.path.append(nb_dir)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3c7e2",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jT7451NXspdw",
    "papermill": {
     "duration": 0.01449,
     "end_time": "2023-01-26T10:09:21.616569",
     "exception": false,
     "start_time": "2023-01-26T10:09:21.602079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eddb4ff",
   "metadata": {
    "colab_type": "text",
    "id": "JbsxFAqC6pjQ",
    "papermill": {
     "duration": 0.006596,
     "end_time": "2023-01-26T10:09:21.643082",
     "exception": false,
     "start_time": "2023-01-26T10:09:21.636486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df140a0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "pexvDJbAtZM0",
    "outputId": "4f7e6e34-d675-423d-d102-1020d49d854f",
    "papermill": {
     "duration": 5.563081,
     "end_time": "2023-01-26T10:09:27.212769",
     "exception": false,
     "start_time": "2023-01-26T10:09:21.649688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "\n",
    "print(f'{tf.__version__=}')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import DataFrame \n",
    "\n",
    "from bson import json_util\n",
    "\n",
    " \n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.models import Sequential, Model, load_model\n",
    " \n",
    "\n",
    "\n",
    "#-------- ours\n",
    "\n",
    "from analyser.legal_docs import LegalDocument, make_headline_attention_vector\n",
    "from analyser.headers_detector import TOKEN_FEATURES\n",
    "from analyser.hyperparams import models_path, work_dir, notebooks_dir, reports_dir\n",
    "from analyser.persistence import DbJsonDoc\n",
    "\n",
    "from trainsets.retrain_contract_uber_model import UberModelTrainsetManager\n",
    "\n",
    "from tf_support import super_contract_model\n",
    "from tf_support.super_contract_model import semantic_map_keys_contract\n",
    "from tf_support.super_contract_model import validate_datapoint\n",
    "from tf_support.super_contract_model import make_xyw\n",
    "from tf_support.super_contract_model import config, make_att_model\n",
    "from tf_support.super_contract_model import FEATURES \n",
    "from tf_support.super_contract_model import sigmoid_focal_crossentropy, losses\n",
    "\n",
    "from tf_support.tf_subject_model import decode_subj_prediction\n",
    "from tf_support.tools import KerasTrainingContext\n",
    "\n",
    "from colab_support.renderer import *\n",
    " \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7445d095-02ad-4c55-b0c2-63c907528350",
   "metadata": {},
   "source": [
    "# Init mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cf9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "ml_flow_url = configured('MLFLOW_URL')\n",
    "mlflow.set_tracking_uri(ml_flow_url)\n",
    "print(f'{ml_flow_url=}', 'set MLFLOW_URL env var to re-define')\n",
    "mlflow.set_experiment(\"–û–±—É—á–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞\")\n",
    "\n",
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ad469b",
   "metadata": {
    "colab_type": "text",
    "id": "HRQOy7o0uyTv",
    "papermill": {
     "duration": 0.006884,
     "end_time": "2023-01-26T10:09:27.896593",
     "exception": false,
     "start_time": "2023-01-26T10:09:27.889709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare trainset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6c097-3545-48b9-a9f3-ce23f3979b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from integration.db import get_mongodb_connection  \n",
    "from bson.objectid import ObjectId\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cb31f9",
   "metadata": {
    "papermill": {
     "duration": 0.010796,
     "end_time": "2023-01-26T10:09:27.928015",
     "exception": false,
     "start_time": "2023-01-26T10:09:27.917219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "COLLECTION_NAME = 'documents'\n",
    "if USE_CONTROL_SET:\n",
    "    COLLECTION_NAME = 'documents_temp'\n",
    "    \n",
    "mongodb_connection = get_mongodb_connection()\n",
    "\n",
    "if USE_CONTROL_SET: \n",
    "    documents_collection = mongodb_connection[COLLECTION_NAME]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185edf0-b9e0-4a54-ad8b-4b3b73e84909",
   "metadata": {},
   "source": [
    "## Load DS metafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10512f7f",
   "metadata": {
    "papermill": {
     "duration": 1.744057,
     "end_time": "2023-01-26T10:09:29.711406",
     "exception": false,
     "start_time": "2023-01-26T10:09:27.967349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "umtm = UberModelTrainsetManager (work_dir, reports_dir=reports_dir)\n",
    "\n",
    "umtm.load_contract_trainset_meta() # 'contract_trainset_meta.csv'\n",
    "stats = umtm.stats\n",
    "\n",
    "if DEBUG:\n",
    "    stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f306b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats[ ['org-1-alias', 'org-2-alias'] ]\n",
    "\n",
    "user_dataset = stats[ stats['unseen']==False]\n",
    "\n",
    "print(f'{len(user_dataset)=}')\n",
    "print(f'{len(stats)=}')\n",
    "\n",
    "\n",
    "# mlflow.log_param('dataset_len_user', len(user_dataset) )\n",
    "# mlflow.log_param('dataset_len', len(stats) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06044745",
   "metadata": {
    "papermill": {
     "duration": 0.011182,
     "end_time": "2023-01-26T10:09:29.761289",
     "exception": false,
     "start_time": "2023-01-26T10:09:29.750107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    user_dataset[user_dataset.subj_len>=150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b43cfe",
   "metadata": {
    "papermill": {
     "duration": 0.007218,
     "end_time": "2023-01-26T10:09:29.776017",
     "exception": false,
     "start_time": "2023-01-26T10:09:29.768799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weights: –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ samples  \n",
    "\n",
    " - weight id proportional to log of contract price (less errors in expencive contracts)\n",
    " - more weight for user-corrected datapoints\n",
    " - normalize weights, so the sum == Number of samples\n",
    " - smaller weight for docs with human mark-up errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda10df",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_file = reports_dir / 'user_markup_errors.csv'\n",
    "print(f'{errors_file=}')\n",
    "try:\n",
    "  errors_df = pd.read_csv(errors_file, index_col=0)\n",
    "except:\n",
    "  print(f'cannot read {errors_file}')\n",
    "  errors_df = DataFrame(columns=['errors severity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb0d92",
   "metadata": {
    "papermill": {
     "duration": 0.007249,
     "end_time": "2023-01-26T10:09:29.790575",
     "exception": false,
     "start_time": "2023-01-26T10:09:29.783326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "stats = umtm.stats\n",
    "stats = stats[stats.documentType != 'ANNEX']\n",
    "stats = stats[stats.documentType != 'undefined']\n",
    "\n",
    "print(len(stats))\n",
    "get_feature_log_weights(stats, 'documentType')\n",
    "\n",
    "# stats.sort_values(['–î–∞—Ç–∞']) \n",
    "\n",
    "if DEBUG:\n",
    "    stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc0c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from trainsets.trainset_tools import get_feature_log_weights\n",
    "# _w=get_feature_log_weights(umtm.stats, 'subject')\n",
    "# _w*_w*_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c5a14",
   "metadata": {
    "papermill": {
     "duration": 0.565472,
     "end_time": "2023-01-26T10:09:30.363404",
     "exception": false,
     "start_time": "2023-01-26T10:09:29.797932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import datetime\n",
    "from trainsets.trainset_tools import get_feature_log_weights\n",
    "\n",
    "subject_weights = get_feature_log_weights(stats, 'subject')\n",
    "subject_weights = subject_weights * subject_weights * subject_weights\n",
    "\n",
    "for i, row in stats.iterrows():\n",
    "  subj_name = row['subject']\n",
    "\n",
    "  #error weight\n",
    "  error_weight = 1.0 \n",
    "  if i in errors_df.index:\n",
    "      error_weight = 1.0 + errors_df.at[i, 'errors severity']\n",
    "\n",
    "\n",
    "  sample_weight = 0.5 \n",
    "  value_weight = 1.0\n",
    "    \n",
    "  if i in errors_df.index:\n",
    "       \n",
    "      if type(errors_df.at[i, '–î–∞—Ç–∞'])==str:\n",
    "#             print (errors_df.at[i, '–î–∞—Ç–∞'], i, 'EXISTS')\n",
    "          value_weight *=1.5\n",
    "    \n",
    "  if not pd.isna(row['user_correction_date']):  # more weight for user-corrected datapoints\n",
    "    sample_weight = 5.0   # TODO: must be estimated anyhow smartly    \n",
    "\n",
    "  \n",
    "  if not pd.isna(row['value_log1p']):\n",
    "    # —á—Ç–æ–±—ã –≤—Å–µ—Ö –∑–∞–ø—É—Ç–∞—Ç—å, –≤–µ—Å –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª–µ–Ω –ª–æ–≥–æ—Ä–∏—Ñ–º—É —Ü–µ–Ω—ã –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞\n",
    "    # (—á—Ç–æ–±—ã –±—ã–ª–æ –º–µ–Ω—å—à–µ –æ—à–∏–±–æ–∫ –≤ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞—Ö –Ω–∞ –±–æ–ª—å—à–∏–µ —Å—É–º–º—ã)\n",
    "    value_weight = 1.0 + row['value_log1p']\n",
    "\n",
    "  sample_weight *=  value_weight \n",
    "  subject_weight =  subject_weights[subj_name] \n",
    "    \n",
    "  sample_weight /= error_weight  \n",
    "\n",
    "  stats.at[i, 'subject_weight'] = subject_weight + random.random()*0.05\n",
    "  stats.at[i, 'sample_weight'] = sample_weight + random.random()*0.05\n",
    "\n",
    "# normalize weights, so the sum == Number of samples\n",
    "# stats.sample_weight /= stats.sample_weight.mean()\n",
    "# stats.subject_weight /= stats.subject_weight.mean()\n",
    "\n",
    "print(f'{stats.sample_weight.mean()=}')\n",
    "print(f'{stats.subject_weight.mean()=}')\n",
    "print(f'{stats.sample_weight.min()=}')\n",
    "print(f'{stats.subject_weight.min()=}')\n",
    "print(f'{stats.sample_weight.max()=}')\n",
    "print(f'{stats.subject_weight.max()=}')\n",
    "\n",
    "stats.to_csv( work_dir / 'contract_trainset_meta.csv', index=True)\n",
    "\n",
    "# stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0c25d2",
   "metadata": {
    "papermill": {
     "duration": 0.007515,
     "end_time": "2023-01-26T10:09:30.397876",
     "exception": false,
     "start_time": "2023-01-26T10:09:30.390361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Validating training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358608d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "colab_type": "code",
    "id": "8pe_gZIK3JFh",
    "outputId": "7b923b06-f592-4b11-bb35-d215566e017d",
    "papermill": {
     "duration": 9.602735,
     "end_time": "2023-01-26T10:09:40.008113",
     "exception": false,
     "start_time": "2023-01-26T10:09:30.405378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# stats['valid'] = True\n",
    "stats['error'] = ''\n",
    "\n",
    " \n",
    "pos = 0 \n",
    "for i in stats.index:\n",
    "\n",
    "  try:\n",
    "    validate_datapoint(str(i), stats)\n",
    "\n",
    "  except Exception as e:\n",
    "    ms = f'{pos} of {len(stats.index)} : {e}' \n",
    "    logger.error(ms)\n",
    "\n",
    "    stats.at[i, 'valid'] = False\n",
    "    stats.at[i, 'error'] = str(e)\n",
    "  pos += 1\n",
    "# stats\n",
    "\n",
    " \n",
    "\n",
    "umtm.stats = umtm.stats[  pd.isna(umtm.stats.value_span) + (umtm.stats.value_span < 10000) ] #remove big docs from TS\n",
    "stats_valid = stats[stats['valid']]\n",
    "\n",
    "del stats\n",
    "print(len(stats_valid))\n",
    "stats = stats_valid\n",
    "umtm.stats = stats_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6644b1bc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'{stats.sample_weight.mean()=}')\n",
    "print(f'{stats.subject_weight.mean()=}')\n",
    "\n",
    "stats.sample_weight /= stats.sample_weight.mean()\n",
    "stats.subject_weight /= stats.subject_weight.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792906a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{stats.sample_weight.mean()=}')\n",
    "print(f'{stats.subject_weight.mean()=}')\n",
    "\n",
    "print('\\n\\nsample_weight')\n",
    "print('MIN\\t', stats.sample_weight.min())\n",
    "print('MAX\\t', stats.sample_weight.max())\n",
    "print('MEAN\\t', stats.sample_weight.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37250b34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "colab_type": "code",
    "id": "Ld_KZaHwqf_G",
    "outputId": "c974398a-62a1-44e8-b73c-6589766b05c7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from trainsets.trainset_tools import get_feature_log_weights\n",
    "\n",
    "_classes = stats_valid['subject'].unique().tolist()\n",
    "\n",
    "print(f'classes: {_classes}')\n",
    "\n",
    "# class_weights = class_weight.compute_class_weight('balanced', _classes, umtm.stats['subject'])\n",
    "# class_weights = dict(zip(_classes, class_weights))\n",
    "\n",
    "\n",
    "class_weights = get_feature_log_weights(stats_valid, 'subject')\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd30110e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "colab_type": "code",
    "id": "Cs6cZtPy6Je1",
    "outputId": "f0a39fff-f3c5-4418-b087-0eef915b7a81",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trainsets.trainset_tools import get_feature_log_weights\n",
    "import mlflow\n",
    "\n",
    "fig = plt.figure(figsize=(13, 6))\n",
    "\n",
    "stats_valid['subject_weight'].hist(bins=40, alpha=0.5)\n",
    "stats_valid['sample_weight'].hist(bins=40, alpha=0.5)\n",
    "\n",
    "plt.xscale('linear') # log?\n",
    "plt.show()\n",
    "mlflow.log_figure(fig, 'Weights Distribution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8068a03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "id": "_DjNv8UQ956S",
    "outputId": "6ded6bae-e1f0-4a77-9024-64da80c6e47f",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(13, 6))\n",
    "\n",
    "p = sns.jointplot(x=\"subject_weight\", y=\"sample_weight\", data=stats_valid)\n",
    "plt.show()\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522545b",
   "metadata": {
    "colab_type": "text",
    "id": "IxEdSGOuq62R",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# look into trainset (take a sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d593f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CRb_AJUliUft",
    "outputId": "0369b8f3-7423-45f3-a0ed-3459408ccec0",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# umtm.calculate_samples_weights()\n",
    " \n",
    "if True:   \n",
    "    SAMPLE_DOC_ID =  stats_valid.index[2]\n",
    "\n",
    "    print('SAMPLE_DOC_ID', SAMPLE_DOC_ID)\n",
    "    (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = make_xyw(SAMPLE_DOC_ID, stats)\n",
    "\n",
    "\n",
    "    print('semantic map shape is:', sm.shape)\n",
    "    _crop = 500\n",
    "    # plot_embedding(tok_f[:_crop], title=f'Tokens features {SAMPLE_DOC_ID}') \n",
    "    # plot_embedding(emb[:_crop], title=f'Embedding {SAMPLE_DOC_ID}') \n",
    "    plot_embedding(sm[:_crop], title=f'Semantic map {SAMPLE_DOC_ID}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78fd4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if DEBUG: \n",
    "  plot_embedding(sm[:, 1::2][:200], title=f'Semantic map {SAMPLE_DOC_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc44d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:   \n",
    "    nonzerozz = np.where(sm[:, 1::2] > 0)[0]\n",
    "    max_len = 1536\n",
    "    # nonzerozz = list(set(nonzerozz))\n",
    "    # nonzerozz\n",
    "\n",
    "    # c=random.choice(nonzerozz)\n",
    "    # sm[c-1:c]\n",
    "    sm = sm*100.\n",
    "    for i in range(0,2000):\n",
    "        segment_center = random.choice(nonzerozz)\n",
    "\n",
    "        _off = random.randint(-max_len//40, max_len//2)\n",
    "        start_from = segment_center - _off\n",
    "        if start_from < 0:\n",
    "            start_from = 0\n",
    "        if start_from >=len(emb):\n",
    "            start_from = len(emb)-1\n",
    "\n",
    "        sm[start_from: start_from+max_len]+=1\n",
    "\n",
    "    plot_embedding(sm, title=f'Semantic map {SAMPLE_DOC_ID}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ed6ec2",
   "metadata": {
    "colab_type": "text",
    "id": "niaa4g6g2Q7g",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Batch generator & TODOs üôè\n",
    "\n",
    "\n",
    "- [X] TODO: add outliers to the trainset ?\n",
    "- [ ] TODO: try sparse_categorical_entropy instead of one-hot encodings\n",
    "- [ ] TODO: model 5.2, 5.1: bipolar concat layer is wrong because we concatenate thongs of different magnitudes. Add a Sigmoid activation layer\n",
    "- [ ] TODO: chechk what is better: to pad with zeros or to pad with means\n",
    "- [X] TODO: add weights to samples\n",
    "- [ ] TODO: sum semantic map alongside vertical axis, and mutiply it (as a mask) by the subject detection seq\n",
    "- [ ] TODO: introduce individual per tag threshosholds, also, the current 0.3 threshold is strange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2a3ef2",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1CFzuOP4w9mB",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "MAX_LEN = 1536\n",
    "def make_generator(self, indices: [int], batch_size: int, augment_samples=False):\n",
    "  #   np.random.seed(43)\n",
    "\n",
    "  while True:\n",
    "    # next batch\n",
    "    batch_indices = np.random.choice(a=indices, size=batch_size)\n",
    "\n",
    "    max_len = MAX_LEN\n",
    "    start_from = 0\n",
    "\n",
    "    if augment_samples:\n",
    "      max_len = random.randint(300, MAX_LEN)\n",
    "\n",
    "    batch_input_emb = []\n",
    "    batch_input_token_f = []\n",
    "    batch_output_sm = []\n",
    "    batch_output_subj = []\n",
    "\n",
    "    weights = []\n",
    "    weights_subj = []\n",
    "\n",
    "    # Read in each input, perform preprocessing and get labels\n",
    "    for doc_id in batch_indices:\n",
    "\n",
    "      dp = make_xyw(doc_id, stats)\n",
    "      (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = dp\n",
    "\n",
    "      #       print(dp)\n",
    "\n",
    "      subject_weight_K = 1.0\n",
    "      if augment_samples:\n",
    "        start_from = 0\n",
    "\n",
    "        # row = stats_valid.loc[doc_id]\n",
    "        if random.random() < 0.6:  # 60% of samples\n",
    "          nonzerozz = np.where(sm[:, 1::2] > 0)[0] #take every second row, because these are end marks\n",
    "#           nonzerozz = nonzerozz\n",
    "          \n",
    "          segment_center = random.choice(nonzerozz)\n",
    "          if len(nonzerozz)==0:\n",
    "             segment_center=0\n",
    "\n",
    "\n",
    "          # segment_center = random.randint(0, len(emb) - 1)  ##select random token as a center\n",
    "\n",
    "          # if not pd.isna(row['value_span']) and random.random() < 0.7:  ##select value token as a center\n",
    "          #   segment_center = int(row['value_span'])\n",
    "\n",
    "          # _off = random.randint(max_len // 4, max_len // 2)\n",
    "          _off = random.randint(-max_len//10, max_len//2)\n",
    "          start_from = segment_center - _off\n",
    "          if start_from < 0:\n",
    "            start_from = 0\n",
    "          if start_from >=len(emb):\n",
    "            start_from = len(emb)-1\n",
    "#           print('start_from', start_from)\n",
    "#           if random_row != 1:#subject row, see semantic_map_keys\n",
    "#               subject_weight_K = 0.1  # lower subject weight because there migh–µ be no information about subject around doc. value\n",
    "\n",
    "      # dp = self.trim_maxlen(dp, start_from, max_len)\n",
    "      dp = UberModelTrainsetManager.trim_maxlen(dp, start_from, max_len)\n",
    "\n",
    "      # TODO: find samples maxlen\n",
    "\n",
    "      (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = dp\n",
    "      #       print((sample_weight, subject_weight))\n",
    "      subject_weight *= subject_weight_K\n",
    "\n",
    "      batch_input_emb.append(emb)\n",
    "      batch_input_token_f.append(tok_f)\n",
    "\n",
    "      batch_output_sm.append(sm)\n",
    "      batch_output_subj.append(subj)\n",
    "\n",
    "      if np.isnan(sample_weight):\n",
    "        raise ValueError()\n",
    "\n",
    "      if np.isnan(subject_weight):\n",
    "        raise ValueError()\n",
    "\n",
    "      weights.append(sample_weight)\n",
    "      weights_subj.append(subject_weight)\n",
    "      # end if emb\n",
    "    # end for loop\n",
    "\n",
    "    # Returns a tuple of (input, output, weights) to feed the network\n",
    "    #     print('batch_output_subj', len(batch_output_subj))\n",
    "    #     print('batch_output_sm', len(batch_output_subj))\n",
    "\n",
    "    yield ([np.array(batch_input_emb), np.array(batch_input_token_f)],\n",
    "           [np.array(batch_output_sm), np.array(batch_output_subj)],\n",
    "           [np.array(weights), np.array(weights_subj)])\n",
    "    \n",
    "\n",
    "    \n",
    "_train, _test = train_test_split(stats_valid, test_size=TEST_SIZE, stratify=stats_valid[['subject']], random_state=TRAIN_TEST_SPLIT_SEED)\n",
    "\n",
    "train_indices = list(_train.index)\n",
    "test_indices = list(_test.index)\n",
    "\n",
    "    \n",
    "####---test\n",
    "_gen = make_generator(umtm, train_indices, batch_size=10, augment_samples=True)\n",
    "\n",
    "sample = next(_gen)\n",
    "# print(len(sample))\n",
    "del _gen\n",
    " \n",
    "(emb, tok_f), (sm, subj), (sample_weight, subject_weight) = sample\n",
    "    \n",
    "print('semantic map shape is:', sm.shape)\n",
    "_crop = 1500\n",
    "_ = plot_embedding(tok_f[0][:_crop], title=f'Tokens features') \n",
    "# plot_embedding(emb[:_crop],   title=f'Embedding {SAMPLE_DOC_ID}') \n",
    "_ = plot_embedding(pd.DataFrame( sm[0], columns= semantic_map_keys_contract) [:_crop],    title=f'Semantic map', height=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5342db82",
   "metadata": {},
   "source": [
    "## [debug] Diagnose SM Rows in TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3865769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_embedding(pd.DataFrame( sm[0], columns= semantic_map_keys_contract) [:_crop],    title=f'Semantic map', height=8)\n",
    "if DEBUG:\n",
    "    _crop = 350\n",
    "    batch_size=100\n",
    "    mtx = np.zeros((batch_size, _crop))\n",
    "\n",
    "\n",
    "    _gen = make_generator(umtm, train_indices, batch_size=batch_size, augment_samples=True) \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    for i in range(0, batch_size):\n",
    "\n",
    "        sample = next(_gen)\n",
    "        (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = sample\n",
    "\n",
    "\n",
    "        sub = sm[0][:,4:6][:_crop] #pd.DataFrame( sm[0], columns= semantic_map_keys_contract) [:_crop][['date-begin']]\n",
    "\n",
    "    #     print(sub[:,0].max())\n",
    "        mtx [i][0:len(sub[:,0])] = sub[:,0]\n",
    "\n",
    "    fig = plot_embedding(mtx.T,    title=f'Semantic map, combined Date rows of {batch_size} samples', height=5)\n",
    "    mlflow.log_figure(fig, 'Diagnose SM Rows in TS.png')\n",
    "    del _gen\n",
    "    del mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "mlflow.log_param('training set', len(train_indices) )\n",
    "mlflow.log_param('evaluation set', len(test_indices) )\n",
    "\n",
    "_s = f\"#### {len(train_indices)} -- total  docs training set\"\n",
    "display(Markdown(_s))\n",
    "_s = f\"#### {len(test_indices)} -- total  docs validation set\"\n",
    "display(Markdown(_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c5ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    dp = make_xyw(stats.index[0], stats_valid)\n",
    "\n",
    "    (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = dp\n",
    "\n",
    "    fig = plot_embedding(sm[:500],    title=f'Semantic map ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a3f015",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "zrKMJ2bsn6yx",
    "outputId": "f39d06b8-8af2-4570-fa72-481633dfe61c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('train_indices[0]:', train_indices[0])\n",
    "print('test_indices[0]:', test_indices[0])\n",
    "\n",
    "\n",
    "def plot_subject_distr(df:DataFrame, title):  \n",
    "    target='subject'\n",
    "    fig = plt.figure(figsize=(16,4))   \n",
    "    sns.set(style=\"whitegrid\")\n",
    "    chart = sns.countplot(data=df.sort_values(target), y=target)\n",
    "    t = f'{title}: Frequency Distribution of subjects; {len(df)} total'\n",
    "    plt.title(t) \n",
    "\n",
    "    _fn = reports_dir / f'Distribution of subjects -{title}.png'\n",
    "    plt.savefig(_fn , bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()\n",
    "\n",
    "    mlflow.log_artifact(_fn)\n",
    "\n",
    "\n",
    " \n",
    "plot_subject_distr(stats_valid, 'ALL')\n",
    "plot_subject_distr(stats_valid[stats_valid.index.isin(train_indices)], 'training')\n",
    "plot_subject_distr(stats_valid[stats_valid.index.isin(test_indices)], 'eval')\n",
    "\n",
    "\n",
    "\n",
    "if DEBUG:   \n",
    "  # test_gen = make_generator(umtm, test_indices, BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, train_indices, BATCH_SIZE, augment_samples=True)\n",
    "  \n",
    "  x, y, w = next(train_gen)\n",
    "  \n",
    "#   print('X:', len(x), 'X[0]=', x[0].shape, 'X[1]=', x[1].shape)\n",
    "#   print('Y:', len(y), 'Y[0]=', y[0].shape, 'Y[1]=', y[1].shape)\n",
    "  \n",
    "\n",
    "#   plot_embedding(x[0][0], 'X2: Token Embeddings')\n",
    "#   plot_embedding(x[1][0], 'X1: Token Features')\n",
    "#   plot_embedding(y[0][0], 'Y: Semantic Map')\n",
    "  \n",
    "#   print(y[0][1])\n",
    "\n",
    "#   del x\n",
    "#   del w\n",
    "#   del y\n",
    "#   del train_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b776a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "RIRaSgxCP3Jt",
    "outputId": "4f253294-c07c-481f-ca0f-5cbea0d31d97",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "ctx = KerasTrainingContext(checkpoints_path=umtm.reports_dir, session_index=1)\n",
    "\n",
    "ctx.set_batch_size_and_trainset_size(BATCH_SIZE, \n",
    "                                     len(test_indices), \n",
    "                                     4 * len(train_indices))\n",
    "\n",
    "DEFAULT_TRAIN_CTX = ctx\n",
    "CLASSES = 43\n",
    "FEATURES = 14\n",
    "\n",
    "metrics = [  'mse', 'binary_crossentropy']\n",
    "# metrics = ['kullback_leibler_divergence', 'mse', 'binary_crossentropy']\n",
    "\n",
    "\n",
    "def train(umodel):\n",
    "  test_gen = make_generator(umtm, test_indices, BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, train_indices, BATCH_SIZE, augment_samples=True) \n",
    "  ctx.train_and_evaluate_model(umodel, generator=train_gen, test_generator=test_gen)\n",
    "\n",
    "def overtrain(umodel):\n",
    "  test_gen = make_generator(umtm, list(train_indices) + list(test_indices), BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, list(train_indices) + list(test_indices), BATCH_SIZE, augment_samples=True) \n",
    "  ctx.train_and_evaluate_model(umodel, generator=train_gen, test_generator=test_gen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17dbb8",
   "metadata": {
    "colab_type": "text",
    "id": "gAFmo0sG4H9k",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Models ü¶ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedecdc5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import analyser\n",
    "def get_weights_filename(model_factory_fn):\n",
    "    weights = ctx.model_checkpoint_path / f'{model_factory_fn.__name__}.h5'\n",
    "    print(weights.is_file(), weights)\n",
    "    if not weights.is_file():\n",
    "        weights = Path(analyser.hyperparams.models_path) / f'{model_factory_fn.__name__}.h5'\n",
    "        print(weights.is_file(), weights)\n",
    "    \n",
    "    return weights\n",
    "\n",
    "# get_weights_filename(uber_detection_model_005_1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0e0d09",
   "metadata": {},
   "source": [
    "## ü•∞ Att model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44020ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_factory_fn = make_att_model      \n",
    "# TRAIN_FROM_CP = True\n",
    "if TRAIN_FROM_CP:\n",
    "    weights = get_weights_filename(model_factory_fn)\n",
    "else:\n",
    "    # weights = Path(analyser.hyperparams.models_path) / f'{model_factory_fn.__name__}.h5'\n",
    "    #TODO: fix this mess with TRAIN_FROM_CP and CHECKPOINT_URL flags\n",
    "    weights = None\n",
    "    # \n",
    "    \n",
    "# weights = Path(analyser.hyperparams.models_path) / f'{model_factory_fn.__name__}.h5'\n",
    "\n",
    "\n",
    "# TRAIN_FROM_CP=True        \n",
    "if not TEST_FLOW:\n",
    "    \n",
    "    umodel = make_att_model() \n",
    "    \n",
    "    print(f'{umodel.name=}')    \n",
    "\n",
    "    if CHECKPOINT_URL is not None:\n",
    "        logger.info(f'LOADING {CHECKPOINT_URL}')\n",
    "        umodel = mlflow.tensorflow.load_model(CHECKPOINT_URL)\n",
    "        # TODO:TEST IT, FIX IT\n",
    "    else:\n",
    "        if TRAIN_FROM_CP:\n",
    "            logger.info(f'LOADING {weights}')\n",
    "            print(f'LOADING {weights=}')\n",
    "            umodel.load_weights(weights, by_name=True, skip_mismatch=True)\n",
    "        else:\n",
    "            logger.warning(f'skip loading weights, because {TRAIN_FROM_CP=}')\n",
    "\n",
    "    # if DEBUG:    \n",
    "    umodel.summary()\n",
    "\n",
    "# raise \"forsibly stopped\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_img_file = f'{umodel.name}.png'\n",
    "# keras.utils.plot_model(umodel, to_file=dot_img_file, show_shapes=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43116bee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(self, model:Model, generator, test_generator, retrain=False, lr=None):\n",
    "    print(f'model.name == {model.name}')\n",
    "    self.trained_models[model.name] = model.name\n",
    "    if self.EVALUATE_ONLY:\n",
    "      print(f'training skipped EVALUATE_ONLY = {self.EVALUATE_ONLY}')\n",
    "      return\n",
    "\n",
    "    _log_fn = f'{model.name}.{self.session_index}.log.csv'\n",
    "    _logger1 = CSVLogger(self.model_checkpoint_path / _log_fn, separator=',', append=not retrain)\n",
    "    _logger2 = CSVLogger(_log_fn, separator=',', append=not retrain)\n",
    "\n",
    "    checkpoint_weights = ModelCheckpoint(self.model_checkpoint_path / (model.name + \".h5\"),\n",
    "                                         monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True,\n",
    "                                         verbose=1)\n",
    "\n",
    "    lr_logged = None\n",
    "    if not retrain:\n",
    "      lr_logged, epoch = self.get_lr_epoch_from_log(model.name)\n",
    "    else:\n",
    "      epoch = 0\n",
    "\n",
    "    if lr_logged is not None:\n",
    "      K.set_value(model.optimizer.lr, lr_logged)\n",
    "\n",
    "    if lr is not None:\n",
    "      K.set_value(model.optimizer.lr, lr)\n",
    "\n",
    "    print(f'continue: lr:{K.get_value(model.optimizer.lr)}, epoch:{epoch}')\n",
    "\n",
    "\n",
    "    history = model.fit(\n",
    "                    generator, batch_size=BATCH_SIZE,\n",
    "#                     steps_per_epoch=train_steps,\n",
    "                    epochs=self.EPOCHS,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=self.validation_steps,\n",
    "                    steps_per_epoch=self.steps_per_epoch,\n",
    "#                     class_weight=class_weights,\n",
    "                    initial_epoch=epoch, \n",
    "#                     workers=8,\n",
    "                    callbacks=[self.reduce_lr, checkpoint_weights, _logger2, _logger1]\n",
    "                    )\n",
    "    \n",
    "    \n",
    "\n",
    "    self.HISTORIES[model.name] = history\n",
    "    self.save_stats(model.name)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "if not TEST_FLOW:\n",
    "\n",
    "    if TRAIN:\n",
    "      config.LR = LR\n",
    "      ctx.unfreezeModel(umodel)\n",
    "    #   umodel.summary()\n",
    "\n",
    "      ctx.EPOCHS = EPOCHS\n",
    "      ctx.EVALUATE_ONLY = False\n",
    "\n",
    "      BATCH_SIZE = 96\n",
    "      test_gen = make_generator(umtm, train_indices + test_indices, BATCH_SIZE)\n",
    "      train_gen = make_generator(umtm, train_indices + test_indices, BATCH_SIZE, augment_samples=True) \n",
    "\n",
    "      train_and_evaluate_model(ctx, umodel, train_gen, test_generator=test_gen, retrain=True, lr=config.LR)\n",
    "    else:\n",
    "      logger.warning(f'skip training, because TRAIN={TRAIN}')\n",
    "\n",
    "\n",
    "    threshold = umodel.get_layer('O1_tagging').get_weights()\n",
    "    if threshold:\n",
    "        print('threshold=', threshold[0][0])\n",
    "\n",
    "        mlflow.log_metric('trained_tags_threshold', threshold[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c83915-7ac9-493b-80bd-d77f25830fe9",
   "metadata": {},
   "source": [
    "## Register model in MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace3c0dc-70a5-4c15-a8fc-246902a1a15c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlflow.log_artifact(ctx.model_checkpoint_path / f'{model_factory_fn.__name__}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd58c6b",
   "metadata": {
    "colab_type": "text",
    "id": "JUum89Tdhg-9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f12e828",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NJ9uhDBaJlO",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not TEST_FLOW:\n",
    "    if umodel:\n",
    "        del umodel\n",
    "\n",
    "    #######################################\n",
    "    #######################################\n",
    "    model_fn = make_att_model\n",
    "    # model_fn = uber_detection_model_003\n",
    "    #######################################\n",
    "    #######################################\n",
    "\n",
    "\n",
    "    weights = ctx.model_checkpoint_path /  f'{model_factory_fn.__name__}.h5'\n",
    "    logger.info(f'LOADING {weights}')\n",
    "    print(f'LOADING {weights}')\n",
    "\n",
    "    umodel = make_att_model() \n",
    "    umodel.load_weights(weights, by_name=False, skip_mismatch=False)\n",
    "    umodel.trainable = False\n",
    "    umodel.summary()\n",
    "\n",
    "    # umodel = ctx.init_model(model_fn, trained=True, trainable=False, weights=ctx.model_checkpoint_path / f'{model_fn.__name__}.h5')\n",
    "\n",
    "\n",
    "\n",
    "    #TODO: remove next 2 lines\n",
    "    ctx.trained_models[umodel.name] = umodel.name\n",
    "    models = ctx.trained_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec371e0",
   "metadata": {
    "colab_type": "text",
    "id": "NLRR4qmKImgQ",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8fda3e",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "me1LdIP5Ik9z",
    "outputId": "1bf81b8f-1f09-4760-a0f3-868a523652d9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_compare_models(\n",
    "    models: [str],\n",
    "    metrics, \n",
    "    title=\"metric/epoch\",\n",
    "    image_save_path = umtm.reports_dir):\n",
    "    \n",
    "  _metrics = [m for m in metrics if not m.startswith('val_')]\n",
    "\n",
    "  for i, m in enumerate(models):\n",
    "\n",
    "    data: pd.DataFrame = ctx.get_log(m)\n",
    "\n",
    "    if data is not None:\n",
    "      data.set_index('epoch')\n",
    "\n",
    "      for metric in _metrics:\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        plt.grid(True)\n",
    "        plt.title(f'{metric} [{m}]')\n",
    "        for metric_variant in ['', 'val_']:\n",
    "          key = metric_variant + metric\n",
    "          if key in data:\n",
    "\n",
    "            x = data['epoch'][-100:]\n",
    "            y = data[key][-100:]\n",
    "\n",
    "\n",
    "            c = 'red'  # plt.cm.jet_r(i * colorstep)\n",
    "            if metric_variant == '':\n",
    "              c = 'blue'\n",
    "            plt.plot(x, y, label=f'{key}', alpha=0.2, color=c)\n",
    "\n",
    "            y = y.rolling(4, win_type='gaussian').mean(std=4)\n",
    "            plt.plot(x, y, label=f'{key} SMOOTH', color=c)\n",
    "\n",
    "            plt.legend(loc='upper right')\n",
    "\n",
    "        \n",
    "        plt.title(f'{[m]} {title}')\n",
    "        plt.grid(True)\n",
    "        img_path = os.path.join(image_save_path, f'{m}-{metric}.png')\n",
    "        \n",
    "        plt.savefig(img_path, bbox_inches='tight')        \n",
    "        plt.show()\n",
    "    else:\n",
    "      logger.error('cannot plot')\n",
    "    \n",
    "if not TEST_FLOW:\n",
    "    models = list(ctx.trained_models.keys())\n",
    "\n",
    "\n",
    "    plot_compare_models(models, ['loss'], 'Loss')\n",
    "\n",
    "    # plot_compare_models(models, ['O1_tagging_kullback_leibler_divergence'], 'TAGS: Kullback Leibler divergence')\n",
    "    # plot_compare_models(models, ['O1_tagging_mse'], 'TAGS: MSE')\n",
    "    # plot_compare_models(models, ['O2_subject_kullback_leibler_divergence'], 'Subj: Kullback Leibler divergence')\n",
    "    # plot_compare_models(models, ['O2_subject_mse'],  'Subjects: MSE')\n",
    "\n",
    "    plot_compare_models(models, ['O1_tagging_loss', 'O2_subject_loss'], 'Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041d7c73",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tf_support.super_contract_model import make_xyw\n",
    "logger.error(\"fix prediction!!\")\n",
    "if False:\n",
    "    sample_index = umtm.stats [umtm.stats['value']>0].index[2]\n",
    "    logger.info(f'making prediction for sample doc {sample_index}')\n",
    "\n",
    "    x, y, _ = make_xyw(sample_index, umtm.stats)\n",
    "    print(f'shape of x[0]={x[0].shape}')\n",
    "    print(f'shape of x[1]={x[1].shape}')\n",
    "\n",
    "    t1 = np.expand_dims(x[0], axis=0)\n",
    "    t2 = np.expand_dims(x[1], axis=0)\n",
    "\n",
    "    print(f'shape of t1={t1.shape}')\n",
    "    print(f'shape of t2={t2.shape}')\n",
    "    print(f'umodel.name ={umodel.name}')\n",
    "\n",
    "    prediction = umodel.predict(x=[t1, t2], batch_size=1)\n",
    "\n",
    "    tagsmap = pd.DataFrame(prediction[0][0], columns=semantic_map_keys_contract)\n",
    "    # .T\n",
    "    plot_embedding(tagsmap[:500], f'Predicted Semantic Map {tagsmap.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fd349d",
   "metadata": {},
   "source": [
    "# Evaluate recent model (with external notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b30f54",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not TEST_FLOW:\n",
    "    %run -i -t {notebooks_dir}/eval_contract_uber_model.ipynb\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41099a96",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('see results at')\n",
    "print(f'{mlflow.get_registry_uri()}/#/experiments/{mlflow.last_active_run().info.experiment_id}/runs/{mlflow.last_active_run().info.run_id}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9eF-UGHyh-C9",
    "7X_zYCYEdlPM",
    "lyI4hbTRFjyM"
   ],
   "name": "Local: structure keras uber model - clean train, evaluate, test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.612159,
   "end_time": "2023-01-26T10:09:40.188121",
   "environment_variables": {},
   "exception": null,
   "input_path": "trainsets/retrain_contract_uber_model.ipynb",
   "output_path": "trainsets/retrain_contract_uber_model.ipynb",
   "parameters": {},
   "start_time": "2023-01-26T10:09:20.575962",
   "version": "2.4.0"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
