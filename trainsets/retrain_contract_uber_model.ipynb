{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JoHJkn9yQIgg"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('retrain_ipynb')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(levelname)s - %(asctime)s - %(name)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.debug('--=logging started=--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Dehw0fnKfSBF",
    "outputId": "3bcb61cd-401a-43d7-dccf-9a6022b2a576"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "TRAIN = True\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print ('Running in colab:', IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZiBqnGnQfKWF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not IN_COLAB:\n",
    "  nb_dir = os.path.split(os.getcwd())[0]\n",
    "  if nb_dir not in sys.path:\n",
    "      sys.path.append(nb_dir)\n",
    "else:\n",
    "  %tensorflow_version 1.x\n",
    "  import tensorflow as tf\n",
    "  print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5cLtueagMru"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  !pip install --upgrade pip\n",
    "  !pip --version\n",
    "  !pip install --no-deps --upgrade git+https://www.github.com/nemoware/analyser.git@uber-models\n",
    "  !pip install -q pyjarowinkler overrides\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jT7451NXspdw"
   },
   "outputs": [],
   "source": [
    "\n",
    "if not IN_COLAB:\n",
    "  import analyser.hyperparams  \n",
    "  _work_dir_default = os.path.realpath(os.path.join(  analyser.hyperparams.__file__, '..', '..', '..', 'work'))\n",
    "  work_dir = os.environ.get('GPN_WORK_DIR', _work_dir_default)\n",
    "  \n",
    "  if not os.path.isdir(work_dir):\n",
    "    os.mkdir(work_dir)\n",
    "\n",
    "  analyser.hyperparams.work_dir = work_dir\n",
    "else:\n",
    "  import analyser.hyperparams\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  os.environ['GPN_WORK_DIR']='/content/drive/My Drive/GazpromOil/trainsets/uber_2'\n",
    "  analyser.hyperparams.work_dir = os.environ['GPN_WORK_DIR']\n",
    "\n",
    "print('work_dir=', analyser.hyperparams.work_dir)\n",
    "assert os.path.isdir(analyser.hyperparams.work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbsxFAqC6pjQ"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "pexvDJbAtZM0",
    "outputId": "4f7e6e34-d675-423d-d102-1020d49d854f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    " \n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "from os import path\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "from colab_support.renderer import *\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bson import json_util\n",
    "\n",
    "from analyser.legal_docs import LegalDocument, make_headline_attention_vector\n",
    "from analyser.headers_detector import make_predicted_headline_attention_vector, get_tokens_features\n",
    "from analyser.hyperparams import models_path\n",
    "from analyser.text_tools import find_top_spans\n",
    "from analyser.persistence import DbJsonDoc\n",
    "\n",
    "from trainsets.trainset_tools import TrainsetBalancer, SubjectTrainsetManager\n",
    "from trainsets.retrain_contract_uber_model import UberModelTrainsetManager\n",
    "\n",
    "from tf_support import super_contract_model\n",
    "from tf_support.super_contract_model import get_base_model, semantic_map_keys_contract\n",
    "from tf_support.super_contract_model import uber_detection_model_005_1_1\n",
    "from tf_support.tf_subject_model import decode_subj_prediction\n",
    "from tf_support.tools import KerasTrainingContext\n",
    "# from tf_support.embedder_elmo import ElmoEmbedder\n",
    "\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Conv1D, LSTM, GRU, BatchNormalization, TimeDistributed, Dense, Bidirectional, Input, Dropout, Lambda\n",
    "from keras.layers import concatenate, SpatialDropout1D, ActivityRegularization\n",
    "from keras.layers import MaxPooling1D, Activation, ThresholdedReLU, GaussianNoise\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "# from keras.utils import plot_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRQOy7o0uyTv"
   },
   "source": [
    "# Prepare trainset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "  from integration.db import get_mongodb_connection\n",
    "  from bson.objectid import ObjectId\n",
    "\n",
    "  def get_doc(objid):\n",
    "    db = get_mongodb_connection()\n",
    "    documents_collection = db['documents']\n",
    "    jdata = documents_collection.find_one({'_id': ObjectId(objid)})\n",
    "    return DbJsonDoc(jdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    jdoc = get_doc('5edbc59bda3678279fbcac77')\n",
    "    doc = jdoc.asLegalDoc()\n",
    "    doc.tokens\n",
    "    \n",
    "from pathlib import Path\n",
    "work_dir = Path(analyser.hyperparams.work_dir)\n",
    "print(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "umtm = UberModelTrainsetManager (work_dir)\n",
    "\n",
    "umtm.load_contract_trainset_meta()\n",
    "stats = umtm.stats\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not IN_COLAB:\n",
    "#     umtm.import_recent_contracts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights: вычисление весов samples  \n",
    "\n",
    "чтобы всех запутать, \n",
    " - вес пропорционален логорифму цены контракта (чтобы было меньше ошибок в контрактах на большие суммы)\n",
    " - more weight for user-corrected datapoints\n",
    " - normalize weights, so the sum == Number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainsets.trainset_tools import get_feature_log_weights\n",
    "\n",
    "stats = umtm.stats\n",
    "subject_weights = get_feature_log_weights(stats, 'subject')\n",
    "subject_weights*=subject_weights\n",
    "\n",
    "for i, row in stats.iterrows():\n",
    "  subj_name = row['subject']\n",
    "\n",
    "  sample_weight = 0.5 \n",
    "  if not pd.isna(row['user_correction_date']):  # more weight for user-corrected datapoints\n",
    "    sample_weight = 5.0   # TODO: must be estimated anyhow smartly\n",
    "\n",
    "  value_weight = 1.0\n",
    "  if not pd.isna(row['value_log1p']):\n",
    "    # чтобы всех запутать, вес пропорционален логорифму цены контракта\n",
    "    # (чтобы было меньше ошибок в контрактах на большие суммы)\n",
    "    value_weight = 1.0 + row['value_log1p']\n",
    "\n",
    "  sample_weight *=  value_weight \n",
    "  subject_weight =  subject_weights[subj_name] \n",
    "  stats.at[i, 'subject_weight'] = subject_weight + random.random()\n",
    "  stats.at[i, 'sample_weight'] = sample_weight + random.random()\n",
    "\n",
    "# normalize weights, so the sum == Number of samples\n",
    "stats.sample_weight /= stats.sample_weight.mean()\n",
    "stats.subject_weight /= stats.subject_weight.mean()\n",
    "\n",
    "print(stats.sample_weight.mean())\n",
    "print(stats.subject_weight.mean())\n",
    "print(stats.sample_weight.min())\n",
    "print(stats.subject_weight.min())\n",
    "print(stats.sample_weight.max())\n",
    "print(stats.subject_weight.max())\n",
    "\n",
    "stats.to_csv( work_dir / 'contract_trainset_meta.csv', index=True)\n",
    "\n",
    "subject_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_support.super_contract_model import make_xyw\n",
    "\n",
    "# from functools import lru_cache\n",
    "\n",
    "# def _dp_fn(doc_id, suffix):\n",
    "#     return os.path.join(work_dir, 'datasets', f'{doc_id}-datapoint-{suffix}.npy')\n",
    "\n",
    "\n",
    "\n",
    "# @lru_cache(maxsize=72)\n",
    "# def make_xyw(doc_id):\n",
    "\n",
    "#     row = stats.loc[doc_id]\n",
    "\n",
    "#     _subj = row['subject']\n",
    "#     subject_one_hot = ContractSubject.encode_1_hot()[_subj]\n",
    "\n",
    "#     embeddings =     np.load(_dp_fn(doc_id, 'embeddings'))\n",
    "#     token_features = np.load(_dp_fn(doc_id, 'token_features'))\n",
    "#     semantic_map =   np.load(_dp_fn(doc_id, 'semantic_map'))\n",
    "\n",
    "#     if embeddings.shape[0] != token_features.shape[0]:\n",
    "#       msg = f'{doc_id} embeddings.shape {embeddings.shape} is incompatible with token_features.shape {token_features.shape}'\n",
    "#       raise AssertionError(msg)\n",
    "\n",
    "#     if embeddings.shape[0] != semantic_map.shape[0]:\n",
    "#       msg = f'{doc_id} embeddings.shape {embeddings.shape} is incompatible with semantic_map.shape {semantic_map.shape}'\n",
    "#       raise AssertionError(msg)\n",
    "\n",
    "#     stats.at[doc_id, 'error'] = None\n",
    "    \n",
    "#     return (\n",
    "#       (embeddings, token_features),\n",
    "#       (semantic_map, subject_one_hot),\n",
    "#       (row['sample_weight'], row['subject_weight']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "colab_type": "code",
    "id": "8pe_gZIK3JFh",
    "outputId": "7b923b06-f592-4b11-bb35-d215566e017d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "from tf_support.super_contract_model import  validate_datapoint\n",
    "\n",
    "stats['valid'] = True\n",
    "stats['error'] = ''\n",
    "\n",
    "for i in stats.index:\n",
    "  \n",
    "  try:\n",
    "    validate_datapoint(str(i), stats)\n",
    "\n",
    "  except Exception as e:\n",
    "    logger.error(e)\n",
    "\n",
    "    stats.at[i, 'valid'] = False\n",
    "    stats.at[i, 'error'] = str(e)\n",
    "    \n",
    "stats\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "umtm.stats = umtm.stats[  pd.isna(umtm.stats.value_span) + (umtm.stats.value_span < 10000) ] #remove big docs from TS\n",
    "stats_valid = stats[stats['valid']]\n",
    "del stats\n",
    "print(len(stats_valid))\n",
    "umtm.stats = stats = stats_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stats_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.sample_weight.mean())\n",
    "print(stats.subject_weight.mean())\n",
    "\n",
    "stats.sample_weight /= stats.sample_weight.mean()\n",
    "stats.subject_weight /= stats.subject_weight.mean()\n",
    "\n",
    "\n",
    "print(stats.subject_weight.mean())\n",
    "print(stats.subject_weight.min())\n",
    "\n",
    "print('\\n\\nsample_weight')\n",
    "print('MIN\\t', stats.sample_weight.min())\n",
    "print('MEAN\\t', stats.sample_weight.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "id": "ouUjO_T7xf8A",
    "outputId": "17f85a9a-b0c1-4395-886f-af66e6e5fb12"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "subj_count = stats_valid['subject'].value_counts()\n",
    "\n",
    "#plot distribution---------------------\n",
    "sns.barplot(subj_count.values, subj_count.index)\n",
    "plt.title('Frequency Distribution of subjects')\n",
    "plt.xlabel('Number of Occurrences')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print ('\\nmin', min (subj_count.values))\n",
    "print ('max', max (subj_count.values))\n",
    "print ('total', sum (subj_count.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "colab_type": "code",
    "id": "Ld_KZaHwqf_G",
    "outputId": "c974398a-62a1-44e8-b73c-6589766b05c7"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from trainsets.trainset_tools import get_feature_log_weights\n",
    "\n",
    "_classes = stats_valid['subject'].unique().tolist()\n",
    "\n",
    "print(f'classes: {_classes}')\n",
    "\n",
    "# class_weights = class_weight.compute_class_weight('balanced', _classes, umtm.stats['subject'])\n",
    "# class_weights = dict(zip(_classes, class_weights))\n",
    "\n",
    "\n",
    "class_weights = get_feature_log_weights(stats_valid, 'subject')\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "colab_type": "code",
    "id": "Cs6cZtPy6Je1",
    "outputId": "f0a39fff-f3c5-4418-b087-0eef915b7a81"
   },
   "outputs": [],
   "source": [
    "from trainsets.trainset_tools import get_feature_log_weights\n",
    " \n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "\n",
    "stats_valid['subject_weight'].hist(bins=40, alpha=0.5)\n",
    "stats_valid['sample_weight'].hist(bins=40, alpha=0.5)\n",
    "\n",
    "plt.xscale('linear') # log?\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "id": "_DjNv8UQ956S",
    "outputId": "6ded6bae-e1f0-4a77-9024-64da80c6e47f"
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"subject_weight\", y=\"sample_weight\", data=stats_valid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxEdSGOuq62R"
   },
   "source": [
    "# look into trainset (take a sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CRb_AJUliUft",
    "outputId": "0369b8f3-7423-45f3-a0ed-3459408ccec0"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# umtm.calculate_samples_weights()\n",
    "SAMPLE_DOC_ID = stats_valid.index[1]\n",
    "\n",
    "print('SAMPLE_DOC_ID', SAMPLE_DOC_ID)\n",
    "(emb, tok_f), (sm, subj), (sample_weight, subject_weight) = make_xyw(SAMPLE_DOC_ID, stats)\n",
    " \n",
    "    \n",
    "print('semantic map shape is:', sm.shape)\n",
    "_crop = 500\n",
    "plot_embedding(tok_f[:_crop], title=f'Tokens features {SAMPLE_DOC_ID}') \n",
    "plot_embedding(emb[:_crop], title=f'Embedding {SAMPLE_DOC_ID}') \n",
    "plot_embedding(sm[:_crop], title=f'Semantic map {SAMPLE_DOC_ID}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_kJ0L2RnrHl3",
    "outputId": "4863cd27-1459-458a-951d-b054235ffaea"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "niaa4g6g2Q7g"
   },
   "source": [
    "# Batch generator & TODOs 🙏\n",
    "\n",
    "\n",
    "- [X] TODO: add outliers to the trainset ?\n",
    "- [ ] TODO: try sparse_categorical_entropy instead of one-hot encodings\n",
    "- [ ] TODO: model 5.2, 5.1: bipolar concat layer is wrong because we concatenate thongs of different magnitudes. Add a Sigmoid activation layer\n",
    "- [ ] TODO: chechk what is better: to pad with zeros or to pad with means\n",
    "- [X] TODO: add weights to samples\n",
    "- [ ] TODO: sum semantic map alongside vertical axis, and mutiply it (as a mask) by the subject detection seq\n",
    "- [ ] TODO: introduce individual per tag threshosholds, also, the current 0.3 threshold is strange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1CFzuOP4w9mB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "def make_generator(self, indices: [int], batch_size: int, augment_samples=False):\n",
    "  np.random.seed(43)\n",
    "\n",
    "  while True:\n",
    "    # next batch\n",
    "    batch_indices = np.random.choice(a=indices, size=batch_size)\n",
    "\n",
    "    max_len = 128 * 12\n",
    "    start_from = 0\n",
    "\n",
    "    if augment_samples:\n",
    "      max_len = random.randint(300, 1400)\n",
    "\n",
    "    batch_input_emb = []\n",
    "    batch_input_token_f = []\n",
    "    batch_output_sm = []\n",
    "    batch_output_subj = []\n",
    "\n",
    "    weights = []\n",
    "    weights_subj = []\n",
    "\n",
    "    # Read in each input, perform preprocessing and get labels\n",
    "    for doc_id in batch_indices:\n",
    "\n",
    "      dp = make_xyw(doc_id, stats)\n",
    "      (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = dp\n",
    "        \n",
    "#       print(dp)\n",
    "    \n",
    "      subject_weight_K = 1.0\n",
    "      if augment_samples:\n",
    "        start_from = 0\n",
    "\n",
    "        row = stats_valid.loc[doc_id]\n",
    "        if random.random() < 0.4:  # 40% of samples\n",
    "          segment_center = random.randint(0, len(emb) - 1)  ##select random token as a center\n",
    "          if not pd.isna(row['value_span']) and random.random() < 0.7:\n",
    "            segment_center = int(row['value_span'])\n",
    "\n",
    "          _off = random.randint(max_len // 4, max_len // 2)\n",
    "          start_from = segment_center - _off\n",
    "          if start_from < 0:\n",
    "            start_from = 0\n",
    "          subject_weight_K = 0.1  # lower subject weight because there mighе be no information about subject around doc. value\n",
    "        \n",
    "      dp = self.trim_maxlen(dp, start_from, max_len)\n",
    "      \n",
    "      # TODO: find samples maxlen\n",
    "\n",
    "      (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = dp\n",
    "#       print((sample_weight, subject_weight))\n",
    "      subject_weight *= subject_weight_K\n",
    "\n",
    "      batch_input_emb.append(emb)\n",
    "      batch_input_token_f.append(tok_f)\n",
    "\n",
    "      batch_output_sm.append(sm)\n",
    "      batch_output_subj.append(subj)\n",
    "\n",
    "      if np.isnan(sample_weight):\n",
    "        raise ValueError()\n",
    "\n",
    "      if np.isnan(subject_weight):\n",
    "        raise ValueError()\n",
    "      \n",
    "      weights.append(sample_weight)\n",
    "      weights_subj.append(subject_weight)\n",
    "      # end if emb\n",
    "    # end for loop\n",
    "\n",
    "    # Returns a tuple of (input, output, weights) to feed the network\n",
    "#     print('batch_output_subj', len(batch_output_subj))\n",
    "#     print('batch_output_sm', len(batch_output_subj))\n",
    "    yield ([np.array(batch_input_emb), np.array(batch_input_token_f)],\n",
    "           [np.array(batch_output_sm), np.array(batch_output_subj)],\n",
    "           [np.array(weights), np.array(weights_subj)])\n",
    "    \n",
    "\n",
    "    \n",
    "_train, _test = train_test_split(stats_valid, test_size=0.22, stratify=stats_valid[['subject']])\n",
    "\n",
    "train_indices = list(_train.index)\n",
    "test_indices = list(_test.index)\n",
    "\n",
    "    \n",
    "####---test\n",
    "_gen = make_generator(umtm, train_indices, 14, augment_samples=True)\n",
    "\n",
    "sample = next(_gen)\n",
    "print(len(sample))\n",
    "del _gen\n",
    " \n",
    "\n",
    "\n",
    "(emb, tok_f), (sm, subj), (sample_weight, subject_weight) = sample\n",
    " \n",
    "    \n",
    "print('semantic map shape is:', sm.shape)\n",
    "_crop = 500\n",
    "plot_embedding(tok_f[0][:_crop], title=f'Tokens features {SAMPLE_DOC_ID}') \n",
    "# plot_embedding(emb[:_crop],   title=f'Embedding {SAMPLE_DOC_ID}') \n",
    "plot_embedding(sm[0][:_crop],    title=f'Semantic map {SAMPLE_DOC_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "zrKMJ2bsn6yx",
    "outputId": "f39d06b8-8af2-4570-fa72-481633dfe61c"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 24\n",
    "EMB =  1024\n",
    " \n",
    "_SELFTEST = True\n",
    "\n",
    "\n",
    "print('train_indices[0]:', train_indices[0])\n",
    "print('test_indices[0]:', test_indices[0])\n",
    "\n",
    "\n",
    "def plot_subject_distr(df, title):  \n",
    "  target='subject'\n",
    "  plt.figure(figsize=(16,4))   \n",
    "  sns.set(style=\"whitegrid\")\n",
    "  chart = sns.countplot(data=df, y=target)\n",
    "  plt.title(f'Frequency Distribution of subjects :{title}')\n",
    "\n",
    " \n",
    "plot_subject_distr(stats_valid, 'ALL')\n",
    "plot_subject_distr(stats_valid[stats_valid.index.isin(train_indices)], 'train')\n",
    "plot_subject_distr(stats_valid[stats_valid.index.isin(test_indices)], 'test')\n",
    "\n",
    "\n",
    "if _SELFTEST:\n",
    "  # test_gen = make_generator(umtm, test_indices, BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, train_indices, BATCH_SIZE, augment_samples=True)\n",
    "  \n",
    "  x, y, w = next(train_gen)\n",
    "  \n",
    "#   print('X:', len(x), 'X[0]=', x[0].shape, 'X[1]=', x[1].shape)\n",
    "#   print('Y:', len(y), 'Y[0]=', y[0].shape, 'Y[1]=', y[1].shape)\n",
    "  \n",
    "\n",
    "#   plot_embedding(x[0][0], 'X2: Token Embeddings')\n",
    "#   plot_embedding(x[1][0], 'X1: Token Features')\n",
    "#   plot_embedding(y[0][0], 'Y: Semantic Map')\n",
    "  \n",
    "#   print(y[0][1])\n",
    "\n",
    "#   del x\n",
    "#   del w\n",
    "#   del y\n",
    "#   del train_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "RIRaSgxCP3Jt",
    "outputId": "4f253294-c07c-481f-ca0f-5cbea0d31d97"
   },
   "outputs": [],
   "source": [
    "\n",
    "ctx = KerasTrainingContext(umtm.work_dir, session_index=21)\n",
    "\n",
    "ctx.set_batch_size_and_trainset_size(BATCH_SIZE, \n",
    "                                     len(test_indices), \n",
    "                                     4 * len(train_indices))\n",
    "\n",
    "DEFAULT_TRAIN_CTX = ctx\n",
    "CLASSES = 43\n",
    "FEATURES = 14\n",
    "\n",
    "metrics = ['kullback_leibler_divergence', 'mse', 'binary_crossentropy']\n",
    "\n",
    "\n",
    "def train(umodel):\n",
    "  test_gen = make_generator(umtm, test_indices, BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, train_indices, BATCH_SIZE, augment_samples=True) \n",
    "  ctx.train_and_evaluate_model(umodel, generator=train_gen, test_generator=test_gen)\n",
    "\n",
    "def overtrain(umodel):\n",
    "  test_gen = make_generator(umtm, list(train_indices) + list(test_indices), BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, list(train_indices) + list(test_indices), BATCH_SIZE, augment_samples=True) \n",
    "  ctx.train_and_evaluate_model(umodel, generator=train_gen, test_generator=test_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6gXvyjKr509e"
   },
   "outputs": [],
   "source": [
    "def init_model(model_fn) -> (Model, KerasTrainingContext):\n",
    "  model_name = model_fn.__name__\n",
    "  model = model_fn(name=model_name, ctx=ctx, trained=True)\n",
    "#   model.name = model_name\n",
    "\n",
    "  keras__version__ = keras.__version__\n",
    "  ch_fn = os.path.join(models_path, f\"{model_name}-{keras__version__}.h5\")\n",
    "  ch_fn_new = os.path.join(umtm.work_dir, f\"{model_name}-{keras__version__}.h5\")\n",
    "\n",
    "  weights_file_old = ch_fn # os.path.join(models_path, model_name + \".weights\")\n",
    "  weights_file_new = ch_fn_new #os.path.join(umtm.work_dir, model_name + \".weights\")\n",
    "\n",
    "  try:\n",
    "    model.load_weights(weights_file_old, by_name=True )\n",
    "    logger.info(f'weights loaded: {weights_file_new}')\n",
    "\n",
    "  except:\n",
    "    msg = f'cannot load  {model_name} from  {weights_file_new}'\n",
    "    warnings.warn(msg)\n",
    "    logger.warning(msg)\n",
    "    model.load_weights(weights_file_old, by_name=True )\n",
    "    logger.info(f'weights loaded: {weights_file_old}')\n",
    "\n",
    "  # freeze bottom 6 layers, including 'embedding_reduced' #TODO: this must be model-specific parameter\n",
    "  for l in model.layers[0:6]:\n",
    "    l.trainable = False\n",
    "\n",
    "  model.compile(loss=super_contract_model.losses, optimizer='Nadam', metrics=super_contract_model.metrics)\n",
    "  model.summary()\n",
    "\n",
    "  return model\n",
    "# from tf_support.tools import KerasTrainingContext\n",
    "\n",
    "\n",
    "# kctx = KerasTrainingContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAFmo0sG4H9k"
   },
   "source": [
    "# Models 🦖"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainf from 0 uber_detection_model_003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_support.super_contract_model import uber_detection_model_003\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_factory_fn = uber_detection_model_003\n",
    "umodel = ctx.init_model(model_factory_fn, trained=True, trainable=True, load_weights=False )\n",
    "\n",
    "umodel.summary()\n",
    "\n",
    "if TRAIN:\n",
    "  test_gen = make_generator(umtm, test_indices, BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, train_indices, BATCH_SIZE, augment_samples=True) \n",
    "\n",
    "  ctx.EPOCHS = 20\n",
    "  ctx.EVALUATE_ONLY = False\n",
    "  ctx.train_and_evaluate_model(umodel, generator=train_gen, test_generator=test_gen, retrain=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue training 003 from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_factory_fn = uber_detection_model_003\n",
    "\n",
    "weights = ctx.model_checkpoint_path / f'{model_factory_fn.__name__}.h5'\n",
    "print(weights.is_file())\n",
    "print(weights)\n",
    "umodel = ctx.init_model(model_factory_fn, trained=True, trainable=True, weights=weights)\n",
    "\n",
    "if TRAIN:\n",
    "  test_gen = make_generator(umtm, test_indices, BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, train_indices, BATCH_SIZE, augment_samples=True) \n",
    "\n",
    "  ctx.EPOCHS = 25\n",
    "  ctx.EVALUATE_ONLY = False\n",
    "  ctx.train_and_evaluate_model(umodel, generator=train_gen, test_generator=test_gen, retrain=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overtrain 003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "  ctx.unfreezeModel(umodel)\n",
    "  umodel.compile(loss=super_contract_model.losses, optimizer='Nadam', metrics=super_contract_model.metrics)\n",
    "  print(super_contract_model.losses)\n",
    "  umodel.summary()\n",
    "  \n",
    "  ctx.EPOCHS = 25\n",
    "  ctx.EVALUATE_ONLY = False\n",
    "  ctx.EPOCHS *= 2\n",
    "\n",
    "  test_gen = make_generator(umtm, train_indices, BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, train_indices + test_indices, BATCH_SIZE, augment_samples=True) \n",
    "  \n",
    "  ctx.train_and_evaluate_model(umodel, train_gen, test_generator=test_gen, retrain=False, lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uber_detection_model_005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_factory_fn = uber_detection_model_005_1_1\n",
    "umodel = ctx.init_model(model_factory_fn, trained=True, trainable=True, load_weights=False )\n",
    "\n",
    "umodel.summary()\n",
    "\n",
    "if TRAIN:\n",
    "  test_gen = make_generator(umtm, test_indices, BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, train_indices, BATCH_SIZE, augment_samples=True) \n",
    "\n",
    "  ctx.EPOCHS = 25\n",
    "  ctx.EVALUATE_ONLY = False\n",
    "  ctx.train_and_evaluate_model(umodel, generator=train_gen, test_generator=test_gen, retrain=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eF7Ktdfo9aa7"
   },
   "source": [
    "### 5.1.1 💕💕 uber_detection_model_005_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "model_factory_fn = uber_detection_model_005_1_1\n",
    "# weights = Path(models_path) / f\"{model_factory_fn.__name__}-{keras.__version__}.h5\"\n",
    "weights = ctx.model_checkpoint_path / f'{model_factory_fn.__name__}.h5'\n",
    "\n",
    "print(weights)\n",
    "print(weights.is_file())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8T-v6SSEs3gX"
   },
   "outputs": [],
   "source": [
    "# umodel = init_model(uber_detection_model_005_1_1 )\n",
    "model_factory_fn = uber_detection_model_005_1_1\n",
    "umodel = ctx.init_model(model_factory_fn, trained=True, trainable=True, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OpgUW39m9abE",
    "outputId": "6febaa3a-bf87-4af6-d415-7db086f454a2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################\n",
    "# Phase I retraining\n",
    "# ❄️ frozen bottom layers\n",
    "######################\n",
    "\n",
    "if TRAIN:\n",
    "  test_gen = make_generator(umtm, test_indices, BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, train_indices, BATCH_SIZE, augment_samples=True) \n",
    "\n",
    "  ctx.EPOCHS = 20\n",
    "  ctx.EVALUATE_ONLY = False\n",
    "  ctx.train_and_evaluate_model(umodel, generator=train_gen, test_generator=test_gen, retrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LJAH6Fjn9abL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################\n",
    "## Phase II finetuning\n",
    "#  all unfrozen, entire trainset, low LR\n",
    "######################\n",
    "if TRAIN:\n",
    "  ctx.unfreezeModel(umodel)\n",
    "  umodel.compile(loss=super_contract_model.losses, optimizer='Nadam', metrics=super_contract_model.metrics)\n",
    "  umodel.summary()\n",
    "  \n",
    "  ctx.EPOCHS = 25\n",
    "  ctx.EVALUATE_ONLY = False\n",
    "  ctx.EPOCHS *= 2\n",
    "\n",
    "  test_gen = make_generator(umtm, train_indices + test_indices, BATCH_SIZE)\n",
    "  train_gen = make_generator(umtm, train_indices + test_indices, BATCH_SIZE, augment_samples=True) \n",
    "  \n",
    "  ctx.train_and_evaluate_model(umodel, train_gen, test_generator=test_gen, retrain=False, lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUum89Tdhg-9"
   },
   "source": [
    "# Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_checkpoint(ctx, model_factory_fn):\n",
    "    \n",
    "#     model_name = model_factory_fn.__name__    \n",
    "#     model = ctx.init_model(model_fn, trained=True, trainable=False, weights=ctx.model_checkpoint_path / f'{model_factory_fn.__name__}.weights')\n",
    "#     model.summary()    \n",
    "\n",
    "\n",
    "#     ch_fn = os.path.join(ctx.model_checkpoint_path, f\"{model_name}-{keras.__version__}.h5\")\n",
    "\n",
    "#     if not os.path.isfile(ch_fn):\n",
    "#       model.save_weights(ch_fn)\n",
    "#       print(f\"model weights saved to {ch_fn}\")\n",
    "\n",
    "#     else:\n",
    "#       print(f\"model weights NOT saved, because file exists {ch_fn}\")\n",
    "\n",
    "# save_checkpoint(ctx, uber_detection_model_005_1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NJ9uhDBaJlO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_fn = uber_detection_model_005_1_1\n",
    "umodel = ctx.init_model(model_fn, trained=True, trainable=False, weights=ctx.model_checkpoint_path / f'{model_fn.__name__}.weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NLRR4qmKImgQ"
   },
   "source": [
    "### training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "me1LdIP5Ik9z",
    "outputId": "1bf81b8f-1f09-4760-a0f3-868a523652d9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_compare_models(\n",
    "    models: [str],\n",
    "    metrics, \n",
    "    title=\"metric/epoch\",\n",
    "    image_save_path = umtm.work_dir):\n",
    "    \n",
    "  _metrics = [m for m in metrics if not m.startswith('val_')]\n",
    "\n",
    "  for i, m in enumerate(models):\n",
    "\n",
    "    data: pd.DataFrame = ctx.get_log(m)\n",
    "\n",
    "    if data is not None:\n",
    "      data.set_index('epoch')\n",
    "\n",
    "      for metric in _metrics:\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        plt.grid()\n",
    "        plt.title(f'{metric}')\n",
    "        for metric_variant in ['', 'val_']:\n",
    "          key = metric_variant + metric\n",
    "          if key in data:\n",
    "\n",
    "            x = data['epoch'][-100:]\n",
    "            y = data[key][-100:]\n",
    "\n",
    "\n",
    "            c = 'red'  # plt.cm.jet_r(i * colorstep)\n",
    "            if metric_variant == '':\n",
    "              c = 'blue'\n",
    "            plt.plot(x, y, label=f'{key}', alpha=0.2, color=c)\n",
    "\n",
    "            y = y.rolling(4, win_type='gaussian').mean(std=4)\n",
    "            plt.plot(x, y, label=f'{key} SMOOTH', color=c)\n",
    "\n",
    "            plt.legend(loc='upper right')\n",
    "\n",
    "        \n",
    "        plt.title(f'{m} {title}')\n",
    "        plt.grid()\n",
    "        img_path = os.path.join(image_save_path, f'{m}-{metric}.png')\n",
    "        plt.savefig(img_path, bbox_inches='tight')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    else:\n",
    "      logger.error('cannot plot')\n",
    "    \n",
    "\n",
    "models = list(ctx.trained_models.keys())\n",
    "\n",
    "\n",
    "plot_compare_models(models, ['loss'], 'Loss')\n",
    "\n",
    "plot_compare_models(models, ['O1_tagging_kullback_leibler_divergence'], 'TAGS: Kullback Leibler divergence')\n",
    "# plot_compare_models(models, ['O1_tagging_mse'], 'TAGS: MSE')\n",
    "plot_compare_models(models, ['O2_subject_kullback_leibler_divergence'], 'Subj: Kullback Leibler divergence')\n",
    "# plot_compare_models(models, ['O2_subject_mse'],  'Subjects: MSE')\n",
    "\n",
    "plot_compare_models(models, ['O1_tagging_loss', 'O2_subject_loss'], 'Loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v1p8Mqpi32Bf"
   },
   "source": [
    "seq_labels_contract## Contract subj Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# umtm.stats\n",
    "# semantic_map_keys_contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = umtm.stats [umtm.stats['value']>0].index[2]\n",
    "print(sample_index)\n",
    "\n",
    "x, y, _ = umtm.make_xyw(sample_index)\n",
    "\n",
    "prediction = umodel.predict(x=[np.expand_dims(x[0], axis=0), np.expand_dims(x[1], axis=0)], batch_size=1)\n",
    "\n",
    "tagsmap = pd.DataFrame(prediction[0][0], columns=semantic_map_keys_contract)\n",
    "# .T\n",
    "plot_embedding(tagsmap[:500], f'Predicted Semantic Map {tagsmap.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent_tags = ['org-1-name',\n",
    "              'org-1-type',\n",
    "              'org-1-alias',\n",
    "              'org-2-name',\n",
    "              'org-2-type',\n",
    "              'org-2-alias']\n",
    "solo_tags = [\n",
    "  'date',\n",
    "  'number',\n",
    "  'sign_value_currency/value',\n",
    "  'sign_value_currency/currency',\n",
    "  'sign_value_currency/sign'\n",
    "]\n",
    "\n",
    "# seq_labels_contract[-3:]\n",
    "\n",
    "tagnames = solo_tags + agent_tags\n",
    "\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "from analyser.contract_agents import ContractAgent, normalize_contract_agent\n",
    "from analyser.documents import TextMap\n",
    "from analyser.ml_tools import SemanticTag\n",
    "from analyser.persistence import DbJsonDoc\n",
    "from analyser.text_tools import find_top_spans\n",
    "# from tf_support.super_contract_model import seq_labels_contract\n",
    "from tf_support.tf_subject_model import decode_subj_prediction\n",
    "\n",
    "from analyser.contract_parser import nn_find_org_names, nn_get_tag_value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetch_tags_from_predicted_semantic_map(_id: str, tagsmap: DataFrame):\n",
    "  jdoc = get_doc(_id)\n",
    "  _map = jdoc.get_tokens_map_unchaged()\n",
    "\n",
    "  results = {}\n",
    "  for key in tagnames:\n",
    "    t = nn_get_tag_value(key, _map, tagsmap )\n",
    "    results[key] = t\n",
    "    # print(t)\n",
    "\n",
    "#   ca = ContractAgent()\n",
    "#   ca.name =  results['org-1-name'] #TODO: check for NONE\n",
    "#   ca.type =  results['org-1-type']\n",
    "#   ca.alias = results['org-1-alias']\n",
    "   \n",
    "\n",
    "#   ca2 = ContractAgent()\n",
    "#   ca2.name =  results['org-2-name'] #TODO: check for NONE\n",
    "#   ca2.type =  results['org-2-type']\n",
    "#   ca2.alias = results['org-2-alias']\n",
    "#   try:\n",
    "#     normalize_contract_agent(ca)\n",
    "#     normalize_contract_agent(ca2)\n",
    "#   except Exception as e:\n",
    "#         # TODO:\n",
    "#     logger.error(f'{_id} {e}')\n",
    "\n",
    "  if results['number'] is not None:\n",
    "    results['number'].value = results['number'].value.strip().lstrip('№').lstrip('N ').lstrip()\n",
    "\n",
    "  return results, jdoc\n",
    "\n",
    "\n",
    "def put_results_into_df(id_, results, df, jdoc: DbJsonDoc):\n",
    "  org_atribs = ['name', 'alias', 'type']\n",
    "\n",
    "  def v(x):\n",
    "    if results[x] is not None:\n",
    "      return results[x].value\n",
    "\n",
    "  def swap(a, b):\n",
    "    ab = [a, b]\n",
    "    try:\n",
    "      ab = sorted(ab)\n",
    "    except:\n",
    "      pass\n",
    "    return ab\n",
    "\n",
    "  def s(a, b):\n",
    "    ab = swap(v(a), v(b))\n",
    "    df.at[id_, f'p-{a}'] = ab[0]\n",
    "    df.at[id_, f'p-{b}'] = ab[1]\n",
    "    return ab\n",
    "\n",
    "  for key in org_atribs:\n",
    "    arr = s(f'org-1-{key}', f'org-2-{key}')\n",
    "\n",
    "  def p(key):\n",
    "    df.at[id_, f'p-{key}'] = v(key)\n",
    "\n",
    "  p('sign_value_currency/value')\n",
    "  p('sign_value_currency/currency')\n",
    "  p('sign_value_currency/sign')\n",
    "\n",
    "  p('date')\n",
    "  p('number')\n",
    "\n",
    "  # get_expected values\n",
    "  for key in solo_tags:\n",
    "    t = jdoc.get_attribute_value(key)\n",
    "    df.at[id_, f'{key}'] = t\n",
    "\n",
    "  for key in org_atribs:\n",
    "    orgs = swap(jdoc.get_attribute_value(f'org-1-{key}'), jdoc.get_attribute_value(f'org-2-{key}'))\n",
    "    df.at[id_, f'org-1-{key}'] = orgs[0]\n",
    "    df.at[id_, f'org-2-{key}'] = orgs[1]\n",
    "\n",
    "def make_subj_predictions(umodel, indices):\n",
    "  ev = umtm.stats.copy()\n",
    "  tags = pd.DataFrame()\n",
    "  for t in tagnames:\n",
    "    tags['p-' + t] = ''\n",
    "    tags[t] = ''\n",
    "\n",
    "  errors_report = pd.DataFrame()\n",
    "  errors_report['expected'] = ''\n",
    "  errors_report['predicted'] = ''\n",
    "\n",
    "  for i, _id in enumerate(indices):\n",
    "    logger.debug(f'validating {_id} {i} of {len(indices)}')\n",
    "    \n",
    "    x, y, _ = umtm.make_xyw(_id)\n",
    "\n",
    "    prediction = umodel.predict(x=[np.expand_dims(x[0], axis=0), np.expand_dims(x[1], axis=0)], batch_size=1)\n",
    "\n",
    "    tagsmap = pd.DataFrame(prediction[0][0], columns=seq_labels_contract)\n",
    "  \n",
    "    r, jdoc = fetch_tags_from_predicted_semantic_map(_id, tagsmap)\n",
    "    put_results_into_df(_id, r, tags, jdoc)\n",
    "    \n",
    "\n",
    "    subj_1hot = prediction[1][0]\n",
    "\n",
    "    expected = decode_subj_prediction(y[1])[0]\n",
    "    predicted = decode_subj_prediction(subj_1hot)[0]\n",
    "\n",
    "    ev.at[_id, 'expected_subj'] = expected.name\n",
    "    ev.at[_id, 'predicted_subj'] = predicted.name\n",
    "\n",
    "    ev.at[_id, 'wrong'] = False\n",
    "    if expected != predicted:\n",
    "      ev.at[_id, 'wrong'] = True\n",
    "\n",
    "  return ev, tags\n",
    "\n",
    "ev, tags = make_subj_predictions(umodel, [sample_index])\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJLgtkpo-NUY"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def fetch_tag_value(tagname: str, textmap: TextMap, tagging: DataFrame, threshold=0.3) -> SemanticTag or None:\n",
    "#   att = tagging[tagname].values\n",
    "#   slices = find_top_spans(att, threshold=threshold, limit=1) #TODO: estimate per-tag thresholds\n",
    "  \n",
    "#   if len(slices) > 0:\n",
    "#     span = slices[0].start, slices[0].stop\n",
    "#     value = textmap.text_range(span)\n",
    "#     tag = SemanticTag(tagname, value, span)\n",
    "#     tag.confidence = att[slices[0]].mean()\n",
    "#     return tag\n",
    "#   return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "subset = umtm.stats #umtm.stats[~pd.isna(umtm.stats['user_correction_date'])].sort_values('analyze_date')\n",
    "_indices =  subset.index\n",
    "ev, tags = make_subj_predictions(umodel, _indices)\n",
    "tags.to_csv('all_contracts_predicstions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset = umtm.stats[~pd.isna(umtm.stats['user_correction_date'])]\n",
    "# pd.isna(umtm.stats['user_correction_date'])\n",
    "ev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jh1WFsjprUr1"
   },
   "outputs": [],
   "source": [
    "# _cols = [  'wrong' ]\n",
    "# _tmp = ev[cols]\n",
    "# errors_report = _tmp[ _tmp.wrong == True] #.sort_values('subject')\n",
    "# print(len(errors_report), 'wrong subjects of', len(tags))\n",
    "# errors_report \n",
    "\n",
    "ev['predicted_subj']\n",
    "subj_df = ev[['predicted_subj', 'expected_subj']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFh8SxP9J081"
   },
   "outputs": [],
   "source": [
    "def make_report(umodel, ev):\n",
    "  plot_cm(ev['expected_subj'], ev['predicted_subj'])\n",
    "  \n",
    "  img_path = os.path.join(umtm.work_dir, f'subjects-confusion-matrix-{umodel.name}.png')\n",
    "  plt.savefig(img_path, bbox_inches='tight')\n",
    "\n",
    "  report = classification_report(ev['expected_subj'], ev['predicted_subj'], digits=3)\n",
    "  print(umodel.name)\n",
    "  print(report)\n",
    "  \n",
    "  with open(os.path.join(umtm.work_dir, f'subjects-classification_report-{umodel.name}.txt'), \"w\") as text_file:\n",
    "    text_file.write(report)\n",
    "\n",
    "\n",
    "subj_df = ev[['predicted_subj', 'expected_subj']].copy() #ev[~pd.isna(ev['predicted_subj'])]\n",
    "make_report(umodel, subj_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mX5RUserhy0m"
   },
   "source": [
    "# Evaluate tags detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.fillna('-', inplace=True)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(d, f):\n",
    "    fn = os.path.join(umtm.work_dir, f)\n",
    "    d.to_csv(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_SUQNtsxVBp9"
   },
   "source": [
    "### Contract number validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "fGnSN-Bp87VW",
    "outputId": "0a23b5c6-91a3-44f7-dd1c-60f567a8f326"
   },
   "outputs": [],
   "source": [
    "wrong_numbers = tags [ tags['number'] != tags['p-number']].sort_values('number')\n",
    "print( f'Contract numbers: {len(wrong_numbers)} of {len(tags)}  ({100. * len(wrong_numbers) / len(tags) :0.1f}%) were detected wronggly')\n",
    "\n",
    "save_csv( wrong_numbers[['p-number', 'number']], 'wrong_numbers.csv')\n",
    "\n",
    "# wrong_numbers[['p-number', 'number']].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags ['sign_value_currency/currency'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x):\n",
    "    if type(x) is str:\n",
    "        v = x.replace(',','.').replace(' ','')\n",
    "    else: \n",
    "        v=x\n",
    "    try:\n",
    "        v=float(v)\n",
    "    except:\n",
    "        v=np.nan\n",
    "    return v \n",
    "\n",
    "tags['n-p-sign_value_currency/value'] = pd.to_numeric( tags['p-sign_value_currency/value'].apply(conv) )\n",
    "tags['n-sign_value_currency/value']   = pd.to_numeric( tags['sign_value_currency/value'].apply(conv) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_values = tags [  tags['n-p-sign_value_currency/value']  != tags['n-sign_value_currency/value']]\n",
    "cols = ['n-p-sign_value_currency/value', 'n-sign_value_currency/value']\n",
    "wrong_values = wrong_values[cols]\n",
    "\n",
    "wrong_values ['val_err'] = \\\n",
    "    np.log1p( np.abs(wrong_values['n-p-sign_value_currency/value'] - wrong_values['n-sign_value_currency/value']))\n",
    "wrong_values = wrong_values.sort_values('val_err', ascending=False)\n",
    "\n",
    "print(len(wrong_values))\n",
    "wrong_values.tail(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U8qtdCl3Zdt7"
   },
   "source": [
    "### Contract Org-1 validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oCUtMUEZZduA"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wrong_orgs1 = tags [ (tags['org-1-name'] != tags['p-org-1-name']) | (tags['org-2-name'] != tags['p-org-2-name']) ]\n",
    "print( f'Org-1 name: {len(wrong_orgs1)} of {len(tags)}  ({100. * len(wrong_orgs1) / len(tags):0.1f}%) were detected incorrectly')\n",
    "\n",
    "cols=['p-org-1-name', 'org-1-name', 'p-org-2-name', 'org-2-name']\n",
    "save_csv( wrong_orgs1[cols], 'wrong_orgs1.csv')\n",
    "\n",
    "wrong_orgs1[cols].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "colab_type": "code",
    "id": "HZrAdEP0iwjK",
    "outputId": "73b4e39b-6313-47a8-854e-7f4af1c76ee6"
   },
   "outputs": [],
   "source": [
    "wrong_aliases = tags [ (tags['org-1-alias'] != tags['p-org-1-alias']) | (tags['org-2-alias'] != tags['p-org-2-alias']) ]\n",
    "print( f'Aliases: {len(wrong_aliases)} of {len(tags)}  ({100. * len(wrong_aliases) / len(tags) : 0.1f}%) were detected incorrectly')\n",
    "\n",
    "cols=['p-org-1-alias', 'org-1-alias', 'p-org-2-alias', 'org-2-alias']\n",
    "save_csv( wrong_aliases[cols], 'wrong_aliases.csv')\n",
    "# wrong_aliases[cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6j8omO8Sk2Nv"
   },
   "outputs": [],
   "source": [
    "wrong_types = tags [ (tags['org-1-type'] != tags['p-org-1-type']) | (tags['org-2-type'] != tags['p-org-2-type'])]\n",
    "print( f'Types: {len(wrong_types)} of {len(tags)}  ({100. * len(wrong_types) / len(tags) : 0.1f}%) were detected incorrectly')\n",
    "cols=['p-org-1-type', 'p-org-2-type', 'org-1-type', 'org-2-type']\n",
    "save_csv( wrong_types[cols], 'wrong_types.csv')\n",
    "wrong_types[cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TLXWndqih-oE"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "arrays = [ wrong_orgs1, wrong_types, wrong_numbers, wrong_aliases]\n",
    "counter = Counter()\n",
    "for a in arrays:\n",
    "  for i in a.index:\n",
    "   counter[i]+=1\n",
    " \n",
    "\n",
    "print('Самый сложный документ: ', counter.most_common()[0][0])\n",
    "print(\"Всего недочетов:\", len(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "colab_type": "code",
    "id": "uvG2pH1rt6G_",
    "outputId": "5b9173d2-c781-49bf-cccb-be2b481edee4"
   },
   "outputs": [],
   "source": [
    "umtm.stats['errors'] = 0\n",
    "for c in counter:\n",
    "  umtm.stats.at[c, 'errors'] = counter[c]\n",
    "\n",
    "\n",
    "calculate_samples_weights(umtm)\n",
    "umtm._save_stats()\n",
    "umtm.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_CR9W8NDH8B-"
   },
   "source": [
    "## Single doc eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFzr4k-cpOzX"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  !wget https://raw.githubusercontent.com/nemoware/analyser/uber-models/tests/contract_db_1.json\n",
    "\n",
    "  with open('contract_db_1.json', 'rb') as handle:    \n",
    "    jdata = json.load(handle, object_hook=json_util.object_hook)\n",
    "\n",
    "  jdoc = DbJsonDoc(jdata)\n",
    "\n",
    "else:\n",
    "  from integration.db import get_mongodb_connection\n",
    "  from bson.objectid import ObjectId\n",
    "\n",
    "  def get_doc(objid):\n",
    "    logger.debug(f'fetching {objid}')\n",
    "    db = get_mongodb_connection()\n",
    "    documents_collection = db['documents']\n",
    "    jdata =  documents_collection.find_one({'_id': ObjectId(objid)})\n",
    "    return DbJsonDoc(jdata)\n",
    "\n",
    "  SAMPLE_DOC_ID = counter.most_common()[0][0] #umtm.stats.index[10]\n",
    "    \n",
    "    \n",
    "    \n",
    "  SAMPLE_DOC_ID = '5eea27adc28b75807f3dae66'\n",
    "  print('SAMPLE_DOC_ID:', SAMPLE_DOC_ID)\n",
    "  dp = umtm.make_xyw(SAMPLE_DOC_ID)\n",
    "  (emb, tok_f), (sm, subj), (sample_weight, subject_weight) = dp\n",
    "\n",
    "  jdoc = get_doc(SAMPLE_DOC_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfHQOFhw3yuO"
   },
   "outputs": [],
   "source": [
    "from analyser.legal_docs import embedd_tokens\n",
    "\n",
    "if IN_COLAB:\n",
    "  embedder = ElmoEmbedder.get_instance('elmo')  # lazy init\n",
    "  emb = embedd_tokens(jdoc.get_tokens_for_embedding(),\n",
    "                             embedder,\n",
    "                             verbosity=2,\n",
    "                             log_key='tmp')\n",
    "\n",
    "  tok_f = get_tokens_features(jdoc.get_tokens_map_unchaged().tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yF9kgac_hZr"
   },
   "outputs": [],
   "source": [
    "###############\n",
    "prediction = umodel.predict(   x=[  np.expand_dims(emb, axis=0), np.expand_dims(tok_f, axis=0)] , batch_size=1)\n",
    "##############\n",
    "print(len(prediction), umodel.name)\n",
    "subj_1hot = prediction[1][0]\n",
    "print('Subject:', decode_subj_prediction(subj_1hot))\n",
    "\n",
    "\n",
    "tagging = pd.DataFrame( prediction[0][0], columns=seq_labels_contract)\n",
    "plot_embedding(tagging, title = f'Predictions of {umodel.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBRtwOj5QvNf"
   },
   "outputs": [],
   "source": [
    "def render_slices(slices, tokens, attention_v, ht='') -> str:\n",
    "  ht += '<ol>'\n",
    "  for _s in slices:\n",
    "    ht += '<li>'\n",
    "    t = tokens[_s]\n",
    "    l = attention_v[_s]\n",
    "    ht += to_color_text(t, l, _range=(0, 1.2))\n",
    "    ht += '<br><hr>'\n",
    "    ht += '</li>'\n",
    "  ht += '</ol>'\n",
    "\n",
    "  return ht\n",
    "\n",
    "for t in seq_labels_contract:\n",
    "  spans = list( find_top_spans( tagging[t].values, threshold=0.3))  \n",
    "  display(HTML(render_slices(spans, jdoc.get_tokens_map_unchaged().tokens, tagging[t].values)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mean_ = tagging.values.max(-1)*0.5\n",
    "# print (mean_.shape)\n",
    "# display(HTML( to_color_text (jdoc.get_tokens_map_unchaged().tokens[:24000],  mean_[:24000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = '5edbadd7da3678279fbcaabf\n",
    "5edbc660da3678279fbcaeac\n",
    "5edbc668da3678279fbcaf6e\n",
    "5edbc65dda3678279fbcae56\n",
    "5edbc66bda3678279fbcafe6\n",
    "5edbc615da3678279fbcadc9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9eF-UGHyh-C9",
    "7X_zYCYEdlPM",
    "lyI4hbTRFjyM"
   ],
   "name": "Local: structure keras uber model - clean train, evaluate, test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
